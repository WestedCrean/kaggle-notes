{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train nn using pytorch lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcb\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# pytorch lightning\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# essentials\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# visualisation\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MaxAbsScaler, PowerTransformer, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, SequentialFeatureSelector, RFECV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.base import clone as clone_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix, log_loss\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# others\n",
    "import xgboost as xgb \n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "# pytorch lightning\n",
    "import torch, torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import lightning as L\n",
    "\n",
    "RANDOM_SEED = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_KAGGLE = False\n",
    "kaggle_folder = \"/kaggle/input/playground-series-s3e26\"\n",
    "local_folder = \"./data\"\n",
    "train_df = pd.read_csv(kaggle_folder if IN_KAGGLE else local_folder + \"/train.csv\", index_col=\"id\")\n",
    "test_df = pd.read_csv(kaggle_folder if IN_KAGGLE else local_folder  + \"/test.csv\", index_col=\"id\")\n",
    "\n",
    "target_column = \"Status\"\n",
    "\n",
    "def feature_engineering(df):\n",
    "    df['Drug'] = df['Drug'].map({\"D-penicillamine\": 1,\"placebo\": 0})\n",
    "    df['Sex'] = df['Sex'].map({\"F\": 1,\"M\": 0})\n",
    "\n",
    "    # change \"Stage\" to string\n",
    "    df[\"Stage\"] = df[\"Stage\"].apply(lambda x: str(x))\n",
    "    return df\n",
    "\n",
    "run_feature_engineering = True\n",
    "\n",
    "categorical_features = [\"Drug\", \"Sex\", \"Ascites\", \"Hepatomegaly\", \"Spiders\", \"Edema\", \"Stage\"]\n",
    "numerical_features = [\"N_Days\", \"Age\", \"Bilirubin\", \"Cholesterol\", \"Albumin\", \"Copper\", \"Alk_Phos\", \"SGOT\", \"Tryglicerides\", \"Platelets\", \"Prothrombin\"]\n",
    "\n",
    "if run_feature_engineering:\n",
    "    train_df = feature_engineering(train_df)\n",
    "\n",
    "if run_feature_engineering:\n",
    "    categorical_features += [\"no_diseases\", \"diseases\"]\n",
    "    numerical_features += [\"date_of_diagnosis\"]\n",
    "\n",
    "X = train_df.drop(columns=target_column)\n",
    "y = train_df[target_column]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=RANDOM_SEED, stratify=y, shuffle=True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_val = le.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    [\n",
    "        (\"power_transformer\", PowerTransformer()),\n",
    "        (\"scaler\", MaxAbsScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    [\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", drop=\"if_binary\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numerical_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "models = [\n",
    "    (\"default xgboost\", xgb.XGBClassifier(\n",
    "        objective=\"multi:softprob\", random_state=RANDOM_SEED, n_jobs=-1 )),\n",
    "    (\"optimized_xgboost\", xgb.XGBClassifier(\n",
    "        objective=\"multi:softprob\", random_state=RANDOM_SEED, n_jobs=-1,\n",
    "        subsample=0.8,\n",
    "        min_child_weight=7,\n",
    "        max_depth=7,\n",
    "        reg_lambda=0.9,\n",
    "        gamma=0.9,\n",
    "        eta=0.08,\n",
    "        colsample_bytree=0.5,\n",
    "        reg_alpha=0.5\n",
    "    )),\n",
    "    (\"default catboost\", cb.CatBoostClassifier(random_state=RANDOM_SEED, verbose=False)),\n",
    "    (\"default lightgbm\", lgb.LGBMClassifier(random_state=RANDOM_SEED, n_jobs=4)),\n",
    "    \n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "clf = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", CalibratedClassifierCV(model, cv=skf)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_proba = clf.predict_proba(X_val)\n",
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "log_loss_score = log_loss(y_val, y_pred_proba)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
