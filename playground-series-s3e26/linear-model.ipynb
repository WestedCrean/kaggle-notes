{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# essentials\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# visualisation\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, log_loss\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import NearestCentroid, KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "from sklearn.utils import compute_sample_weight, compute_class_weight\n",
    "\n",
    "\n",
    "# others\n",
    "import xgboost as xgb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 64\n",
    "\n",
    "input_folder = \"./data\" # /kaggle/input/playground-series-s3e26\n",
    "train_df = pd.read_csv(input_folder+ \"/train.csv\", index_col=\"id\")\n",
    "test_df = pd.read_csv(input_folder+\"/test.csv\", index_col=\"id\")\n",
    "\n",
    "target_column = \"Status\"\n",
    "\n",
    "categorical_features = [\"Drug\", \"Sex\", \"Ascites\", \"Hepatomegaly\", \"Spiders\", \"Edema\", \"Stage\"]\n",
    "numerical_features = [\"N_Days\", \"Age\", \"Bilirubin\", \"Cholesterol\", \"Albumin\", \"Copper\", \"Alk_Phos\", \"SGOT\", \"Tryglicerides\", \"Platelets\", \"Prothrombin\"]\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(columns=target_column)\n",
    "y = train_df[target_column]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=RANDOM_SEED, stratify=y, shuffle=True)\n",
    "\n",
    "print(f\"Number of training examples: {len(X_train)}\")\n",
    "print(f\"Number of validation examples: {len(X_val)}\")\n",
    "\n",
    "print(\"Number of examples per class in training set\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print(\"Number of examples per class in validation set\")\n",
    "print(y_val.value_counts())\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_val = le.transform(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight_keys = np.unique(y_train)\n",
    "class_weight_values = compute_class_weight(\"balanced\", classes=np.unique(y_train), y=y_train)\n",
    "\n",
    "class_weights = dict(zip(class_weight_keys, class_weight_values))\n",
    "class_weights\n",
    "\n",
    "sample_weights = [ class_weights[j] for j in y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = {\n",
    "    \"xgboost\": xgb.XGBClassifier(objective=\"multi:softprob\", random_state=RANDOM_SEED, n_jobs=-1),\n",
    "    \"logistic_regression\": LogisticRegression(random_state=RANDOM_SEED, multi_class=\"ovr\", n_jobs=-1),\n",
    "    \"sgd\": SGDClassifier(random_state=RANDOM_SEED, n_jobs=-1, loss=\"log_loss\"),\n",
    "    \"decision_tree\": DecisionTreeClassifier(random_state=RANDOM_SEED),\n",
    "    \"random_forest\": RandomForestClassifier(random_state=RANDOM_SEED, n_jobs=-1),\n",
    "    \"gradient_boosting\": GradientBoostingClassifier(random_state=RANDOM_SEED),\n",
    "    \"naive_bayes\": GaussianNB(),\n",
    "    \"svc\": SVC(random_state=RANDOM_SEED, probability=True),\n",
    "    \"linear_svc\": LinearSVC(random_state=RANDOM_SEED),\n",
    "    \"nu_svc\": NuSVC(random_state=RANDOM_SEED),\n",
    "    \"kneighbors\": KNeighborsClassifier(n_jobs=-1),\n",
    "    \"gaussian_process\": GaussianProcessClassifier(random_state=RANDOM_SEED, multi_class = \"one_vs_rest\", n_jobs=-1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    [\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numerical_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "models_scores = []\n",
    "\n",
    "for model_name, model in tqdm(models.items()):\n",
    "    try:\n",
    "        clf = Pipeline(\n",
    "            [\n",
    "                (\"preprocessor\", preprocessor),\n",
    "                (\"classifier\", CalibratedClassifierCV(model, cv=3)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        clf.fit(X_train, y_train, classifier__sample_weight=sample_weights)\n",
    "        y_pred_proba = clf.predict_proba(X_val)\n",
    "        y_pred = clf.predict(X_val)\n",
    "\n",
    "        log_loss_score = log_loss(y_val, y_pred_proba)\n",
    "    except Exception as e:\n",
    "        print(\"Problem with model: \", model_name)\n",
    "        print(e)\n",
    "        log_loss_score = None\n",
    "\n",
    "    models_scores.append({\n",
    "        \"model_name\": model_name,\n",
    "        \"log_loss\": log_loss_score\n",
    "    })\n",
    "\n",
    "models_scores_df = pd.DataFrame(models_scores).sort_values(by=\"log_loss\", ascending=True)\n",
    "models_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = models_scores_df.iloc[0][\"model_name\"]\n",
    "\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "clf = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", best_model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train, classifier__sample_weight=sample_weights)\n",
    "y_pred_proba = clf.predict_proba(X_val)\n",
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "print(f\"Log loss: {log_loss(y_val, y_pred_proba)}\")\n",
    "print(classification_report(y_val, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise confusion matrix\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "ax.title.set_text(\"Confusion matrix\")\n",
    "sns.heatmap(confusion_matrix(y_val, y_pred), annot=True, ax=ax)\n",
    "ax.set_xticklabels(le.classes_)\n",
    "ax.set_yticklabels(le.classes_)\n",
    "\n",
    "# show on top of heatmap text \"Predicted values\"\n",
    "ax.set_xlabel(\"Predicted values\")\n",
    "ax.set_ylabel(\"True values\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
