{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train current best model & create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# essentials\n",
    "import os\n",
    "import pathlib\n",
    "from copy import copy\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# visualisation\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn imports\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MaxAbsScaler, PowerTransformer, FunctionTransformer, StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MaxAbsScaler, PowerTransformer, FunctionTransformer, StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, make_union, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, SequentialFeatureSelector, RFECV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.base import clone as clone_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix, log_loss\n",
    "from sklearn.impute import SimpleImputer, MissingIndicator, KNNImputer\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import RocCurveDisplay, roc_auc_score, make_scorer, roc_curve\n",
    "\n",
    "from sklearn.preprocessing import Binarizer, Normalizer, RobustScaler, StandardScaler\n",
    "from tpot.builtins import StackingEstimator, ZeroCount\n",
    "from tpot.export_utils import set_param_recursive\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# others\n",
    "import xgboost as xgb \n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import optuna\n",
    "\n",
    "RANDOM_SEED = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_KAGGLE = False\n",
    "\n",
    "kaggle_folder = \"/kaggle/input/\"\n",
    "local_folder = \"./data/\"\n",
    "train_df = pd.read_csv(kaggle_folder if IN_KAGGLE else local_folder + \"playground-series-s3e26/train.csv\", index_col=\"id\")\n",
    "test_df = pd.read_csv(kaggle_folder if IN_KAGGLE else local_folder  + \"playground-series-s3e26/test.csv\", index_col=\"id\")\n",
    "original_df = pd.read_csv(kaggle_folder if IN_KAGGLE else local_folder  + \"cirrhosis-prediction-dataset/cirrhosis.csv\", index_col=\"ID\")\n",
    "\n",
    "original_df['generated'] = 0\n",
    "train_df['generated'] = 1\n",
    "test_df['generated'] = 1\n",
    "train_df = pd.concat([train_df, original_df], axis=0)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "target_column = \"Status\"\n",
    "\n",
    "target_map = {\"C\": \"censored\", \"CL\": \"censored due to liver transplant\", \"D\": \"death\"} # for readability of charts\n",
    "train_df[target_column] = train_df[target_column].map(target_map)\n",
    "\n",
    "categorical_features = [\"Drug\", \"Sex\", \"Ascites\", \"Hepatomegaly\", \"Spiders\", \"Edema\", \"Stage\"]\n",
    "numerical_features = [\"N_Days\", \"Age\", \"Bilirubin\", \"Cholesterol\", \"Albumin\", \"Copper\", \"Alk_Phos\", \"SGOT\", \"Tryglicerides\", \"Platelets\", \"Prothrombin\"]\n",
    "\n",
    "#categorical_features += [\"generated\"]\n",
    "\n",
    "def num_features_1(df):\n",
    "    df['bilirubin_increased_levels'] = df['Bilirubin'] > 1.1\n",
    "    df['cholesterol_increased'] = df['Cholesterol'] > 240\n",
    "    df[\"albumin_low\"] = df['Albumin'] < 3.5\n",
    "    df[\"urinary_copper_increased\"] = df['Copper'] > 40\n",
    "    df[\"Alk_Phos_increased\"] = df['Alk_Phos'] > 1400\n",
    "    df['SGOT_increased'] = df[\"SGOT\"] > 80 \n",
    "    df[\"Tryglicerides_normal\"] = df['Tryglicerides'] < 150 \n",
    "    df[\"Platelets_normal\"] = (df['Platelets'] >= 150) & (df['Platelets'] <= 400)\n",
    "    \n",
    "    threshold_platelets = 150\n",
    "    df['thrombocytopenia'] = np.where(df['Platelets'] < threshold_platelets, 1, 0)\n",
    "\n",
    "    new_cat_feature_names = [\n",
    "        \"thrombocytopenia\"\n",
    "    ]\n",
    "    new_num_feature_names = [\n",
    "        'bilirubin_increased_levels',\n",
    "        'cholesterol_increased',\n",
    "        'albumin_low',\n",
    "        'urinary_copper_increased',\n",
    "        'Alk_Phos_increased',\n",
    "        'SGOT_increased',\n",
    "        'Tryglicerides_normal',\n",
    "        'Platelets_normal',\n",
    "    ]\n",
    "    return df, new_cat_feature_names, new_num_feature_names\n",
    "\n",
    "def num_features_2(df):\n",
    "    normal_ranges = {\n",
    "        'Bilirubin': (0.1, 1.2),\n",
    "        'Cholesterol': (0, 200),\n",
    "        'Albumin': (3.5, 5.5),\n",
    "        'Copper': (10, 30),\n",
    "        'Alk_Phos': (40, 129),\n",
    "        'SGOT': (8, 45),\n",
    "        'Tryglicerides': (48.68, 168.15),\n",
    "        'Platelets': (150, 400),\n",
    "        'Prothrombin': (9.4, 12.5)\n",
    "    }\n",
    "\n",
    "    for feature, (normal_range_min, normal_range_max) in normal_ranges.items():\n",
    "        if feature == 'Albumin':\n",
    "            df[f'{feature}_is_normal'] = (df[feature] >= normal_range_min)\n",
    "        else:\n",
    "            df[f'{feature}_is_normal'] = (df[feature] >= normal_range_min) & (df[feature] <= normal_range_max) \n",
    "\n",
    "        # Add deviation calculation as before\n",
    "        df.loc[~df[f'{feature}_is_normal'], f'{feature}_deviation'] = df[feature] - ((normal_range_min + normal_range_max) / 2)\n",
    "\n",
    "    threshold_platelets = 150\n",
    "    df['thrombocytopenia'] = np.where(df['Platelets'] < threshold_platelets, 1, 0)\n",
    "\n",
    "\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    new_cat_feature_names = [f'{feature}_is_normal' for feature in normal_ranges.keys() ]\n",
    "    new_num_feature_names = [f'{feature}_deviation' for feature in normal_ranges.keys()]\n",
    "\n",
    "    new_cat_feature_names.append('thrombocytopenia')\n",
    "    \n",
    "    return df, new_cat_feature_names, new_num_feature_names\n",
    "\n",
    "def num_features_3(df):\n",
    "    ##initial pass as creating features for meaningful cutoffs\n",
    "    df['APRI']=100 * (df['SGOT'])/df['Platelets']\n",
    "    df['under769days']=np.where(df['N_Days']<769, 1, 0)\n",
    "    df['bilirubin_1.2']=np.where(df['Bilirubin']>1.2, 1, 0)\n",
    "    df['albumin_low']=np.where(df['Albumin']<2.23, 1, 0)\n",
    "    df['copper_high']=np.where(df['Copper']>73, 1, 0)\n",
    "    df['SGOT_high']=np.where(df['SGOT']>73, 1, 0)\n",
    "    df['Prothrombin_high']=np.where(df['Prothrombin']>10.8, 1, 0)\n",
    "    df['Edema_yn']=np.where(df['Edema']=='N', 0, 1)\n",
    "    df['bilirubin_3']=np.where(df['Bilirubin']>3, 1, 0)\n",
    "    df['high_cholesteroal']=np.where(df['Cholesterol']>240, 1, 0)\n",
    "    df['age_over_70']=np.where((df['Age']/365)>=70, 1, 0)\n",
    "    df['abnormal_alp']=np.where(((df['Alk_Phos']<30 )| (df['Alk_Phos']>147)), 1, 0)\n",
    "    df['very_high_tri']=np.where(df['Tryglicerides']>500, 1, 0)\n",
    "    df['high_tri']=np.where(df['Tryglicerides']>200, 1, 0)\n",
    "    df['copper_deficient']=np.where(((df['Sex']=='F') & (df['Copper']<80) |(df['Sex']=='M') & (df['Copper']<70)), 1, 0)\n",
    "    df['FIB4']=(df['Age']/365)* (df['SGOT']/df['Platelets'])\n",
    "    df['ALBI']=.66*np.log(df['Bilirubin'])-.085 * df['Albumin']\n",
    "\n",
    "    new_cat_feature_names = [\n",
    "        \"under769days\",\n",
    "        \"bilirubin_1.2\",\n",
    "        \"albumin_low\",\n",
    "        \"copper_high\",\n",
    "        \"SGOT_high\",\n",
    "        \"Prothrombin_high\",\n",
    "        \"Edema_yn\",\n",
    "        \"bilirubin_3\",\n",
    "        \"high_cholesteroal\",\n",
    "        \"age_over_70\",\n",
    "        \"abnormal_alp\",\n",
    "        \"very_high_tri\",\n",
    "        \"high_tri\",\n",
    "        \"copper_deficient\",\n",
    "    ]\n",
    "    new_num_feature_names = [\n",
    "        \"APRI\",\n",
    "        \"FIB4\",\n",
    "        \"ALBI\",\n",
    "    ]\n",
    "\n",
    "    \n",
    "    return df, new_cat_feature_names, new_num_feature_names\n",
    "\n",
    "def base_feature_engineering(df):\n",
    "    df['Drug'] = df['Drug'].map({\"D-penicillamine\": 1,\"Placebo\": 0})\n",
    "    df['Sex'] = df['Sex'].map({\"F\": 1,\"M\": 0})\n",
    "    \n",
    "    df[\"Stage\"] = df[\"Stage\"].apply(lambda x: str(x))\n",
    "    df['Stage'] = df['Stage'].astype('category')\n",
    "\n",
    "    for c in categorical_features:\n",
    "        df[c] = df[c].astype('category')\n",
    "    return df\n",
    "\n",
    "\n",
    "train_df, new_cat, new_num = num_features_2(train_df)\n",
    "train_df = base_feature_engineering(train_df)\n",
    "\n",
    "\n",
    "categorical_features += new_cat\n",
    "numerical_features += new_num\n",
    "\n",
    "X = train_df.drop(columns=target_column)\n",
    "y = train_df[target_column]\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=RANDOM_SEED, stratify=y, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imputer = SimpleImputer(strategy=\"constant\", fill_value=0, add_indicator=True)\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"missing\", add_indicator=True)\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    [\n",
    "        (\"num_imputer\", num_imputer),\n",
    "        (\"power_transformer\", PowerTransformer()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    [\n",
    "        (\"cast as str\", FunctionTransformer(lambda x: x.astype(str), validate=False)),\n",
    "        (\"cat_imputer\", cat_imputer),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", drop=\"if_binary\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numerical_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "\n",
    "lgbm_best_params = {'n_estimators': 394, 'max_depth': 24, 'learning_rate': 0.018470603878367985, 'reg_alpha': 0.41378770694989003, 'reg_lambda': 0.032090753198459054, 'min_child_weight': 3.8061942196940897, 'min_child_samples': 47, 'subsample': 0.8047498902111587, 'subsample_freq': 5, 'colsample_bytree': 0.20152270171348546, 'num_leaves': 126, 'max_bin': 872, 'boosting_type': 'gbdt', 'num_imputer_strategy': 'constant', 'cat_imputer_strategy': 'constant'}\n",
    "xgb_params = {'n_estimators': 500, 'max_depth': 48, 'learning_rate': 0.012196600643907861, 'reg_alpha': 0.04387533822107198, 'reg_lambda': 0.0019799138401186277, 'min_child_weight': 3.877063073846295, 'min_child_samples': 6, 'subsample': 0.8443268948580747, 'subsample_freq': 0, 'colsample_bytree': 0.23694087295634517, 'num_leaves': 81, 'max_bin': 405, 'boosting_type': 'gbdt', 'num_imputer_strategy': 'constant', 'cat_imputer_strategy': 'most_frequent'}\n",
    "lgbm_model_optuna = lgb.LGBMClassifier(**lgbm_best_params, random_state=RANDOM_SEED, verbose=-1, n_jobs=5)\n",
    "xgb_model_optuna = xgb.XGBClassifier(\n",
    "        **xgb_params, objective=\"multi:softprob\", random_state=RANDOM_SEED, n_jobs=-1, tree_method=\"hist\", device=\"cuda\"\n",
    "    )\n",
    "\n",
    "models = {\n",
    "    \"voting classifier 1\": VotingClassifier(\n",
    "        estimators=[\n",
    "            (\"catboost\", cb.CatBoostClassifier(random_state=RANDOM_SEED, verbose=False)),\n",
    "            (\"lightgbm_optuna\", lgbm_model_optuna),\n",
    "            (\"xgb_optuna\", xgb_model_optuna),\n",
    "        ],\n",
    "        voting=\"soft\",\n",
    "        n_jobs=-1,\n",
    "        verbose=1),\n",
    "    \"stacking classifier 1\": StackingClassifier(\n",
    "        estimators=[\n",
    "            (\"catboost\", cb.CatBoostClassifier(random_state=RANDOM_SEED, verbose=False)),\n",
    "            (\"lightgbm_optuna\", lgbm_model_optuna),\n",
    "            (\"xgb_optuna\", xgb_model_optuna),\n",
    "        ],\n",
    "        stack_method=\"predict_proba\",\n",
    "        final_estimator=LogisticRegression(),\n",
    "        n_jobs=-1,\n",
    "        verbose=1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for model_name, model in models.items():\n",
    "    clf = Pipeline(\n",
    "        [\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", model),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    cc_cv = CalibratedClassifierCV(clf, cv=skf)\n",
    "\n",
    "    cc_cv.fit(X_train, y_train)\n",
    "    y_pred_proba = cc_cv.predict_proba(X_val)\n",
    "    y_pred = cc_cv.predict(X_val)\n",
    "    \n",
    "    cr = classification_report(y_val, y_pred, output_dict=True)\n",
    "\n",
    "    recall_class_0 = confusion_matrix(y_val, y_pred, normalize=\"true\")[0, 0]\n",
    "    recall_class_1 = confusion_matrix(y_val, y_pred, normalize=\"true\")[1, 1]\n",
    "    recall_class_2 = confusion_matrix(y_val, y_pred, normalize=\"true\")[2, 2]\n",
    "    data.append({\n",
    "        \"model\": model_name, \n",
    "        \"log_loss_score\": log_loss(y_val, y_pred_proba),\n",
    "        \"avg_precision\": cr[\"macro avg\"][\"precision\"],\n",
    "        \"f1_score\": cr[\"macro avg\"][\"f1-score\"],\n",
    "        \"recall_class_0\": recall_class_0,\n",
    "        \"recall_class_1\": recall_class_1,\n",
    "        \"recall_class_2\": recall_class_2,\n",
    "    })    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>log_loss_score</th>\n",
       "      <th>avg_precision</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall_class_0</th>\n",
       "      <th>recall_class_1</th>\n",
       "      <th>recall_class_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>voting classifier 1</td>\n",
       "      <td>0.405173</td>\n",
       "      <td>0.799585</td>\n",
       "      <td>0.707588</td>\n",
       "      <td>0.936538</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.770318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  log_loss_score  avg_precision  f1_score  \\\n",
       "0  voting classifier 1        0.405173       0.799585  0.707588   \n",
       "\n",
       "   recall_class_0  recall_class_1  recall_class_2  \n",
       "0        0.936538             0.3        0.770318  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = pd.DataFrame(data).drop_duplicates().sort_values(by=[\"log_loss_score\", \"recall_class_1\"], ascending=[True, False])\n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter optimization\n",
    "\n",
    "- XGBoost\n",
    "- LightGBM\n",
    "- CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "def objective_xgboost(trial):\n",
    "    xgboost_model_optuna = xgb.XGBClassifier(\n",
    "        objective=\"multi:softprob\", n_jobs=-1, tree_method=\"hist\", device=\"cuda\"\n",
    "    )\n",
    "    clf = Pipeline(\n",
    "        [\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", xgboost_model_optuna),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    params = {\n",
    "        \"classifier__random_state\": trial.suggest_int(\"random_state\", 1, 1000),\n",
    "        'classifier__n_estimators' : trial.suggest_int('n_estimators',50,500),\n",
    "        \"classifier__max_depth\":trial.suggest_int('max_depth',3,50),\n",
    "        \"classifier__eta\" : trial.suggest_float('eta',1e-4, 0.25, log=True),\n",
    "\n",
    "        'classifier__reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10.0),\n",
    "        'classifier__reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n",
    "        \"classifier__min_child_weight\" : trial.suggest_float('min_child_weight', 0.5,10),\n",
    "        \"classifier__subsample\" : trial.suggest_float('subsample', 0.1, 1),\n",
    "        \"classifier__colsample_bytree\" : trial.suggest_float('colsample_bytree',0.2,1),\n",
    "        'classifier__num_leaves' : trial.suggest_int('num_leaves', 2, 64),\n",
    "        'classifier__max_delta_step' : trial.suggest_int('max_delta_step', 0, 10),\n",
    "        'classifier__scale_pos_weight' : trial.suggest_int('scale_pos_weight', 0, 10),\n",
    "        'preprocessor__num__num_imputer__strategy': trial.suggest_categorical('num_imputer_strategy', ['mean', 'median', 'constant']),\n",
    "        'preprocessor__cat__cat_imputer__strategy': trial.suggest_categorical('cat_imputer_strategy', ['most_frequent', 'constant']),\n",
    "    }\n",
    "    clf.set_params(**params)\n",
    "    \n",
    "    cv = abs(cross_val_score(clf, X, y, cv = skf,scoring='neg_log_loss').mean())\n",
    "    return cv\n",
    "\n",
    "def objective_lightgbm(trial):\n",
    "    lgbm_best_params = {\n",
    "        'n_estimators': 377, \n",
    "        'max_depth': 24, \n",
    "        'learning_rate': 0.018470603878367985, \n",
    "        'reg_alpha': 0.41378770694989003, \n",
    "        'reg_lambda': 0.032090753198459054, \n",
    "        'min_child_weight': 3.8061942196940897, \n",
    "        'min_child_samples': 47, \n",
    "        'subsample': 0.8047498902111587, \n",
    "        'subsample_freq': 5, \n",
    "        'colsample_bytree': 0.20152270171348546,\n",
    "        'num_leaves': 126, \n",
    "        'max_bin': 872, \n",
    "        }\n",
    "    lightgbm_model_optuna = lgb.LGBMClassifier(**lgbm_best_params, random_state=RANDOM_SEED, verbose=-1, n_jobs=-1)\n",
    "    clf = Pipeline(\n",
    "        [\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", lightgbm_model_optuna),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    params = {\n",
    "        'classifier__n_estimators' : 377,\n",
    "        \"classifier__max_depth\":trial.suggest_int('max_depth',3,50),\n",
    "        \"classifier__learning_rate\" : trial.suggest_float('learning_rate',1e-4, 0.25, log=True),\n",
    "        'classifier__reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0),\n",
    "        'classifier__reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0),\n",
    "        \"classifier__min_child_weight\" : trial.suggest_float('min_child_weight', 0.5,4),\n",
    "        \"classifier__min_child_samples\" : trial.suggest_int('min_child_samples',1,100),\n",
    "        \"classifier__subsample\" : trial.suggest_float('subsample', 0.4, 1),\n",
    "        \"classifier__subsample_freq\" : trial.suggest_int('subsample_freq',0,5),\n",
    "        \"classifier__colsample_bytree\" : trial.suggest_float('colsample_bytree',0.2,1),\n",
    "        \"classifier__num_leaves\" : trial.suggest_int('num_leaves', 2, 64*2),\n",
    "        \"classifier__max_bin\" : trial.suggest_int('max_bin', 128, 1024),\n",
    "        #'preprocessor__num__num_imputer__n_neighbors': 44,\n",
    "    }\n",
    "    \n",
    "    clf.set_params(**params)\n",
    "    \n",
    "    cv = abs(cross_val_score(clf, X, y, cv = skf,scoring='neg_log_loss').mean())\n",
    "    return cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective_lightgbm, n_trials=50, timeout=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.4266954252981998\n",
      "Best params: {'max_depth': 49, 'learning_rate': 0.024023967768376772, 'reg_alpha': 0.35728585250443956, 'reg_lambda': 7.807435805826675, 'min_child_weight': 0.95207025899839, 'min_child_samples': 47, 'subsample': 0.45170744695557963, 'subsample_freq': 0, 'colsample_bytree': 0.21692098536099505, 'num_leaves': 75, 'max_bin': 702}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n",
    "lgbm_best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective_xgboost, n_trials=200, timeout=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best score:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n",
    "xgb_best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective_catboost_preprocessor, n_trials=50, timeout=2000)\n",
    "print(\"Best score:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n",
    "xgb_best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgbm_best_params = {'n_estimators': 394, 'max_depth': 24, 'learning_rate': 0.018470603878367985, 'reg_alpha': 0.41378770694989003, 'reg_lambda': 0.032090753198459054, 'min_child_weight': 3.8061942196940897, 'min_child_samples': 47, 'subsample': 0.8047498902111587, 'subsample_freq': 5, 'colsample_bytree': 0.20152270171348546, 'num_leaves': 126, 'max_bin': 872, 'boosting_type': 'gbdt', 'num_imputer_strategy': 'constant', 'cat_imputer_strategy': 'constant'}\n",
    "lgbmmodel_optuna = lgb.LGBMClassifier(**lgbm_best_params, verbose=-1, n_jobs=-1)\n",
    "clf = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", lgbmmodel_optuna),\n",
    "    ]\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_proba = clf.predict_proba(X_val)\n",
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "cr = classification_report(y_val, y_pred, output_dict=True)\n",
    "\n",
    "recall_class_0 = confusion_matrix(y_val, y_pred, normalize=\"true\")[0, 0]\n",
    "recall_class_1 = confusion_matrix(y_val, y_pred, normalize=\"true\")[1, 1]\n",
    "recall_class_2 = confusion_matrix(y_val, y_pred, normalize=\"true\")[2, 2]\n",
    "data.append({\n",
    "    \"model\": \"LightGBM_tuned\", \n",
    "    \"log_loss_score\": log_loss(y_val, y_pred_proba),\n",
    "    \"avg_precision\": cr[\"macro avg\"][\"precision\"],\n",
    "    \"f1_score\": cr[\"macro avg\"][\"f1-score\"],\n",
    "    \"recall_class_0\": recall_class_0,\n",
    "    \"recall_class_1\": recall_class_1,\n",
    "    \"recall_class_2\": recall_class_2,\n",
    "})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb_best_params = {'n_estimators': 468, 'max_depth': 8, 'eta': 0.015470486727229083, 'reg_alpha': 0.20921594374776836, 'reg_lambda': 0.13852230882501773, 'min_child_weight': 0.7650897230059427, 'subsample': 0.35568531774241186, 'sampling_method': 'uniform', 'colsample_bytree': 0.5094764848989666, 'num_leaves': 42, 'max_delta_step': 8, 'scale_pos_weight': 2, 'num_imputer_strategy': 'constant', 'cat_imputer_strategy': 'constant'}\n",
    "model_optuna = xgb.XGBClassifier(\n",
    "        **xgb_best_params, objective=\"multi:softprob\", n_jobs=-1,\n",
    "    )\n",
    "clf = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", model_optuna),\n",
    "    ]\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_proba = clf.predict_proba(X_val)\n",
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "cr = classification_report(y_val, y_pred, output_dict=True)\n",
    "\n",
    "recall_class_0 = confusion_matrix(y_val, y_pred, normalize=\"true\")[0, 0]\n",
    "recall_class_1 = confusion_matrix(y_val, y_pred, normalize=\"true\")[1, 1]\n",
    "recall_class_2 = confusion_matrix(y_val, y_pred, normalize=\"true\")[2, 2]\n",
    "data.append({\n",
    "    \"model\": \"xgboost_tuned\", \n",
    "    \"log_loss_score\": log_loss(y_val, y_pred_proba),\n",
    "    \"avg_precision\": cr[\"macro avg\"][\"precision\"],\n",
    "    \"f1_score\": cr[\"macro avg\"][\"f1-score\"],\n",
    "    \"recall_class_0\": recall_class_0,\n",
    "    \"recall_class_1\": recall_class_1,\n",
    "    \"recall_class_2\": recall_class_2,\n",
    "})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame(data).drop_duplicates().sort_values(by=[\"log_loss_score\", \"recall_class_1\"], ascending=[True, False])\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = models[\"LightGBM_tuned\"]\n",
    "model = lgb.LGBMClassifier(**lgbm_best_params, verbose=-1, n_jobs=5)\n",
    "\n",
    "#model = VotingClassifier(\n",
    "#        estimators=[\n",
    "#            (\"lightgbm_optuna\", lgb.LGBMClassifier(**lgbm_best_params, verbose=-1, n_jobs=5)),\n",
    "#            (\"xgb_optuna\", xgb.XGBClassifier(\n",
    "#                **xgb_best_params, objective=\"multi:softprob\", n_jobs=-1, tree_method=\"hist\", device=\"cuda\"\n",
    "#            )),\n",
    "#        ],\n",
    "#        voting=\"soft\",\n",
    "#        n_jobs=-1,\n",
    "#        verbose=1),\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wiktor/.pyenv/versions/3.10.11/envs/kaggling/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status_C</th>\n",
       "      <th>Status_CL</th>\n",
       "      <th>Status_D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7905</th>\n",
       "      <td>0.622510</td>\n",
       "      <td>0.035168</td>\n",
       "      <td>0.342322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7906</th>\n",
       "      <td>0.666710</td>\n",
       "      <td>0.082269</td>\n",
       "      <td>0.251021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7907</th>\n",
       "      <td>0.166860</td>\n",
       "      <td>0.024842</td>\n",
       "      <td>0.808298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7908</th>\n",
       "      <td>0.922391</td>\n",
       "      <td>0.009413</td>\n",
       "      <td>0.068197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909</th>\n",
       "      <td>0.608441</td>\n",
       "      <td>0.067972</td>\n",
       "      <td>0.323587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13171</th>\n",
       "      <td>0.792300</td>\n",
       "      <td>0.059861</td>\n",
       "      <td>0.147839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13172</th>\n",
       "      <td>0.900534</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.085032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13173</th>\n",
       "      <td>0.868473</td>\n",
       "      <td>0.014163</td>\n",
       "      <td>0.117364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13174</th>\n",
       "      <td>0.939651</td>\n",
       "      <td>0.010690</td>\n",
       "      <td>0.049659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13175</th>\n",
       "      <td>0.529947</td>\n",
       "      <td>0.033862</td>\n",
       "      <td>0.436191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5271 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Status_C  Status_CL  Status_D\n",
       "id                                  \n",
       "7905   0.622510   0.035168  0.342322\n",
       "7906   0.666710   0.082269  0.251021\n",
       "7907   0.166860   0.024842  0.808298\n",
       "7908   0.922391   0.009413  0.068197\n",
       "7909   0.608441   0.067972  0.323587\n",
       "...         ...        ...       ...\n",
       "13171  0.792300   0.059861  0.147839\n",
       "13172  0.900534   0.014434  0.085032\n",
       "13173  0.868473   0.014163  0.117364\n",
       "13174  0.939651   0.010690  0.049659\n",
       "13175  0.529947   0.033862  0.436191\n",
       "\n",
       "[5271 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IN_KAGGLE = False\n",
    "\n",
    "kaggle_folder = \"/kaggle/input/\"\n",
    "local_folder = \"./data/\"\n",
    "train_df = pd.read_csv(kaggle_folder if IN_KAGGLE else local_folder + \"playground-series-s3e26/train.csv\", index_col=\"id\")\n",
    "test_df = pd.read_csv(kaggle_folder if IN_KAGGLE else local_folder  + \"playground-series-s3e26/test.csv\", index_col=\"id\")\n",
    "original_df = pd.read_csv(kaggle_folder if IN_KAGGLE else local_folder  + \"cirrhosis-prediction-dataset/cirrhosis.csv\", index_col=\"ID\")\n",
    "\n",
    "categorical_features = [\"Drug\", \"Sex\", \"Ascites\", \"Hepatomegaly\", \"Spiders\", \"Edema\", \"Stage\"]\n",
    "numerical_features = [\"N_Days\", \"Age\", \"Bilirubin\", \"Cholesterol\", \"Albumin\", \"Copper\", \"Alk_Phos\", \"SGOT\", \"Tryglicerides\", \"Platelets\", \"Prothrombin\"]\n",
    "\n",
    "#categorical_features += [\"generated\"]\n",
    "#original_df['generated'] = 0\n",
    "#train_df['generated'] = 1\n",
    "#test_df['generated'] = 1\n",
    "train_df = pd.concat([train_df, original_df], axis=0)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "target_column = \"Status\"\n",
    "\n",
    "train_df, new_cat, new_num = num_features_2(train_df)\n",
    "train_df = base_feature_engineering(train_df)\n",
    "\n",
    "categorical_features += new_cat\n",
    "numerical_features += new_num\n",
    "\n",
    "test_df, _, _ = num_features_2(test_df)\n",
    "test_df = base_feature_engineering(test_df)\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "X_train = train_df.drop(columns=target_column)\n",
    "y_train = le.fit_transform(train_df[target_column])\n",
    "\n",
    "X_test = test_df\n",
    "\n",
    "\n",
    "num_imputer = SimpleImputer(strategy=\"constant\", add_indicator=True)\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"MISSING\", add_indicator=True)\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    [\n",
    "        (\"num_imputer\", num_imputer),\n",
    "        (\"standard scaler\", StandardScaler()),\n",
    "        #(\"power_transformer\", PowerTransformer()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    [\n",
    "        (\"cast as str\", FunctionTransformer(lambda x: x.astype(str), validate=False)),\n",
    "        (\"cat_imputer\", cat_imputer),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", drop=\"if_binary\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numerical_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf = pipeline\n",
    "#clf = clone_model(pipeline)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict_proba(X_test)\n",
    "\n",
    "submission_df = pd.DataFrame(y_pred, index=X_test.index, columns=[f\"Status_{target}\" for target in le.classes_])\n",
    "submission_df.to_csv(\"./submission.csv\")\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
