{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive approach random_forest + optuna - holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'default_xgboost_with_holidays_seasonality_features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Improve Your Coding</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Train More LLMs</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Win Friends and Influence People</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Win More Kaggle Competitions</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Write Better</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Store</td>\n",
       "      <td>Using LLMs to Improve Your Coding</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Store</td>\n",
       "      <td>Using LLMs to Train More LLMs</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Store</td>\n",
       "      <td>Using LLMs to Win Friends and Influence People</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Store</td>\n",
       "      <td>Using LLMs to Win More Kaggle Competitions</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Store</td>\n",
       "      <td>Using LLMs to Write Better</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    country         store  \\\n",
       "0  2017-01-01  Argentina  Kaggle Learn   \n",
       "1  2017-01-01  Argentina  Kaggle Learn   \n",
       "2  2017-01-01  Argentina  Kaggle Learn   \n",
       "3  2017-01-01  Argentina  Kaggle Learn   \n",
       "4  2017-01-01  Argentina  Kaggle Learn   \n",
       "5  2017-01-01  Argentina  Kaggle Store   \n",
       "6  2017-01-01  Argentina  Kaggle Store   \n",
       "7  2017-01-01  Argentina  Kaggle Store   \n",
       "8  2017-01-01  Argentina  Kaggle Store   \n",
       "9  2017-01-01  Argentina  Kaggle Store   \n",
       "\n",
       "                                          product  num_sold  \n",
       "0               Using LLMs to Improve Your Coding        63  \n",
       "1                   Using LLMs to Train More LLMs        66  \n",
       "2  Using LLMs to Win Friends and Influence People         9  \n",
       "3      Using LLMs to Win More Kaggle Competitions        59  \n",
       "4                      Using LLMs to Write Better        49  \n",
       "5               Using LLMs to Improve Your Coding        88  \n",
       "6                   Using LLMs to Train More LLMs        98  \n",
       "7  Using LLMs to Win Friends and Influence People        14  \n",
       "8      Using LLMs to Win More Kaggle Competitions        83  \n",
       "9                      Using LLMs to Write Better        69  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data_path = \"./data/\"\n",
    "df_train = pd.read_csv(data_path + \"train.csv\")\n",
    "df_test = pd.read_csv(data_path + \"test.csv\")\n",
    "\n",
    "# drop id\n",
    "df_train.drop('id', axis=1, inplace=True)\n",
    "\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_sold</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>week_number</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>Argentina_holiday</th>\n",
       "      <th>Canada_holiday</th>\n",
       "      <th>Estonia_holiday</th>\n",
       "      <th>...</th>\n",
       "      <th>country_Japan</th>\n",
       "      <th>country_Spain</th>\n",
       "      <th>store_Kagglazon</th>\n",
       "      <th>store_Kaggle Learn</th>\n",
       "      <th>store_Kaggle Store</th>\n",
       "      <th>product_Using LLMs to Improve Your Coding</th>\n",
       "      <th>product_Using LLMs to Train More LLMs</th>\n",
       "      <th>product_Using LLMs to Win Friends and Influence People</th>\n",
       "      <th>product_Using LLMs to Win More Kaggle Competitions</th>\n",
       "      <th>product_Using LLMs to Write Better</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_sold  year  month  day  week_number  dayofweek  dayofmonth  \\\n",
       "0        63  2017      1    1           52          6           1   \n",
       "1        66  2017      1    1           52          6           1   \n",
       "2         9  2017      1    1           52          6           1   \n",
       "3        59  2017      1    1           52          6           1   \n",
       "4        49  2017      1    1           52          6           1   \n",
       "\n",
       "   Argentina_holiday  Canada_holiday  Estonia_holiday  ...  country_Japan  \\\n",
       "0               True           False            False  ...          False   \n",
       "1               True           False            False  ...          False   \n",
       "2               True           False            False  ...          False   \n",
       "3               True           False            False  ...          False   \n",
       "4               True           False            False  ...          False   \n",
       "\n",
       "   country_Spain  store_Kagglazon  store_Kaggle Learn  store_Kaggle Store  \\\n",
       "0          False            False                True               False   \n",
       "1          False            False                True               False   \n",
       "2          False            False                True               False   \n",
       "3          False            False                True               False   \n",
       "4          False            False                True               False   \n",
       "\n",
       "   product_Using LLMs to Improve Your Coding  \\\n",
       "0                                       True   \n",
       "1                                      False   \n",
       "2                                      False   \n",
       "3                                      False   \n",
       "4                                      False   \n",
       "\n",
       "   product_Using LLMs to Train More LLMs  \\\n",
       "0                                  False   \n",
       "1                                   True   \n",
       "2                                  False   \n",
       "3                                  False   \n",
       "4                                  False   \n",
       "\n",
       "   product_Using LLMs to Win Friends and Influence People  \\\n",
       "0                                              False        \n",
       "1                                              False        \n",
       "2                                               True        \n",
       "3                                              False        \n",
       "4                                              False        \n",
       "\n",
       "   product_Using LLMs to Win More Kaggle Competitions  \\\n",
       "0                                              False    \n",
       "1                                              False    \n",
       "2                                              False    \n",
       "3                                               True    \n",
       "4                                              False    \n",
       "\n",
       "   product_Using LLMs to Write Better  \n",
       "0                               False  \n",
       "1                               False  \n",
       "2                               False  \n",
       "3                               False  \n",
       "4                                True  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import holidays\n",
    "\n",
    "def transform_date(df):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    return df\n",
    "\n",
    "def create_features(df):\n",
    "    # split date into year, month, day\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "\n",
    "    # week number\n",
    "    df['week_number'] = df['date'].dt.isocalendar().week.astype(int)\n",
    "    \n",
    "    # day of week\n",
    "    df['dayofweek'] = df['date'].dt.dayofweek\n",
    "    df['dayofmonth'] = df['date'].dt.day\n",
    "    # weekend\n",
    "    #df['weekend'] = (df['date'].dt.weekday >=4).astype(int)\n",
    "\n",
    "    # drop date\n",
    "    #df = df.drop('date', axis=1)\n",
    "\n",
    "    # one-hot encoding of 'country', 'store', 'product' columns\n",
    "    #df_train = pd.get_dummies(df_train, columns=['country', 'store', 'product'])\n",
    "\n",
    "\n",
    "    df['country'] = df['country'].astype('category')\n",
    "    df['store'] = df['store'].astype('category')\n",
    "    df['product'] = df['product'].astype('category')\n",
    "\n",
    "    return df\n",
    "\n",
    "def encode_cat_variables(df):\n",
    "    categorical_features = [\"country\", \"store\", \"product\"]\n",
    "    df = pd.get_dummies(df, columns=categorical_features)\n",
    "    return df\n",
    "\n",
    "def add_holidays(df):\n",
    "    # courtesy of kacperrabczewski in https://www.kaggle.com/code/kacperrabczewski/last-minute-forecasting#Modeling-%F0%9F%AA%84\n",
    "\n",
    "    years_list = [2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
    "\n",
    "    Argentina_holidays = holidays.CountryHoliday('AR', years=years_list)\n",
    "    Canada_holidays = holidays.CountryHoliday('CA', years=years_list)\n",
    "    Estonia_holidays = holidays.CountryHoliday('EE', years=years_list)\n",
    "    Japan_holidays = holidays.CountryHoliday('JP', years=years_list)\n",
    "    Spain_holidays = holidays.CountryHoliday('ES', years=years_list)\n",
    "    \n",
    "    # Create Holiday Column \n",
    "    df['Argentina_holiday'] = df.loc[df['country'] == 'Argentina', 'date'].apply(lambda d: True if d in Argentina_holidays else False)\n",
    "    df['Canada_holiday'] = df.loc[df['country'] == 'Canada', 'date'].apply(lambda d: True if d in Canada_holidays else False)\n",
    "    df['Estonia_holiday'] = df.loc[df['country'] == 'Estonia', 'date'].apply(lambda d: True if d in Estonia_holidays else False)\n",
    "    df['Japan_holiday'] = df.loc[df['country'] == 'Japan', 'date'].apply(lambda d: True if d in Japan_holidays else False)\n",
    "    df['Spain_holiday'] = df.loc[df['country'] == 'Spain', 'date'].apply(lambda d: True if d in Spain_holidays else False)\n",
    "\n",
    "    df['Argentina_holiday'] = df['Argentina_holiday'].fillna(False)\n",
    "    df['Canada_holiday'] = df['Canada_holiday'].fillna(False)\n",
    "    df['Estonia_holiday'] = df['Estonia_holiday'].fillna(False)\n",
    "    df['Japan_holiday'] = df['Japan_holiday'].fillna(False)\n",
    "    df['Spain_holiday'] = df['Spain_holiday'].fillna(False)\n",
    "\n",
    "    df = df.drop('date', axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def seasonality_features(df):\n",
    "    \n",
    "    # getting seasonal patterns\n",
    "    df['month_sin'] = np.sin(2*np.pi*df.month/12)\n",
    "    df['month_cos'] = np.cos(2*np.pi*df.month/12)\n",
    "    df['day_sin'] = np.sin(2*np.pi*df.dayofmonth/31)\n",
    "    df['day_cos'] = np.cos(2*np.pi*df.dayofmonth/31)\n",
    "    return df\n",
    "\n",
    "df_train_0 = transform_date(df_train)\n",
    "df_train_0 = create_features(df_train_0)\n",
    "df_train_0 = add_holidays(df_train_0)\n",
    "df_train_0 = seasonality_features(df_train_0)\n",
    "df_train_0 = encode_cat_variables(df_train_0)\n",
    "df_train_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['year',\n",
       " 'month',\n",
       " 'day',\n",
       " 'week_number',\n",
       " 'dayofweek',\n",
       " 'dayofmonth',\n",
       " 'Argentina_holiday',\n",
       " 'Canada_holiday',\n",
       " 'Estonia_holiday',\n",
       " 'Japan_holiday',\n",
       " 'Spain_holiday',\n",
       " 'month_sin',\n",
       " 'month_cos',\n",
       " 'day_sin',\n",
       " 'day_cos',\n",
       " 'country_Argentina',\n",
       " 'country_Canada',\n",
       " 'country_Estonia',\n",
       " 'country_Japan',\n",
       " 'country_Spain',\n",
       " 'store_Kagglazon',\n",
       " 'store_Kaggle Learn',\n",
       " 'store_Kaggle Store',\n",
       " 'product_Using LLMs to Improve Your Coding',\n",
       " 'product_Using LLMs to Train More LLMs',\n",
       " 'product_Using LLMs to Win Friends and Influence People',\n",
       " 'product_Using LLMs to Win More Kaggle Competitions',\n",
       " 'product_Using LLMs to Write Better']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_features = df_train_0.columns.tolist()\n",
    "model_features.remove(\"num_sold\")\n",
    "model_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136950 entries, 0 to 136949\n",
      "Data columns (total 29 columns):\n",
      " #   Column                                                  Non-Null Count   Dtype  \n",
      "---  ------                                                  --------------   -----  \n",
      " 0   num_sold                                                136950 non-null  int64  \n",
      " 1   year                                                    136950 non-null  int32  \n",
      " 2   month                                                   136950 non-null  int32  \n",
      " 3   day                                                     136950 non-null  int32  \n",
      " 4   week_number                                             136950 non-null  int32  \n",
      " 5   dayofweek                                               136950 non-null  int32  \n",
      " 6   dayofmonth                                              136950 non-null  int32  \n",
      " 7   Argentina_holiday                                       136950 non-null  bool   \n",
      " 8   Canada_holiday                                          136950 non-null  bool   \n",
      " 9   Estonia_holiday                                         136950 non-null  bool   \n",
      " 10  Japan_holiday                                           136950 non-null  bool   \n",
      " 11  Spain_holiday                                           136950 non-null  bool   \n",
      " 12  month_sin                                               136950 non-null  float64\n",
      " 13  month_cos                                               136950 non-null  float64\n",
      " 14  day_sin                                                 136950 non-null  float64\n",
      " 15  day_cos                                                 136950 non-null  float64\n",
      " 16  country_Argentina                                       136950 non-null  bool   \n",
      " 17  country_Canada                                          136950 non-null  bool   \n",
      " 18  country_Estonia                                         136950 non-null  bool   \n",
      " 19  country_Japan                                           136950 non-null  bool   \n",
      " 20  country_Spain                                           136950 non-null  bool   \n",
      " 21  store_Kagglazon                                         136950 non-null  bool   \n",
      " 22  store_Kaggle Learn                                      136950 non-null  bool   \n",
      " 23  store_Kaggle Store                                      136950 non-null  bool   \n",
      " 24  product_Using LLMs to Improve Your Coding               136950 non-null  bool   \n",
      " 25  product_Using LLMs to Train More LLMs                   136950 non-null  bool   \n",
      " 26  product_Using LLMs to Win Friends and Influence People  136950 non-null  bool   \n",
      " 27  product_Using LLMs to Win More Kaggle Competitions      136950 non-null  bool   \n",
      " 28  product_Using LLMs to Write Better                      136950 non-null  bool   \n",
      "dtypes: bool(18), float64(4), int32(6), int64(1)\n",
      "memory usage: 10.7 MB\n"
     ]
    }
   ],
   "source": [
    "df_train_0.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function by which submissions are scored is SMAPE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMAPE(A, F):\n",
    "    return 100/len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-29 18:21:05,210] A new study created in memory with name: no-name-71e6d43b-cbb5-4f8e-b388-a54f4027cebb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-29 18:22:26,576] Trial 0 finished with value: 11.049948987550778 and parameters: {'n_estimators': 796, 'max_depth': 15}. Best is trial 0 with value: 11.049948987550778.\n",
      "[I 2023-07-29 18:23:24,821] Trial 1 finished with value: 10.413084585617982 and parameters: {'n_estimators': 858, 'max_depth': 12}. Best is trial 1 with value: 10.413084585617982.\n",
      "[I 2023-07-29 18:23:29,529] Trial 2 finished with value: 14.329526419456538 and parameters: {'n_estimators': 893, 'max_depth': 5}. Best is trial 1 with value: 10.413084585617982.\n",
      "[I 2023-07-29 18:24:48,407] Trial 3 finished with value: 11.180639259363272 and parameters: {'n_estimators': 944, 'max_depth': 13}. Best is trial 1 with value: 10.413084585617982.\n",
      "[I 2023-07-29 18:26:07,785] Trial 4 finished with value: 11.049948987550778 and parameters: {'n_estimators': 614, 'max_depth': 15}. Best is trial 1 with value: 10.413084585617982.\n",
      "[I 2023-07-29 18:26:16,580] Trial 5 finished with value: 11.670464870086745 and parameters: {'n_estimators': 514, 'max_depth': 9}. Best is trial 1 with value: 10.413084585617982.\n",
      "[I 2023-07-29 18:27:36,391] Trial 6 finished with value: 11.351052444551541 and parameters: {'n_estimators': 714, 'max_depth': 14}. Best is trial 1 with value: 10.413084585617982.\n",
      "[I 2023-07-29 18:27:41,032] Trial 7 finished with value: 10.616358988335652 and parameters: {'n_estimators': 164, 'max_depth': 10}. Best is trial 1 with value: 10.413084585617982.\n",
      "[I 2023-07-29 18:29:03,149] Trial 8 finished with value: 11.049948987550778 and parameters: {'n_estimators': 702, 'max_depth': 15}. Best is trial 1 with value: 10.413084585617982.\n",
      "[I 2023-07-29 18:29:04,888] Trial 9 finished with value: 16.78797670490106 and parameters: {'n_estimators': 250, 'max_depth': 4}. Best is trial 1 with value: 10.413084585617982.\n",
      "[I 2023-07-29 18:29:23,080] Trial 10 finished with value: 10.954499241757809 and parameters: {'n_estimators': 431, 'max_depth': 11}. Best is trial 1 with value: 10.413084585617982.\n",
      "[I 2023-07-29 18:29:26,573] Trial 11 finished with value: 11.503097462927723 and parameters: {'n_estimators': 180, 'max_depth': 9}. Best is trial 1 with value: 10.413084585617982.\n",
      "[I 2023-07-29 18:29:42,442] Trial 12 finished with value: 10.938664909352799 and parameters: {'n_estimators': 381, 'max_depth': 11}. Best is trial 1 with value: 10.413084585617982.\n",
      "[I 2023-07-29 18:29:44,164] Trial 13 finished with value: 13.035532478001615 and parameters: {'n_estimators': 122, 'max_depth': 7}. Best is trial 1 with value: 10.413084585617982.\n",
      "[I 2023-07-29 18:29:57,263] Trial 14 finished with value: 10.914259322466997 and parameters: {'n_estimators': 306, 'max_depth': 11}. Best is trial 1 with value: 10.413084585617982.\n",
      "[I 2023-07-29 18:31:04,049] Trial 15 finished with value: 10.413934967084025 and parameters: {'n_estimators': 994, 'max_depth': 12}. Best is trial 1 with value: 10.413084585617982.\n",
      "[I 2023-07-29 18:32:21,589] Trial 16 finished with value: 11.180639259363272 and parameters: {'n_estimators': 1000, 'max_depth': 13}. Best is trial 1 with value: 10.413084585617982.\n",
      "[I 2023-07-29 18:33:20,554] Trial 17 finished with value: 10.413369099413483 and parameters: {'n_estimators': 842, 'max_depth': 12}. Best is trial 1 with value: 10.413084585617982.\n",
      "[I 2023-07-29 18:33:29,458] Trial 18 finished with value: 13.265860408053125 and parameters: {'n_estimators': 839, 'max_depth': 8}. Best is trial 1 with value: 10.413084585617982.\n",
      "[I 2023-07-29 18:34:46,953] Trial 19 finished with value: 11.180639259363272 and parameters: {'n_estimators': 742, 'max_depth': 13}. Best is trial 1 with value: 10.413084585617982.\n",
      "[I 2023-07-29 18:34:52,021] Trial 20 finished with value: 14.834857840834488 and parameters: {'n_estimators': 610, 'max_depth': 7}. Best is trial 1 with value: 10.413084585617982.\n",
      "[I 2023-07-29 18:35:51,359] Trial 21 finished with value: 10.411863595096298 and parameters: {'n_estimators': 881, 'max_depth': 12}. Best is trial 21 with value: 10.411863595096298.\n",
      "[I 2023-07-29 18:36:52,267] Trial 22 finished with value: 10.412735961656098 and parameters: {'n_estimators': 867, 'max_depth': 12}. Best is trial 21 with value: 10.411863595096298.\n",
      "[I 2023-07-29 18:37:52,524] Trial 23 finished with value: 10.410939326177973 and parameters: {'n_estimators': 913, 'max_depth': 12}. Best is trial 23 with value: 10.410939326177973.\n",
      "[I 2023-07-29 18:38:13,339] Trial 24 finished with value: 10.994522513312097 and parameters: {'n_estimators': 918, 'max_depth': 10}. Best is trial 23 with value: 10.410939326177973.\n",
      "[I 2023-07-29 18:39:25,936] Trial 25 finished with value: 11.351052444551541 and parameters: {'n_estimators': 790, 'max_depth': 14}. Best is trial 23 with value: 10.410939326177973.\n",
      "[I 2023-07-29 18:39:41,156] Trial 26 finished with value: 10.918393359300266 and parameters: {'n_estimators': 669, 'max_depth': 10}. Best is trial 23 with value: 10.410939326177973.\n",
      "[I 2023-07-29 18:40:53,152] Trial 27 finished with value: 11.351052444551541 and parameters: {'n_estimators': 947, 'max_depth': 14}. Best is trial 23 with value: 10.410939326177973.\n",
      "[I 2023-07-29 18:41:44,562] Trial 28 finished with value: 10.409780215011315 and parameters: {'n_estimators': 810, 'max_depth': 12}. Best is trial 28 with value: 10.409780215011315.\n",
      "[I 2023-07-29 18:41:56,231] Trial 29 finished with value: 11.790966617779436 and parameters: {'n_estimators': 782, 'max_depth': 9}. Best is trial 28 with value: 10.409780215011315.\n",
      "[I 2023-07-29 18:42:49,523] Trial 30 finished with value: 11.177972123681423 and parameters: {'n_estimators': 514, 'max_depth': 13}. Best is trial 28 with value: 10.409780215011315.\n",
      "[I 2023-07-29 18:43:44,861] Trial 31 finished with value: 10.412927388812024 and parameters: {'n_estimators': 876, 'max_depth': 12}. Best is trial 28 with value: 10.409780215011315.\n",
      "[I 2023-07-29 18:44:15,640] Trial 32 finished with value: 10.99705138405979 and parameters: {'n_estimators': 801, 'max_depth': 11}. Best is trial 28 with value: 10.409780215011315.\n",
      "[I 2023-07-29 18:45:12,179] Trial 33 finished with value: 10.411436109379272 and parameters: {'n_estimators': 890, 'max_depth': 12}. Best is trial 28 with value: 10.409780215011315.\n",
      "[I 2023-07-29 18:46:24,934] Trial 34 finished with value: 11.180639259363272 and parameters: {'n_estimators': 934, 'max_depth': 13}. Best is trial 28 with value: 10.409780215011315.\n",
      "[I 2023-07-29 18:47:37,878] Trial 35 finished with value: 11.351052444551541 and parameters: {'n_estimators': 772, 'max_depth': 14}. Best is trial 28 with value: 10.409780215011315.\n",
      "[I 2023-07-29 18:47:58,407] Trial 36 finished with value: 10.994468355898269 and parameters: {'n_estimators': 906, 'max_depth': 10}. Best is trial 28 with value: 10.409780215011315.\n",
      "[I 2023-07-29 18:49:15,245] Trial 37 finished with value: 11.049948987550778 and parameters: {'n_estimators': 826, 'max_depth': 15}. Best is trial 28 with value: 10.409780215011315.\n",
      "[I 2023-07-29 18:49:51,879] Trial 38 finished with value: 11.019964527255787 and parameters: {'n_estimators': 969, 'max_depth': 11}. Best is trial 28 with value: 10.409780215011315.\n",
      "[I 2023-07-29 18:49:58,612] Trial 39 finished with value: 13.238396324989651 and parameters: {'n_estimators': 610, 'max_depth': 8}. Best is trial 28 with value: 10.409780215011315.\n",
      "[I 2023-07-29 18:50:42,553] Trial 40 finished with value: 10.41062532085466 and parameters: {'n_estimators': 700, 'max_depth': 12}. Best is trial 28 with value: 10.409780215011315.\n",
      "[I 2023-07-29 18:51:25,966] Trial 41 finished with value: 10.412893536346255 and parameters: {'n_estimators': 688, 'max_depth': 12}. Best is trial 28 with value: 10.409780215011315.\n",
      "[I 2023-07-29 18:52:37,361] Trial 42 finished with value: 11.180639259363272 and parameters: {'n_estimators': 741, 'max_depth': 13}. Best is trial 28 with value: 10.409780215011315.\n",
      "[W 2023-07-29 18:53:02,480] Trial 43 failed with parameters: {'n_estimators': 882, 'max_depth': 12} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\Wiktor\\AppData\\Local\\Temp\\ipykernel_1564\\2074422212.py\", line 25, in objective\n",
      "    model.fit(\n",
      "  File \"c:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "KeyboardInterrupt\n",
      "[W 2023-07-29 18:53:02,481] Trial 43 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 35\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[39mreturn\u001b[39;00m SMAPE(y_val, np\u001b[39m.\u001b[39mround(model\u001b[39m.\u001b[39mpredict(X_val)))\n\u001b[0;32m     34\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n\u001b[0;32m     37\u001b[0m best_hyperparams \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_params\n",
      "File \u001b[1;32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\study.py:443\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    340\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    349\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    350\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \n\u001b[0;32m    352\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 443\u001b[0m     _optimize(\n\u001b[0;32m    444\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    445\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    446\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    447\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    448\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    449\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    450\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    451\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    452\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    453\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[20], line 25\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mobjective\u001b[39m(trial):\n\u001b[0;32m     19\u001b[0m     model\u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBRegressor(\n\u001b[0;32m     20\u001b[0m         tree_method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpu_hist\u001b[39m\u001b[39m\"\u001b[39m, enable_categorical\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     21\u001b[0m         n_estimators\u001b[39m=\u001b[39mtrial\u001b[39m.\u001b[39msuggest_int(\u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m100\u001b[39m, \u001b[39m1000\u001b[39m),\n\u001b[0;32m     22\u001b[0m         max_depth\u001b[39m=\u001b[39mtrial\u001b[39m.\u001b[39msuggest_int(\u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m15\u001b[39m),\n\u001b[0;32m     23\u001b[0m     )\n\u001b[1;32m---> 25\u001b[0m     model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     26\u001b[0m         X_train, y_train,\n\u001b[0;32m     27\u001b[0m         eval_set\u001b[39m=\u001b[39;49m[( X_train, y_train), ( X_val, y_val)],\n\u001b[0;32m     28\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m     29\u001b[0m     )\n\u001b[0;32m     31\u001b[0m     \u001b[39mreturn\u001b[39;00m SMAPE(y_val, np\u001b[39m.\u001b[39mround(model\u001b[39m.\u001b[39mpredict(X_val)))\n",
      "File \u001b[1;32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py:1025\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1014\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m (\n\u001b[0;32m   1017\u001b[0m     model,\n\u001b[0;32m   1018\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1024\u001b[0m )\n\u001b[1;32m-> 1025\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m   1026\u001b[0m     params,\n\u001b[0;32m   1027\u001b[0m     train_dmatrix,\n\u001b[0;32m   1028\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[0;32m   1029\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[0;32m   1030\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m   1031\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[0;32m   1032\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[0;32m   1033\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[0;32m   1034\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1035\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   1036\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1037\u001b[0m )\n\u001b[0;32m   1039\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1040\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[0;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[0;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[0;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[0;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "\n",
    "train_index, val_index = [ x for x in TimeSeriesSplit(n_splits=5).split(df_train_0) ][-1]\n",
    "\n",
    "X_train = df_train_0.iloc[train_index][model_features]\n",
    "y_train = df_train_0.iloc[train_index]['num_sold']\n",
    "\n",
    "X_val = df_train_0.iloc[val_index][model_features]\n",
    "y_val = df_train_0.iloc[val_index]['num_sold']\n",
    "\n",
    "cat_features_indices = np.where((X_train.dtypes == \"category\") | (X_train.dtypes == \"object\"))[0]\n",
    "cat_features_indices\n",
    "\n",
    "def objective(trial):\n",
    "    model= xgb.XGBRegressor(\n",
    "        tree_method=\"gpu_hist\", enable_categorical=True,\n",
    "        n_estimators=trial.suggest_int('n_estimators', 100, 1000),\n",
    "        max_depth=trial.suggest_int('max_depth', 3, 15),\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[( X_train, y_train), ( X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    return SMAPE(y_val, np.round(model.predict(X_val)))\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_hyperparams = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 810, 'max_depth': 12}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validated results:\n",
      "SMAPE: [13.85144387499987, 9.271005920021572, 11.780750994602853, 18.984407960786655, 14.560680492771942]\n",
      "R2: [0.9631319421575548, 0.9871692628195864, 0.9708657124348878, 0.9462368588893403, 0.9746859805294681]\n",
      "MSE: [1299.9037897042717, 448.10865279299014, 916.5842716319825, 1697.9399342825848, 992.0135377875137]\n",
      "Mean results:\n",
      "SMAPE: 13.6897\n",
      "R2: 0.9684\n",
      "MSE: 1070.9100\n"
     ]
    }
   ],
   "source": [
    "# split into train and validation\n",
    "\n",
    "results_smape = []\n",
    "results_r2 = []\n",
    "results_mse = []\n",
    "\n",
    "\n",
    "N_SPLITS = 5\n",
    "\n",
    "for train_index, val_index in TimeSeriesSplit(n_splits=N_SPLITS).split(df_train_0):\n",
    "    X_train = df_train_0.iloc[train_index][model_features]\n",
    "    y_train = df_train_0.iloc[train_index]['num_sold']\n",
    "\n",
    "    X_val = df_train_0.iloc[val_index]\n",
    "    y_val = df_train_0.iloc[val_index]['num_sold']\n",
    "\n",
    "    model = xgb.XGBRegressor(tree_method=\"gpu_hist\", enable_categorical=True)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        #eval_set=[( X_train, y_train), ( X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # evaluate on validation set\n",
    "    y_pred = np.round(model.predict(X_val[model_features]))\n",
    "\n",
    "    smape = SMAPE(y_val, y_pred)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "\n",
    "    results_smape.append(smape)\n",
    "    results_r2.append(r2)\n",
    "    results_mse.append(mse)\n",
    "    del model\n",
    "\n",
    "print(\"Cross validated results:\")\n",
    "\n",
    "print(\"SMAPE: %s\" % results_smape)\n",
    "print(\"R2: %s\" % results_r2)\n",
    "print(\"MSE: %s\" % results_mse)\n",
    "\n",
    "print(\"Mean results:\")\n",
    "print(\"SMAPE: %.4f\" % np.mean(results_smape))\n",
    "print(\"R2: %.4f\" % np.mean(results_r2))\n",
    "print(\"MSE: %.4f\" % np.mean(results_mse))\n",
    "\n",
    "\n",
    "# add a row with results to csv file leaderboard.csv\n",
    "\n",
    "row = [model_name, np.mean(results_smape), np.mean(results_r2), np.mean(results_mse)]\n",
    "with open('leaderboard.csv', 'a') as fd:\n",
    "    import csv\n",
    "    fd.write('\\n')\n",
    "    writer = csv.writer(fd, delimiter=',', lineterminator=';\\n')\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# train and predict for submission\n",
    "\n",
    "df_train = pd.read_csv(data_path + \"train.csv\")\n",
    "df_train['date'] = pd.to_datetime(df_train['date'])\n",
    "\n",
    "df_train_0 = transform_date(df_train)\n",
    "df_train_0 = create_features(df_train_0)\n",
    "df_train_0 = add_holidays(df_train_0)\n",
    "df_train_0 = seasonality_features(df_train_0)\n",
    "df_train_0 = encode_cat_variables(df_train_0)\n",
    "\n",
    "X_train = df_train_0.drop('num_sold', axis=1)\n",
    "y_train = df_train_0['num_sold']\n",
    "\n",
    "\n",
    "model = xgb.XGBRegressor(tree_method=\"gpu_hist\", enable_categorical=True)\n",
    "model.fit(\n",
    "    X_train[model_features], y_train,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "df_val = X_val.copy()\n",
    "df_val['actual'] = y_val\n",
    "df_val['prediction'] = model.predict(df_val[model_features])\n",
    "df_val['prediction'] = df_val['prediction'].astype(int)\n",
    "\n",
    "\n",
    "X_train['date'] = pd.to_datetime(X_train['year'].astype(str) + '-' + X_train['month'].astype(str) + '-' + X_train['day'].astype(str))\n",
    "X_val['date'] = pd.to_datetime(X_val['year'].astype(str) + '-' + X_val['month'].astype(str) + '-' + X_val['day'].astype(str))\n",
    "df_val['date'] = pd.to_datetime(df_val['year'].astype(str) + '-' + df_val['month'].astype(str) + '-' + df_val['day'].astype(str))\n",
    "\n",
    "# sort by date\n",
    "X_train.sort_values(by='date', inplace=True)\n",
    "X_val.sort_values(by='date', inplace=True)\n",
    "\n",
    "# plot 'num_sold' vs 'date'\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "ax.plot(X_train['date'], y_train, label='train', color='lightblue')\n",
    "ax.plot(X_val['date'], y_val, label='validation', color='pink')\n",
    "ax.plot(df_val['date'], df_val['prediction'], label='prediction', color='crimson')\n",
    "\n",
    "# x axis show only from 2021 onwards\n",
    "ax.set_xlim([datetime.date(2021, 1, 1), df_val['date'].max()])\n",
    "ax.set_xlabel('date')\n",
    "ax.set_ylabel('num_sold')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>week_number</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>Argentina_holiday</th>\n",
       "      <th>Canada_holiday</th>\n",
       "      <th>Estonia_holiday</th>\n",
       "      <th>Japan_holiday</th>\n",
       "      <th>Spain_holiday</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136950</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Improve Your Coding</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136951</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Train More LLMs</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136952</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Win Friends and Influence People</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136953</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Win More Kaggle Competitions</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136954</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Write Better</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27370</th>\n",
       "      <td>164320</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Kagglazon</td>\n",
       "      <td>Using LLMs to Improve Your Coding</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27371</th>\n",
       "      <td>164321</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Kagglazon</td>\n",
       "      <td>Using LLMs to Train More LLMs</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27372</th>\n",
       "      <td>164322</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Kagglazon</td>\n",
       "      <td>Using LLMs to Win Friends and Influence People</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27373</th>\n",
       "      <td>164323</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Kagglazon</td>\n",
       "      <td>Using LLMs to Win More Kaggle Competitions</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27374</th>\n",
       "      <td>164324</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Kagglazon</td>\n",
       "      <td>Using LLMs to Write Better</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27375 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id       date    country         store  \\\n",
       "0      136950 2022-01-01  Argentina  Kaggle Learn   \n",
       "1      136951 2022-01-01  Argentina  Kaggle Learn   \n",
       "2      136952 2022-01-01  Argentina  Kaggle Learn   \n",
       "3      136953 2022-01-01  Argentina  Kaggle Learn   \n",
       "4      136954 2022-01-01  Argentina  Kaggle Learn   \n",
       "...       ...        ...        ...           ...   \n",
       "27370  164320 2022-12-31      Spain     Kagglazon   \n",
       "27371  164321 2022-12-31      Spain     Kagglazon   \n",
       "27372  164322 2022-12-31      Spain     Kagglazon   \n",
       "27373  164323 2022-12-31      Spain     Kagglazon   \n",
       "27374  164324 2022-12-31      Spain     Kagglazon   \n",
       "\n",
       "                                              product  year  month  day  \\\n",
       "0                   Using LLMs to Improve Your Coding  2022      1    1   \n",
       "1                       Using LLMs to Train More LLMs  2022      1    1   \n",
       "2      Using LLMs to Win Friends and Influence People  2022      1    1   \n",
       "3          Using LLMs to Win More Kaggle Competitions  2022      1    1   \n",
       "4                          Using LLMs to Write Better  2022      1    1   \n",
       "...                                               ...   ...    ...  ...   \n",
       "27370               Using LLMs to Improve Your Coding  2022     12   31   \n",
       "27371                   Using LLMs to Train More LLMs  2022     12   31   \n",
       "27372  Using LLMs to Win Friends and Influence People  2022     12   31   \n",
       "27373      Using LLMs to Win More Kaggle Competitions  2022     12   31   \n",
       "27374                      Using LLMs to Write Better  2022     12   31   \n",
       "\n",
       "       week_number  dayofweek  dayofmonth  Argentina_holiday  Canada_holiday  \\\n",
       "0               52          5           1               True           False   \n",
       "1               52          5           1               True           False   \n",
       "2               52          5           1               True           False   \n",
       "3               52          5           1               True           False   \n",
       "4               52          5           1               True           False   \n",
       "...            ...        ...         ...                ...             ...   \n",
       "27370           52          5          31              False           False   \n",
       "27371           52          5          31              False           False   \n",
       "27372           52          5          31              False           False   \n",
       "27373           52          5          31              False           False   \n",
       "27374           52          5          31              False           False   \n",
       "\n",
       "       Estonia_holiday  Japan_holiday  Spain_holiday  prediction  \n",
       "0                False          False          False          36  \n",
       "1                False          False          False          36  \n",
       "2                False          False          False          -1  \n",
       "3                False          False          False          32  \n",
       "4                False          False          False          27  \n",
       "...                ...            ...            ...         ...  \n",
       "27370            False          False          False         747  \n",
       "27371            False          False          False         715  \n",
       "27372            False          False          False         113  \n",
       "27373            False          False          False         697  \n",
       "27374            False          False          False         557  \n",
       "\n",
       "[27375 rows x 17 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test \n",
    "\n",
    "df_test = pd.read_csv(data_path + \"test.csv\")\n",
    "df_test_0 = transform_date(df_test)\n",
    "df_test_0 = create_features(df_test_0)\n",
    "df_test_0 = add_holidays(df_test_0)\n",
    "df_test_0 = seasonality_features(df_test_0)\n",
    "df_test_0 = encode_cat_variables(df_test_0)\n",
    "\n",
    "# predict for test set\n",
    "df_test['prediction'] = model.predict(df_test_0[model_features])\n",
    "df_test['prediction'] = df_test['prediction'].astype(int)\n",
    "display(df_test)\n",
    "\n",
    "df_test['num_sold'] = df_test['prediction']\n",
    "df_test[['id', 'num_sold']].to_csv(f'{model_name}_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
