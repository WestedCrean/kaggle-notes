{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive approach random_forest + optuna - holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'xgboost_with_holidays'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Improve Your Coding</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Train More LLMs</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Win Friends and Influence People</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Win More Kaggle Competitions</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Learn</td>\n",
       "      <td>Using LLMs to Write Better</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Store</td>\n",
       "      <td>Using LLMs to Improve Your Coding</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Store</td>\n",
       "      <td>Using LLMs to Train More LLMs</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Store</td>\n",
       "      <td>Using LLMs to Win Friends and Influence People</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Store</td>\n",
       "      <td>Using LLMs to Win More Kaggle Competitions</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Kaggle Store</td>\n",
       "      <td>Using LLMs to Write Better</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    country         store  \\\n",
       "0  2017-01-01  Argentina  Kaggle Learn   \n",
       "1  2017-01-01  Argentina  Kaggle Learn   \n",
       "2  2017-01-01  Argentina  Kaggle Learn   \n",
       "3  2017-01-01  Argentina  Kaggle Learn   \n",
       "4  2017-01-01  Argentina  Kaggle Learn   \n",
       "5  2017-01-01  Argentina  Kaggle Store   \n",
       "6  2017-01-01  Argentina  Kaggle Store   \n",
       "7  2017-01-01  Argentina  Kaggle Store   \n",
       "8  2017-01-01  Argentina  Kaggle Store   \n",
       "9  2017-01-01  Argentina  Kaggle Store   \n",
       "\n",
       "                                          product  num_sold  \n",
       "0               Using LLMs to Improve Your Coding        63  \n",
       "1                   Using LLMs to Train More LLMs        66  \n",
       "2  Using LLMs to Win Friends and Influence People         9  \n",
       "3      Using LLMs to Win More Kaggle Competitions        59  \n",
       "4                      Using LLMs to Write Better        49  \n",
       "5               Using LLMs to Improve Your Coding        88  \n",
       "6                   Using LLMs to Train More LLMs        98  \n",
       "7  Using LLMs to Win Friends and Influence People        14  \n",
       "8      Using LLMs to Win More Kaggle Competitions        83  \n",
       "9                      Using LLMs to Write Better        69  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data_path = \"./data/\"\n",
    "df_train = pd.read_csv(data_path + \"train.csv\")\n",
    "df_test = pd.read_csv(data_path + \"test.csv\")\n",
    "\n",
    "# drop id\n",
    "df_train.drop('id', axis=1, inplace=True)\n",
    "\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_sold</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>week_number</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>weekend</th>\n",
       "      <th>Argentina_holiday</th>\n",
       "      <th>Canada_holiday</th>\n",
       "      <th>Estonia_holiday</th>\n",
       "      <th>...</th>\n",
       "      <th>country_Japan</th>\n",
       "      <th>country_Spain</th>\n",
       "      <th>store_Kagglazon</th>\n",
       "      <th>store_Kaggle Learn</th>\n",
       "      <th>store_Kaggle Store</th>\n",
       "      <th>product_Using LLMs to Improve Your Coding</th>\n",
       "      <th>product_Using LLMs to Train More LLMs</th>\n",
       "      <th>product_Using LLMs to Win Friends and Influence People</th>\n",
       "      <th>product_Using LLMs to Win More Kaggle Competitions</th>\n",
       "      <th>product_Using LLMs to Write Better</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_sold  year  month  day  week_number  dayofweek  weekend  \\\n",
       "0        63  2017      1    1           52          6        1   \n",
       "1        66  2017      1    1           52          6        1   \n",
       "2         9  2017      1    1           52          6        1   \n",
       "3        59  2017      1    1           52          6        1   \n",
       "4        49  2017      1    1           52          6        1   \n",
       "\n",
       "   Argentina_holiday  Canada_holiday  Estonia_holiday  ...  country_Japan  \\\n",
       "0               True           False            False  ...          False   \n",
       "1               True           False            False  ...          False   \n",
       "2               True           False            False  ...          False   \n",
       "3               True           False            False  ...          False   \n",
       "4               True           False            False  ...          False   \n",
       "\n",
       "   country_Spain  store_Kagglazon  store_Kaggle Learn  store_Kaggle Store  \\\n",
       "0          False            False                True               False   \n",
       "1          False            False                True               False   \n",
       "2          False            False                True               False   \n",
       "3          False            False                True               False   \n",
       "4          False            False                True               False   \n",
       "\n",
       "   product_Using LLMs to Improve Your Coding  \\\n",
       "0                                       True   \n",
       "1                                      False   \n",
       "2                                      False   \n",
       "3                                      False   \n",
       "4                                      False   \n",
       "\n",
       "   product_Using LLMs to Train More LLMs  \\\n",
       "0                                  False   \n",
       "1                                   True   \n",
       "2                                  False   \n",
       "3                                  False   \n",
       "4                                  False   \n",
       "\n",
       "   product_Using LLMs to Win Friends and Influence People  \\\n",
       "0                                              False        \n",
       "1                                              False        \n",
       "2                                               True        \n",
       "3                                              False        \n",
       "4                                              False        \n",
       "\n",
       "   product_Using LLMs to Win More Kaggle Competitions  \\\n",
       "0                                              False    \n",
       "1                                              False    \n",
       "2                                              False    \n",
       "3                                               True    \n",
       "4                                              False    \n",
       "\n",
       "   product_Using LLMs to Write Better  \n",
       "0                               False  \n",
       "1                               False  \n",
       "2                               False  \n",
       "3                               False  \n",
       "4                                True  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import holidays\n",
    "\n",
    "def transform_date(df):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    return df\n",
    "\n",
    "def create_features(df):\n",
    "    # split date into year, month, day\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "\n",
    "    # week number\n",
    "    df['week_number'] = df['date'].dt.isocalendar().week.astype(int)\n",
    "    \n",
    "    # day of week\n",
    "    df['dayofweek'] = df['date'].dt.dayofweek\n",
    "\n",
    "    # weekend\n",
    "    df['weekend'] = (df['date'].dt.weekday >=4).astype(int)\n",
    "\n",
    "    # drop date\n",
    "    #df = df.drop('date', axis=1)\n",
    "\n",
    "    # one-hot encoding of 'country', 'store', 'product' columns\n",
    "    #df_train = pd.get_dummies(df_train, columns=['country', 'store', 'product'])\n",
    "\n",
    "\n",
    "    df['country'] = df['country'].astype('category')\n",
    "    df['store'] = df['store'].astype('category')\n",
    "    df['product'] = df['product'].astype('category')\n",
    "\n",
    "    return df\n",
    "\n",
    "def encode_cat_variables(df):\n",
    "    categorical_features = [\"country\", \"store\", \"product\"]\n",
    "    df = pd.get_dummies(df, columns=categorical_features)\n",
    "    return df\n",
    "\n",
    "def add_holidays(df):\n",
    "    # courtesy of kacperrabczewski in https://www.kaggle.com/code/kacperrabczewski/last-minute-forecasting#Modeling-%F0%9F%AA%84\n",
    "\n",
    "    years_list = [2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
    "\n",
    "    Argentina_holidays = holidays.CountryHoliday('AR', years=years_list)\n",
    "    Canada_holidays = holidays.CountryHoliday('CA', years=years_list)\n",
    "    Estonia_holidays = holidays.CountryHoliday('EE', years=years_list)\n",
    "    Japan_holidays = holidays.CountryHoliday('JP', years=years_list)\n",
    "    Spain_holidays = holidays.CountryHoliday('ES', years=years_list)\n",
    "    \n",
    "    # Create Holiday Column \n",
    "    df['Argentina_holiday'] = df.loc[df['country'] == 'Argentina', 'date'].apply(lambda d: True if d in Argentina_holidays else False)\n",
    "    df['Canada_holiday'] = df.loc[df['country'] == 'Canada', 'date'].apply(lambda d: True if d in Canada_holidays else False)\n",
    "    df['Estonia_holiday'] = df.loc[df['country'] == 'Estonia', 'date'].apply(lambda d: True if d in Estonia_holidays else False)\n",
    "    df['Japan_holiday'] = df.loc[df['country'] == 'Japan', 'date'].apply(lambda d: True if d in Japan_holidays else False)\n",
    "    df['Spain_holiday'] = df.loc[df['country'] == 'Spain', 'date'].apply(lambda d: True if d in Spain_holidays else False)\n",
    "\n",
    "    df['Argentina_holiday'] = df['Argentina_holiday'].fillna(False)\n",
    "    df['Canada_holiday'] = df['Canada_holiday'].fillna(False)\n",
    "    df['Estonia_holiday'] = df['Estonia_holiday'].fillna(False)\n",
    "    df['Japan_holiday'] = df['Japan_holiday'].fillna(False)\n",
    "    df['Spain_holiday'] = df['Spain_holiday'].fillna(False)\n",
    "\n",
    "    df = df.drop('date', axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train_0 = transform_date(df_train)\n",
    "df_train_0 = create_features(df_train_0)\n",
    "df_train_0 = add_holidays(df_train_0)\n",
    "df_train_0 = encode_cat_variables(df_train_0)\n",
    "df_train_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['year',\n",
       " 'month',\n",
       " 'day',\n",
       " 'week_number',\n",
       " 'dayofweek',\n",
       " 'weekend',\n",
       " 'Argentina_holiday',\n",
       " 'Canada_holiday',\n",
       " 'Estonia_holiday',\n",
       " 'Japan_holiday',\n",
       " 'Spain_holiday',\n",
       " 'country_Argentina',\n",
       " 'country_Canada',\n",
       " 'country_Estonia',\n",
       " 'country_Japan',\n",
       " 'country_Spain',\n",
       " 'store_Kagglazon',\n",
       " 'store_Kaggle Learn',\n",
       " 'store_Kaggle Store',\n",
       " 'product_Using LLMs to Improve Your Coding',\n",
       " 'product_Using LLMs to Train More LLMs',\n",
       " 'product_Using LLMs to Win Friends and Influence People',\n",
       " 'product_Using LLMs to Win More Kaggle Competitions',\n",
       " 'product_Using LLMs to Write Better']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_features = df_train_0.columns.tolist()\n",
    "model_features.remove(\"num_sold\")\n",
    "model_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136950 entries, 0 to 136949\n",
      "Data columns (total 25 columns):\n",
      " #   Column                                                  Non-Null Count   Dtype\n",
      "---  ------                                                  --------------   -----\n",
      " 0   num_sold                                                136950 non-null  int64\n",
      " 1   year                                                    136950 non-null  int32\n",
      " 2   month                                                   136950 non-null  int32\n",
      " 3   day                                                     136950 non-null  int32\n",
      " 4   week_number                                             136950 non-null  int32\n",
      " 5   dayofweek                                               136950 non-null  int32\n",
      " 6   weekend                                                 136950 non-null  int32\n",
      " 7   Argentina_holiday                                       136950 non-null  bool \n",
      " 8   Canada_holiday                                          136950 non-null  bool \n",
      " 9   Estonia_holiday                                         136950 non-null  bool \n",
      " 10  Japan_holiday                                           136950 non-null  bool \n",
      " 11  Spain_holiday                                           136950 non-null  bool \n",
      " 12  country_Argentina                                       136950 non-null  bool \n",
      " 13  country_Canada                                          136950 non-null  bool \n",
      " 14  country_Estonia                                         136950 non-null  bool \n",
      " 15  country_Japan                                           136950 non-null  bool \n",
      " 16  country_Spain                                           136950 non-null  bool \n",
      " 17  store_Kagglazon                                         136950 non-null  bool \n",
      " 18  store_Kaggle Learn                                      136950 non-null  bool \n",
      " 19  store_Kaggle Store                                      136950 non-null  bool \n",
      " 20  product_Using LLMs to Improve Your Coding               136950 non-null  bool \n",
      " 21  product_Using LLMs to Train More LLMs                   136950 non-null  bool \n",
      " 22  product_Using LLMs to Win Friends and Influence People  136950 non-null  bool \n",
      " 23  product_Using LLMs to Win More Kaggle Competitions      136950 non-null  bool \n",
      " 24  product_Using LLMs to Write Better                      136950 non-null  bool \n",
      "dtypes: bool(18), int32(6), int64(1)\n",
      "memory usage: 6.5 MB\n"
     ]
    }
   ],
   "source": [
    "df_train_0.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function by which submissions are scored is SMAPE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMAPE(A, F):\n",
    "    return 100/len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-29 16:51:53,110] A new study created in memory with name: no-name-ce3792ed-7bdf-40ac-8be0-01ab63ee9c00\n",
      "[I 2023-07-29 16:51:54,395] Trial 0 finished with value: 22.90888809455214 and parameters: {'n_estimators': 167, 'max_depth': 4}. Best is trial 0 with value: 22.90888809455214.\n",
      "[I 2023-07-29 16:52:00,759] Trial 1 finished with value: 17.12190647401724 and parameters: {'n_estimators': 640, 'max_depth': 6}. Best is trial 1 with value: 17.12190647401724.\n",
      "[I 2023-07-29 16:52:02,659] Trial 2 finished with value: 26.937164056105456 and parameters: {'n_estimators': 317, 'max_depth': 3}. Best is trial 1 with value: 17.12190647401724.\n",
      "[I 2023-07-29 16:52:04,986] Trial 3 finished with value: 15.124763252862946 and parameters: {'n_estimators': 211, 'max_depth': 7}. Best is trial 3 with value: 15.124763252862946.\n",
      "[I 2023-07-29 16:52:06,900] Trial 4 finished with value: 20.76374457441892 and parameters: {'n_estimators': 214, 'max_depth': 5}. Best is trial 3 with value: 15.124763252862946.\n",
      "[I 2023-07-29 16:52:16,189] Trial 5 finished with value: 15.16766122937996 and parameters: {'n_estimators': 863, 'max_depth': 7}. Best is trial 3 with value: 15.124763252862946.\n",
      "[I 2023-07-29 16:52:20,813] Trial 6 finished with value: 15.136575347054292 and parameters: {'n_estimators': 427, 'max_depth': 7}. Best is trial 3 with value: 15.124763252862946.\n",
      "[I 2023-07-29 16:52:25,188] Trial 7 finished with value: 22.8467479400647 and parameters: {'n_estimators': 615, 'max_depth': 4}. Best is trial 3 with value: 15.124763252862946.\n",
      "[I 2023-07-29 16:52:32,469] Trial 8 finished with value: 11.902449275369216 and parameters: {'n_estimators': 515, 'max_depth': 10}. Best is trial 8 with value: 11.902449275369216.\n",
      "[I 2023-07-29 16:52:35,747] Trial 9 finished with value: 17.15499461571303 and parameters: {'n_estimators': 332, 'max_depth': 6}. Best is trial 8 with value: 11.902449275369216.\n",
      "[I 2023-07-29 16:52:47,875] Trial 10 finished with value: 11.918892967137397 and parameters: {'n_estimators': 874, 'max_depth': 10}. Best is trial 8 with value: 11.902449275369216.\n",
      "[I 2023-07-29 16:53:01,555] Trial 11 finished with value: 11.92766364164483 and parameters: {'n_estimators': 986, 'max_depth': 10}. Best is trial 8 with value: 11.902449275369216.\n",
      "[I 2023-07-29 16:53:12,058] Trial 12 finished with value: 11.910975597354282 and parameters: {'n_estimators': 747, 'max_depth': 10}. Best is trial 8 with value: 11.902449275369216.\n",
      "[I 2023-07-29 16:53:20,672] Trial 13 finished with value: 12.167928712346495 and parameters: {'n_estimators': 703, 'max_depth': 9}. Best is trial 8 with value: 11.902449275369216.\n",
      "[I 2023-07-29 16:53:26,651] Trial 14 finished with value: 12.190896768365604 and parameters: {'n_estimators': 487, 'max_depth': 9}. Best is trial 8 with value: 11.902449275369216.\n",
      "[I 2023-07-29 16:53:35,439] Trial 15 finished with value: 12.174667395563484 and parameters: {'n_estimators': 718, 'max_depth': 9}. Best is trial 8 with value: 11.902449275369216.\n",
      "[I 2023-07-29 16:53:41,413] Trial 16 finished with value: 13.528369530702287 and parameters: {'n_estimators': 536, 'max_depth': 8}. Best is trial 8 with value: 11.902449275369216.\n",
      "[I 2023-07-29 16:53:52,467] Trial 17 finished with value: 11.918882148629255 and parameters: {'n_estimators': 826, 'max_depth': 10}. Best is trial 8 with value: 11.902449275369216.\n",
      "[I 2023-07-29 16:54:01,044] Trial 18 finished with value: 13.510760948188153 and parameters: {'n_estimators': 758, 'max_depth': 8}. Best is trial 8 with value: 11.902449275369216.\n",
      "[I 2023-07-29 16:54:05,693] Trial 19 finished with value: 13.54123759445238 and parameters: {'n_estimators': 412, 'max_depth': 8}. Best is trial 8 with value: 11.902449275369216.\n",
      "[I 2023-07-29 16:54:13,131] Trial 20 finished with value: 12.16250357226455 and parameters: {'n_estimators': 607, 'max_depth': 9}. Best is trial 8 with value: 11.902449275369216.\n",
      "[I 2023-07-29 16:54:24,440] Trial 21 finished with value: 11.918028643576742 and parameters: {'n_estimators': 844, 'max_depth': 10}. Best is trial 8 with value: 11.902449275369216.\n",
      "[I 2023-07-29 16:54:37,669] Trial 22 finished with value: 11.926023930731768 and parameters: {'n_estimators': 991, 'max_depth': 10}. Best is trial 8 with value: 11.902449275369216.\n",
      "[I 2023-07-29 16:54:48,670] Trial 23 finished with value: 11.91358822075675 and parameters: {'n_estimators': 818, 'max_depth': 10}. Best is trial 8 with value: 11.902449275369216.\n",
      "[I 2023-07-29 16:54:58,135] Trial 24 finished with value: 12.175393310245903 and parameters: {'n_estimators': 773, 'max_depth': 9}. Best is trial 8 with value: 11.902449275369216.\n",
      "[I 2023-07-29 16:55:08,382] Trial 25 finished with value: 13.537512744767955 and parameters: {'n_estimators': 918, 'max_depth': 8}. Best is trial 8 with value: 11.902449275369216.\n",
      "[I 2023-07-29 16:55:17,408] Trial 26 finished with value: 11.893101158925049 and parameters: {'n_estimators': 672, 'max_depth': 10}. Best is trial 26 with value: 11.893101158925049.\n",
      "[I 2023-07-29 16:55:24,176] Trial 27 finished with value: 12.174931399535556 and parameters: {'n_estimators': 552, 'max_depth': 9}. Best is trial 26 with value: 11.893101158925049.\n",
      "[I 2023-07-29 16:55:33,383] Trial 28 finished with value: 11.89461154049323 and parameters: {'n_estimators': 674, 'max_depth': 10}. Best is trial 26 with value: 11.893101158925049.\n",
      "[I 2023-07-29 16:55:41,219] Trial 29 finished with value: 13.53124844599378 and parameters: {'n_estimators': 670, 'max_depth': 8}. Best is trial 26 with value: 11.893101158925049.\n",
      "[I 2023-07-29 16:55:48,251] Trial 30 finished with value: 12.173883888470886 and parameters: {'n_estimators': 563, 'max_depth': 9}. Best is trial 26 with value: 11.893101158925049.\n",
      "[I 2023-07-29 16:55:58,229] Trial 31 finished with value: 11.906687442712995 and parameters: {'n_estimators': 738, 'max_depth': 10}. Best is trial 26 with value: 11.893101158925049.\n",
      "[I 2023-07-29 16:56:07,103] Trial 32 finished with value: 11.907363587708904 and parameters: {'n_estimators': 648, 'max_depth': 10}. Best is trial 26 with value: 11.893101158925049.\n",
      "[I 2023-07-29 16:56:13,768] Trial 33 finished with value: 11.911844543298535 and parameters: {'n_estimators': 490, 'max_depth': 10}. Best is trial 26 with value: 11.893101158925049.\n",
      "[I 2023-07-29 16:56:17,409] Trial 34 finished with value: 26.937164056105456 and parameters: {'n_estimators': 679, 'max_depth': 3}. Best is trial 26 with value: 11.893101158925049.\n",
      "[I 2023-07-29 16:56:24,736] Trial 35 finished with value: 12.168720119400184 and parameters: {'n_estimators': 594, 'max_depth': 9}. Best is trial 26 with value: 11.893101158925049.\n",
      "[I 2023-07-29 16:56:25,782] Trial 36 finished with value: 20.82540782404465 and parameters: {'n_estimators': 119, 'max_depth': 5}. Best is trial 26 with value: 11.893101158925049.\n",
      "[I 2023-07-29 16:56:31,461] Trial 37 finished with value: 11.90655342127418 and parameters: {'n_estimators': 412, 'max_depth': 10}. Best is trial 26 with value: 11.893101158925049.\n",
      "[I 2023-07-29 16:56:35,773] Trial 38 finished with value: 12.208735473403294 and parameters: {'n_estimators': 342, 'max_depth': 9}. Best is trial 26 with value: 11.893101158925049.\n",
      "[I 2023-07-29 16:56:39,017] Trial 39 finished with value: 20.761217336258042 and parameters: {'n_estimators': 394, 'max_depth': 5}. Best is trial 26 with value: 11.893101158925049.\n",
      "[I 2023-07-29 16:56:42,500] Trial 40 finished with value: 11.924795825653653 and parameters: {'n_estimators': 253, 'max_depth': 10}. Best is trial 26 with value: 11.893101158925049.\n",
      "[I 2023-07-29 16:56:49,291] Trial 41 finished with value: 11.911387279766148 and parameters: {'n_estimators': 496, 'max_depth': 10}. Best is trial 26 with value: 11.893101158925049.\n",
      "[I 2023-07-29 16:56:54,420] Trial 42 finished with value: 11.904290369712042 and parameters: {'n_estimators': 377, 'max_depth': 10}. Best is trial 26 with value: 11.893101158925049.\n",
      "[I 2023-07-29 16:56:57,891] Trial 43 finished with value: 12.217093450833751 and parameters: {'n_estimators': 274, 'max_depth': 9}. Best is trial 26 with value: 11.893101158925049.\n",
      "[I 2023-07-29 16:57:02,594] Trial 44 finished with value: 15.142328637637718 and parameters: {'n_estimators': 452, 'max_depth': 7}. Best is trial 26 with value: 11.893101158925049.\n",
      "[I 2023-07-29 16:57:07,546] Trial 45 finished with value: 11.918357887474968 and parameters: {'n_estimators': 361, 'max_depth': 10}. Best is trial 26 with value: 11.893101158925049.\n",
      "[I 2023-07-29 16:57:13,872] Trial 46 finished with value: 11.90891805441767 and parameters: {'n_estimators': 462, 'max_depth': 10}. Best is trial 26 with value: 11.893101158925049.\n",
      "[I 2023-07-29 16:57:20,268] Trial 47 finished with value: 12.1720052272533 and parameters: {'n_estimators': 518, 'max_depth': 9}. Best is trial 26 with value: 11.893101158925049.\n",
      "[I 2023-07-29 16:57:25,317] Trial 48 finished with value: 11.917164250893297 and parameters: {'n_estimators': 369, 'max_depth': 10}. Best is trial 26 with value: 11.893101158925049.\n",
      "[I 2023-07-29 16:57:28,862] Trial 49 finished with value: 12.206907214622339 and parameters: {'n_estimators': 280, 'max_depth': 9}. Best is trial 26 with value: 11.893101158925049.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "\n",
    "train_index, val_index = [ x for x in TimeSeriesSplit(n_splits=5).split(df_train_0) ][-1]\n",
    "\n",
    "X_train = df_train_0.iloc[train_index][model_features]\n",
    "y_train = df_train_0.iloc[train_index]['num_sold']\n",
    "\n",
    "X_val = df_train_0.iloc[val_index][model_features]\n",
    "y_val = df_train_0.iloc[val_index]['num_sold']\n",
    "\n",
    "cat_features_indices = np.where((X_train.dtypes == \"category\") | (X_train.dtypes == \"object\"))[0]\n",
    "cat_features_indices\n",
    "\n",
    "def objective(trial):\n",
    "    model=xgb.XGBRegressor(\n",
    "        tree_method=\"gpu_hist\", enable_categorical=True,\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 1, 10),\n",
    "        learning_rate=trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True),\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[( X_train, y_train), ( X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    return SMAPE(y_val, np.round(model.predict(X_val)))\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_hyperparams = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 672, 'max_depth': 10}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and validation\n",
    "\n",
    "results_smape = []\n",
    "results_r2 = []\n",
    "results_mse = []\n",
    "\n",
    "\n",
    "N_SPLITS = 5\n",
    "\n",
    "for train_index, val_index in TimeSeriesSplit(n_splits=N_SPLITS).split(df_train_0):\n",
    "    X_train = df_train_0.iloc[train_index][model_features]\n",
    "    y_train = df_train_0.iloc[train_index]['num_sold']\n",
    "\n",
    "    X_val = df_train_0.iloc[val_index]\n",
    "    y_val = df_train_0.iloc[val_index]['num_sold']\n",
    "\n",
    "    model = xgb.XGBRegressor(tree_method=\"gpu_hist\", enable_categorical=True, **best_hyperparams)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    y_pred = np.round(model.predict(X_val[model_features]))\n",
    "\n",
    "    smape = SMAPE(y_val, y_pred)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "\n",
    "    results_smape.append(smape)\n",
    "    results_r2.append(r2)\n",
    "    results_mse.append(mse)\n",
    "    del model\n",
    "\n",
    "print(\"Cross validated results:\")\n",
    "\n",
    "print(\"SMAPE: %s\" % results_smape)\n",
    "print(\"R2: %s\" % results_r2)\n",
    "print(\"MSE: %s\" % results_mse)\n",
    "\n",
    "print(\"Mean results:\")\n",
    "print(\"SMAPE: %.4f\" % np.mean(results_smape))\n",
    "print(\"R2: %.4f\" % np.mean(results_r2))\n",
    "print(\"MSE: %.4f\" % np.mean(results_mse))\n",
    "\n",
    "\n",
    "# add a row with results to csv file leaderboard.csv\n",
    "\n",
    "row = [model_name, np.mean(results_smape), np.mean(results_r2), np.mean(results_mse)]\n",
    "with open('leaderboard.csv', 'a') as fd:\n",
    "    import csv\n",
    "    fd.write('\\n')\n",
    "    writer = csv.writer(fd, delimiter=',', lineterminator=';\\n')\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m y_train \u001b[39m=\u001b[39m df_train_0[\u001b[39m'\u001b[39m\u001b[39mnum_sold\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     15\u001b[0m model \u001b[39m=\u001b[39m RandomForestRegressor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbest_hyperparams)\n\u001b[1;32m---> 16\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train[model_features], y_train)\n\u001b[0;32m     18\u001b[0m df_val \u001b[39m=\u001b[39m X_val\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     19\u001b[0m df_val[\u001b[39m'\u001b[39m\u001b[39mactual\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m y_val\n",
      "File \u001b[1;32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    457\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    458\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    459\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    460\u001b[0m )(\n\u001b[0;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    462\u001b[0m         t,\n\u001b[0;32m    463\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    464\u001b[0m         X,\n\u001b[0;32m    465\u001b[0m         y,\n\u001b[0;32m    466\u001b[0m         sample_weight,\n\u001b[0;32m    467\u001b[0m         i,\n\u001b[0;32m    468\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    469\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    470\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    471\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    472\u001b[0m     )\n\u001b[0;32m    473\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    474\u001b[0m )\n\u001b[0;32m    476\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1855\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1853\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1854\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1855\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[0;32m   1857\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1858\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1859\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1860\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1861\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1862\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1784\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1783\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1784\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1785\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1786\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1292\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \n\u001b[0;32m   1294\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1320\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(\n\u001b[0;32m   1321\u001b[0m         X,\n\u001b[0;32m   1322\u001b[0m         y,\n\u001b[0;32m   1323\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1324\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   1325\u001b[0m     )\n\u001b[0;32m   1326\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train and predict for submission\n",
    "\n",
    "df_train = pd.read_csv(data_path + \"train.csv\")\n",
    "df_train['date'] = pd.to_datetime(df_train['date'])\n",
    "\n",
    "df_train_0 = transform_date(df_train)\n",
    "df_train_0 = create_features(df_train_0)\n",
    "df_train_0 = add_holidays(df_train_0)\n",
    "df_train_0 = encode_cat_variables(df_train_0)\n",
    "\n",
    "X_train = df_train_0.drop('num_sold', axis=1)\n",
    "y_train = df_train_0['num_sold']\n",
    "\n",
    "\n",
    "model = RandomForestRegressor(**best_hyperparams)\n",
    "model.fit(X_train[model_features], y_train)\n",
    "\n",
    "df_val = X_val.copy()\n",
    "df_val['actual'] = y_val\n",
    "df_val['prediction'] = model.predict(df_val[model_features])\n",
    "df_val['prediction'] = df_val['prediction'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "X_train['date'] = pd.to_datetime(X_train['year'].astype(str) + '-' + X_train['month'].astype(str) + '-' + X_train['day'].astype(str))\n",
    "X_val['date'] = pd.to_datetime(X_val['year'].astype(str) + '-' + X_val['month'].astype(str) + '-' + X_val['day'].astype(str))\n",
    "df_val['date'] = pd.to_datetime(df_val['year'].astype(str) + '-' + df_val['month'].astype(str) + '-' + df_val['day'].astype(str))\n",
    "\n",
    "# sort by date\n",
    "X_train.sort_values(by='date', inplace=True)\n",
    "X_val.sort_values(by='date', inplace=True)\n",
    "\n",
    "# plot 'num_sold' vs 'date'\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "ax.plot(X_train['date'], y_train, label='train', color='lightblue')\n",
    "ax.plot(X_val['date'], y_val, label='validation', color='pink')\n",
    "ax.plot(df_val['date'], df_val['prediction'], label='prediction', color='crimson')\n",
    "\n",
    "# x axis show only from 2021 onwards\n",
    "ax.set_xlim([datetime.date(2021, 1, 1), df_val['date'].max()])\n",
    "ax.set_xlabel('date')\n",
    "ax.set_ylabel('num_sold')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test \n",
    "\n",
    "df_test = pd.read_csv(data_path + \"test.csv\")\n",
    "\n",
    "df_test_0 = transform_date(df_test)\n",
    "df_test_0 = create_features(df_test_0)\n",
    "df_test_0 = add_holidays(df_test_0)\n",
    "df_test_0 = encode_cat_variables(df_test_0)\n",
    "\n",
    "# predict for test set\n",
    "df_test['prediction'] = model.predict(df_test_0[model_features])\n",
    "df_test['prediction'] = df_test['prediction'].astype(int)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['num_sold'] = df_test['prediction']\n",
    "df_test[['id', 'num_sold']].to_csv(f'{model_name}_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
