{"cells":[{"cell_type":"markdown","metadata":{},"source":["# ⚽S4E1 - EDA & initial submission - Binary Classification with a Bank Churn Dataset \n","\n","Welcome to 2024! For this Episode of the Series, your task is to predict whether a customer continues with their account or closes it (e.g., churns). Good luck!\n","\n","## Evaluation\n","\n","Submissions are evaluated on area under the ROC curve between the predicted probability and the observed target.\n","\n","## Submission Format\n","\n","For each id in the test set, you must predict the probability for the target variable Exited. The file should contain a header and have the following format:\n","\n","```\n","id,Exited\n","0,0.9\n","1,0.1\n","2,0.5\n","etc.\n","```\n","\n","## Data Description\n","\n","The dataset for this competition (both train and test) was generated from a deep learning model trained on the Bank Customer Churn Prediction dataset. Feature distributions are close to, but not exactly the same, as the original. \n","\n","# Code\n","\n","## ToC\n","\n","- [Imports](#Imports)\n","\n","\n","## Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-01-04T20:03:46.497400Z","iopub.status.busy":"2024-01-04T20:03:46.496914Z","iopub.status.idle":"2024-01-04T20:03:59.746581Z","shell.execute_reply":"2024-01-04T20:03:59.745260Z","shell.execute_reply.started":"2024-01-04T20:03:46.497360Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/wiktor/.pyenv/versions/3.11.3/envs/kaggling/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAZcAAABhCAYAAAAa2uy9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADKUlEQVR4nO3bz2qcZRjG4eedP2nsQCsh0SIFNz2BZO8p9CQ8Bg9AcO/GnoBuPQE3HkKCCLpxUTcFbQ2kJjWZmczrQnGZTOktn5+9rs1sHoabgY8fwzCt994LAIImQw8A4P9HXACIExcA4sQFgDhxASBOXACIExcA4sQFgLjZNkcnJyfVe6/5fP5v7wHgP2y1WlVrrQ4PD2+82youvffabDb162+v6tof+re2f3lV/WBR7flFtWuf2zb6tFV/b1Gz+ctqbTP0nNHofVLr5b2aXZ1W69dDzxmF3qa1urNXZ3VZm/J8but+7dZsMr31bqu4zOfzWi6X9eU3z+vZi+Ubj3tbfPH9d3X+5HEtPv22Zj+dDj1nFNaP9ur8yeN6+Ojr2r37y9BzRuPy1fv19MeP6+EPn9c7Fz8PPWcU/lh8WE+PPquv+kk9q9+HnjMan9RH9WD+7q13fnMBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIhrvfd+29Hx8XH13uvsfF3rza3n/G1/uay+v6j24qLaajP0nFHo80n1/UXN5i+rteuh54xG79Nar+7V7Oq02mY99JxR6JNZre/s1Vm/rOvyfG7rfu3WbDKto6OjG+9m27xZa62qqg727r75srfK4q+XD3aGnTFK+0MPGJXWqnZ2qmrnwdBTRqNV1U5VHZTn83WsVqt/mnCTrb65AMDr8JsLAHHiAkCcuAAQJy4AxIkLAHHiAkCcuAAQJy4AxP0JEUGH3u8dhhMAAAAASUVORK5CYII=","text/plain":["<Figure size 500x100 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# essentials\n","import os\n","import pathlib\n","from copy import copy\n","import json\n","\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","\n","# visualisation\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# sklearn imports\n","import sklearn\n","from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, cross_val_score\n","from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MaxAbsScaler, PowerTransformer, FunctionTransformer, StandardScaler\n","from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MaxAbsScaler, PowerTransformer, FunctionTransformer, StandardScaler\n","from sklearn.pipeline import Pipeline, make_pipeline, make_union, FeatureUnion\n","from sklearn.compose import ColumnTransformer\n","from sklearn.feature_selection import SelectKBest, chi2, f_classif, SequentialFeatureSelector, RFECV\n","from sklearn.calibration import CalibratedClassifierCV\n","from sklearn.base import clone as clone_model\n","from sklearn.metrics import classification_report, confusion_matrix, log_loss\n","from sklearn.impute import SimpleImputer, MissingIndicator, KNNImputer\n","\n","\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, StackingClassifier, VotingClassifier, AdaBoostClassifier\n","from sklearn.linear_model import LogisticRegression, ElasticNet, SGDClassifier, RidgeClassifier, PassiveAggressiveClassifier, TweedieRegressor\n","from sklearn.svm import SVC, LinearSVC, NuSVC\n","from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB, ComplementNB\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import RocCurveDisplay, roc_auc_score, make_scorer, roc_curve\n","\n","from sklearn.preprocessing import Binarizer, Normalizer, RobustScaler, StandardScaler\n","from sklearn.preprocessing import FunctionTransformer\n","\n","# others\n","import xgboost as xgb \n","import lightgbm as lgb\n","import catboost as cb\n","\n","import optuna\n","import shap\n","\n","RANDOM_SEED = 64\n","\n","palette = [\"#4464ad\", \"#dc136c\", \"#F4FF52\", \"#f58f29\",\"#45cb85\"]\n","\n","sns.set_theme(style=\"whitegrid\")\n","sns.set_palette(palette)\n","sns.palplot(palette)"]},{"cell_type":"markdown","metadata":{},"source":["## Data loading & EDA\n","\n","First we will check\n","\n","1. Number and types of columns\n","2. Number of rows in train and test\n","2. Missing values\n","3. Target variable distribution"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-01-04T20:04:02.461936Z","iopub.status.busy":"2024-01-04T20:04:02.461081Z","iopub.status.idle":"2024-01-04T20:04:03.308882Z","shell.execute_reply":"2024-01-04T20:04:03.307180Z","shell.execute_reply.started":"2024-01-04T20:04:02.461876Z"},"trusted":true},"outputs":[],"source":["IN_KAGGLE = False\n","\n","kaggle_folder = \"/kaggle/input/\"\n","local_folder = \"./data/\"\n","input_folder = kaggle_folder if IN_KAGGLE else local_folder\n","\n","train_df = pd.read_csv(input_folder + \"playground-series-s4e1/train.csv\", index_col=\"id\")\n","test_df = pd.read_csv(input_folder + \"playground-series-s4e1/test.csv\", index_col=\"id\")\n","submission_df = pd.read_csv(input_folder + \"playground-series-s4e1/sample_submission.csv\")\n","original_df = pd.read_csv(input_folder + \"bank-customer-churn-prediction/Churn_Modelling.csv\")\n","target_col = \"Exited\"\n","\n","numeric_features = ['CustomerId', 'CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n","categorical_features = ['Surname', 'Geography', 'Gender', 'HasCrCard', 'IsActiveMember']\n","\n","features_to_drop = ['CustomerId', 'Surname']\n","\n","GENERATED_COLUMN = True\n","ADD_ORIGINAL_DF = True\n","\n","model_postfix = \"_with_original\" if ADD_ORIGINAL_DF else \"\"\n","model_postfix += \"_generated\" if GENERATED_COLUMN else \"\"\n","\n","original_df = original_df.drop(columns=['RowNumber'])\n","\n","# drop na rows from orignal df\n","original_df = original_df.dropna()\n","\n","if GENERATED_COLUMN:\n","    train_df['generated'] = 1\n","    test_df['generated'] = 1\n","    original_df['generated'] = 0\n","    categorical_features.append('generated')\n","    \n","if ADD_ORIGINAL_DF:\n","    train_df = pd.concat([train_df, original_df])\n","\n","\n","for f in features_to_drop:\n","    if f in numeric_features:\n","        numeric_features.remove(f)\n","    if f in categorical_features:\n","        categorical_features.remove(f)\n","    \n","    train_df = train_df.drop(columns=f)\n","\n","def initial_feature_engineering(df):\n","    df['HasCrCard'] = df['HasCrCard'].astype('bool')\n","    df['IsActiveMember'] = df['IsActiveMember'].astype('bool')\n","    df['Gender'] = df['Gender'].map({ \"Male\": 0, \"Female\": 1}).astype(\"bool\")\n","    # encode geography\n","    df = pd.get_dummies(df, columns=['Geography'])\n","\n","    return df\n","\n","def feature_engineering_1(df):\n","    # Balance\n","    df['balance_over_100k'] = df['Balance'] >= 100000\n","    df['balance_over_150k'] = df['Balance'] >= 150000\n","\n","    # EstimatedSalary\n","    df[\"estimated_salary_under_50k\"] = df[\"EstimatedSalary\"] < 50000\n","    df[\"estimated_salary_50k_to_100k\"] = (df[\"EstimatedSalary\"] >= 50000) & (df[\"EstimatedSalary\"] < 100000)\n","    df[\"estamated_salary_over_150k\"] = df[\"EstimatedSalary\"] >= 150000\n","\n","    # NumOfProducts\n","    df[\"num_of_products_3_or_4\"] = df[\"NumOfProducts\"] >= 3\n","\n","    # Age\n","    df[\"age_over_40\"] = df[\"Age\"] >= 40\n","    df[\"age_over_50\"] = df[\"Age\"] >= 50\n","    df[\"age_over_60\"] = df[\"Age\"] >= 60\n","\n","    new_features = [\n","        \"balance_over_100k\",\n","        \"balance_over_150k\",\n","        \"estimated_salary_under_50k\",\n","        \"estimated_salary_50k_to_100k\",\n","        \"estamated_salary_over_150k\",\n","        \"num_of_products_3_or_4\",\n","        \"age_over_40\",\n","        \"age_over_50\",\n","        \"age_over_60\",\n","    ]\n","    for f in new_features:\n","        df[f] = df[f].astype(\"int\")\n","\n","    return df\n","\n","train_df = initial_feature_engineering(train_df)\n","train_df = feature_engineering_1(train_df)\n","X_train, X_val, y_train, y_val = train_test_split(train_df.drop(columns=target_col), train_df[target_col], test_size=0.2, random_state=RANDOM_SEED, stratify=train_df[target_col])"]},{"cell_type":"markdown","metadata":{},"source":["## Ideas for feature engineering"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-01-04T20:04:03.311250Z","iopub.status.busy":"2024-01-04T20:04:03.310809Z","iopub.status.idle":"2024-01-04T20:04:03.330270Z","shell.execute_reply":"2024-01-04T20:04:03.328813Z","shell.execute_reply.started":"2024-01-04T20:04:03.311211Z"},"trusted":true},"outputs":[],"source":["def create_pipeline(model, numeric_scalers=(\"scaler\", StandardScaler())):\n","    numeric_pipeline = Pipeline(\n","        [numeric_scalers]\n","    )\n","\n","    categorical_pipeline = Pipeline([\n","        #(\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n","        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\", drop='if_binary')),\n","    ])\n","\n","    preprocessor = ColumnTransformer([\n","        (\"numeric\", numeric_pipeline, numeric_features),\n","        #(\"categorical\", categorical_pipeline, categorical_features),\n","    ], remainder='passthrough')\n","\n","    return Pipeline([\n","        (\"preprocessor\", preprocessor),\n","        (\"classifier\", model),\n","    ])\n","\n","def train_models(models, X_train, y_train, parameters={}):\n","    trained_models = {}\n","    for model_name, model in tqdm(models.items()):\n","        if model_name in parameters:\n","            model.set_params(**parameters[model_name])\n","        model = create_pipeline(model)\n","        model.fit(X_train, y_train)\n","        trained_models[model_name] = model\n","    return trained_models\n","\n","def evaluate_models(models, X_val, y_val):\n","    # create a dataframe with \"model_name\", \"accuracy\", \"precision\", \"recall\", \"area under the ROC curve\"\n","    results_df = pd.DataFrame(columns=[\"model_name\", \"accuracy\", \"precision\", \"recall\", \"auc\"])\n","\n","    for model_name, model in tqdm(models.items()):\n","        y_pred = model.predict(X_val)\n","        y_proba = model.predict_proba(X_val)[:, 1]\n","        results_df = pd.concat([\n","            results_df,\n","            pd.DataFrame({\n","                \"model_name\": [model_name],\n","                \"accuracy\": [model.score(X_val, y_val)],\n","                \"precision\": [sklearn.metrics.precision_score(y_val, y_pred)],\n","                \"recall\": [sklearn.metrics.recall_score(y_val, y_pred)],\n","                \"auc\": [sklearn.metrics.roc_auc_score(y_val, y_proba)],\n","            })\n","        ])\n","    return results_df\n","\n","def plot_roc_curve(models, X_val, y_val):\n","    fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n","    palette_to_use = sns.color_palette(\"husl\", len(models))\n","    # for each model, plot the roc curve in the same plot, with other color\n","    for i, (model_name, model) in enumerate(models.items()):\n","        y_proba = model.predict_proba(X_val)[:, 1]\n","        fpr, tpr, _ = roc_curve(y_val, y_proba)\n","        roc_auc = roc_auc_score(y_val, y_proba)\n","        ax.plot(fpr, tpr, label=f\"{model_name} (AUC = {roc_auc:.2f})\", color=palette_to_use[i])\n","        ax.plot([0, 1], [0, 1], color='black', linestyle='--')\n","    ax.set_xlabel(\"False Positive Rate\")\n","    ax.set_ylabel(\"True Positive Rate\")\n","    ax.set_title(\"ROC Curve\")\n","    # show legend\n","    ax.legend()\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-01-04T20:09:02.848675Z","iopub.status.busy":"2024-01-04T20:09:02.848177Z","iopub.status.idle":"2024-01-04T20:09:02.915864Z","shell.execute_reply":"2024-01-04T20:09:02.914115Z","shell.execute_reply.started":"2024-01-04T20:09:02.848634Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training models...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 3/3 [00:15<00:00,  5.27s/it]\n"]}],"source":["trained_models = {}\n","\n","# generate random seed\n","models = {\n","    \"xgboost\": xgb.XGBClassifier(random_state=RANDOM_SEED, n_jobs=-1),\n","    \"lightgbm\": lgb.LGBMClassifier(random_state=RANDOM_SEED, n_jobs=-1, verbosity=-1),\n","    \"catboost\": cb.CatBoostClassifier(random_state=RANDOM_SEED, verbose=False, thread_count=16),\n","    #\"knn\": KNeighborsClassifier(n_jobs=-1),\n","    #\"random_forest\": RandomForestClassifier(random_state=RANDOM_SEED, n_jobs=-1),\n","    #\"gradient_boosting\": GradientBoostingClassifier(random_state=RANDOM_SEED),\n","    #\"extra_trees\": ExtraTreesClassifier(random_state=RANDOM_SEED, n_jobs=-1),\n","    #\"bagging\": BaggingClassifier(random_state=RANDOM_SEED, n_jobs=-1),\n","    #\"ada_boost\": AdaBoostClassifier(random_state=RANDOM_SEED),\n","    #\"sgd\": SGDClassifier(random_state=RANDOM_SEED, loss=\"log_loss\", n_jobs=-1),\n","}\n","\n","print(\"Training models...\")\n","\n","trained_models = {}\n","for model_name, model in tqdm(models.items()):\n","    model = create_pipeline(model)\n","    model.fit(X_train, y_train)\n","    trained_models[model_name] = model\n","\n","#print(\"Evaluating models...\")\n","#results_df = evaluate_models(trained_models, X_val, y_val)\n","#results_df.sort_values(by=\"auc\", ascending=False)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting imbalanced-learn\n","  Downloading imbalanced_learn-0.11.0-py3-none-any.whl.metadata (8.3 kB)\n","Requirement already satisfied: numpy>=1.17.3 in /home/wiktor/.pyenv/versions/kaggling/lib/python3.11/site-packages (from imbalanced-learn) (1.26.3)\n","Requirement already satisfied: scipy>=1.5.0 in /home/wiktor/.pyenv/versions/kaggling/lib/python3.11/site-packages (from imbalanced-learn) (1.11.4)\n","Requirement already satisfied: scikit-learn>=1.0.2 in /home/wiktor/.pyenv/versions/kaggling/lib/python3.11/site-packages (from imbalanced-learn) (1.3.2)\n","Requirement already satisfied: joblib>=1.1.1 in /home/wiktor/.pyenv/versions/kaggling/lib/python3.11/site-packages (from imbalanced-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /home/wiktor/.pyenv/versions/kaggling/lib/python3.11/site-packages (from imbalanced-learn) (3.2.0)\n","Downloading imbalanced_learn-0.11.0-py3-none-any.whl (235 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.6/235.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: imbalanced-learn\n","Successfully installed imbalanced-learn-0.11.0\n"]}],"source":["! pip install imbalanced-learn"]},{"cell_type":"markdown","metadata":{},"source":["## Oversampling"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 3/3 [00:18<00:00,  6.28s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Evaluating models...\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/9 [00:00<?, ?it/s]The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","100%|██████████| 9/9 [00:02<00:00,  3.77it/s]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model_name</th>\n","      <th>accuracy</th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>auc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>lightgbm_randomoversampler_first</td>\n","      <td>0.815465</td>\n","      <td>0.543405</td>\n","      <td>0.789232</td>\n","      <td>0.889360</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>catboost_randomoversampler_first</td>\n","      <td>0.819493</td>\n","      <td>0.551227</td>\n","      <td>0.780979</td>\n","      <td>0.887399</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>lightgbm</td>\n","      <td>0.788185</td>\n","      <td>0.499055</td>\n","      <td>0.821429</td>\n","      <td>0.886343</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>lightgbm_randomoversampler_second</td>\n","      <td>0.788185</td>\n","      <td>0.499055</td>\n","      <td>0.821429</td>\n","      <td>0.886343</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>xgboost_randomoversampler_first</td>\n","      <td>0.819036</td>\n","      <td>0.550910</td>\n","      <td>0.773674</td>\n","      <td>0.886171</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>catboost</td>\n","      <td>0.797840</td>\n","      <td>0.513716</td>\n","      <td>0.798025</td>\n","      <td>0.881058</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>catboost_randomoversampler_second</td>\n","      <td>0.797840</td>\n","      <td>0.513716</td>\n","      <td>0.798025</td>\n","      <td>0.881058</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>xgboost</td>\n","      <td>0.563402</td>\n","      <td>0.309114</td>\n","      <td>0.864448</td>\n","      <td>0.799849</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>xgboost_randomoversampler_second</td>\n","      <td>0.563402</td>\n","      <td>0.309114</td>\n","      <td>0.864448</td>\n","      <td>0.799849</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                          model_name  accuracy  precision    recall       auc\n","0   lightgbm_randomoversampler_first  0.815465   0.543405  0.789232  0.889360\n","0   catboost_randomoversampler_first  0.819493   0.551227  0.780979  0.887399\n","0                           lightgbm  0.788185   0.499055  0.821429  0.886343\n","0  lightgbm_randomoversampler_second  0.788185   0.499055  0.821429  0.886343\n","0    xgboost_randomoversampler_first  0.819036   0.550910  0.773674  0.886171\n","0                           catboost  0.797840   0.513716  0.798025  0.881058\n","0  catboost_randomoversampler_second  0.797840   0.513716  0.798025  0.881058\n","0                            xgboost  0.563402   0.309114  0.864448  0.799849\n","0   xgboost_randomoversampler_second  0.563402   0.309114  0.864448  0.799849"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["from imblearn.over_sampling import RandomOverSampler, SMOTE\n","from imblearn.combine import SMOTEENN\n","from imblearn.ensemble import BalancedBaggingClassifier\n","from imblearn.pipeline import Pipeline as imPipeline\n","\n","def create_oversampling_pipeline(model, numeric_scalers=(\"scaler\", StandardScaler())):\n","    numeric_pipeline = Pipeline(\n","        [numeric_scalers]\n","    )\n","\n","    categorical_pipeline = Pipeline([\n","        #(\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n","        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\", drop='if_binary')),\n","    ])\n","\n","    preprocessor = ColumnTransformer([\n","        (\"numeric\", numeric_pipeline, numeric_features),\n","        #(\"categorical\", categorical_pipeline, categorical_features),\n","    ], remainder='passthrough')\n","    \n","    return imPipeline([\n","        (\"resampler\", RandomOverSampler(random_state=RANDOM_SEED)),\n","        (\"preprocessor\", preprocessor),\n","        (\"classifier\", model),\n","    ])\n","\n","\n","for model_name, model in tqdm(models.items()):\n","    model = create_oversampling_pipeline(model)\n","    model.fit(X_train, y_train)\n","    trained_models[model_name + \"_randomoversampler_first\"] = model\n","\n","print(\"Evaluating models...\")\n","results_df = evaluate_models(trained_models, X_val, y_val)\n","results_df.sort_values(by=\"auc\", ascending=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["raise Exception(\"Stop here\")"]},{"cell_type":"markdown","metadata":{},"source":["## Best params"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["best_params_lightgbm = lightgbm_best_params\n","best_params_xgboost = xgboost_best_params\n","best_params_catboost = catboost_best_params\n","\n","optuna_best_parameters_found = {\n","    \"xgboost\": xgboost_best_params,\n","    \"lightgbm\": lightgbm_best_params,\n","    \"catboost\": catboost_best_params,\n","}\n","\n","optuna_best_parameters_found"]},{"cell_type":"markdown","metadata":{},"source":["## Submission"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import lightgbm\n","\n","models = {\n","    \"xgboost\": xgb.XGBClassifier(random_state=RANDOM_SEED, n_jobs=-1),\n","    \"lightgbm\": lightgbm.LGBMClassifier(random_state=RANDOM_SEED, n_jobs=-1, verbosity=-1),\n","    \"catboost\": cb.CatBoostClassifier(random_state=RANDOM_SEED, verbose=False),\n","    #\"logistic_regression\": LogisticRegression(random_state=RANDOM_SEED, n_jobs=-1),\n","    \"knn\": KNeighborsClassifier(n_jobs=-1),\n","    \"stacked\": StackingClassifier(\n","        [\n","            (\"xgboost\", xgb.XGBClassifier(random_state=RANDOM_SEED, n_jobs=-1, **xgboost_best_params)),\n","            (\"lightgbm\", lightgbm.LGBMClassifier(random_state=RANDOM_SEED, n_jobs=-1, **lightgbm_best_params)),\n","            (\"catboost\", cb.CatBoostClassifier(random_state=RANDOM_SEED, verbose=False, **catboost_best_params)),\n","        ],\n","        final_estimator=LogisticRegression(random_state=RANDOM_SEED, n_jobs=-1),\n","        n_jobs=-1,\n","    ),\n","}\n","\n","trained_models = train_models(models, X_train, y_train, parameters=optuna_best_parameters_found)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_df = evaluate_models(trained_models, X_val, y_val)\n","results_df.sort_values(by=\"auc\", ascending=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_roc_curve(trained_models, X_val, y_val)"]},{"cell_type":"markdown","metadata":{},"source":["# Submission"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_df = pd.read_csv(input_folder + \"playground-series-s4e1/train.csv\", index_col=\"id\")\n","test_df = pd.read_csv(input_folder + \"playground-series-s4e1/test.csv\", index_col=\"id\")\n","submission_df = pd.read_csv(input_folder + \"playground-series-s4e1/sample_submission.csv\")\n","original_df = pd.read_csv(input_folder + \"bank-customer-churn-prediction/Churn_Modelling.csv\")\n","target_col = \"Exited\"\n","\n","numeric_features = ['CustomerId', 'CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n","categorical_features = ['Surname', 'Geography', 'Gender', 'HasCrCard', 'IsActiveMember']\n","\n","features_to_drop = ['CustomerId', 'Surname']\n","\n","GENERATED_COLUMN = True\n","ADD_ORIGINAL_DF = True\n","\n","model_postfix = \"_with_original\" if ADD_ORIGINAL_DF else \"\"\n","model_postfix += \"_generated\" if GENERATED_COLUMN else \"\"\n","\n","original_df = original_df.drop(columns=['RowNumber'])\n","\n","# drop na rows from orignal df\n","original_df = original_df.dropna()\n","\n","if GENERATED_COLUMN:\n","    train_df['generated'] = 1\n","    test_df['generated'] = 1\n","    original_df['generated'] = 0\n","    categorical_features.append('generated')\n","    \n","if ADD_ORIGINAL_DF:\n","    train_df = pd.concat([train_df, original_df])\n","\n","\n","for f in features_to_drop:\n","    if f in numeric_features:\n","        numeric_features.remove(f)\n","    if f in categorical_features:\n","        categorical_features.remove(f)\n","    \n","    train_df = train_df.drop(columns=f)\n","    test_df = test_df.drop(columns=f)\n","\n","train_df = initial_feature_engineering(train_df)\n","train_df = feature_engineering_1(train_df)\n","\n","test_df = initial_feature_engineering(test_df)\n","test_df = feature_engineering_1(test_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-04T20:09:37.302130Z","iopub.status.busy":"2024-01-04T20:09:37.301584Z","iopub.status.idle":"2024-01-04T20:09:50.619255Z","shell.execute_reply":"2024-01-04T20:09:50.617914Z","shell.execute_reply.started":"2024-01-04T20:09:37.302089Z"},"trusted":true},"outputs":[],"source":["# train model on train data\n","model = StackingClassifier(\n","    [\n","        (\"xgboost\", xgb.XGBClassifier(random_state=RANDOM_SEED, n_jobs=-1, **xgboost_best_params)),\n","        (\"lightgbm\", lightgbm.LGBMClassifier(random_state=RANDOM_SEED, n_jobs=-1, **lightgbm_best_params)),\n","        (\"catboost\", cb.CatBoostClassifier(random_state=RANDOM_SEED, verbose=False, **catboost_best_params)),\n","    ],\n","    final_estimator=LogisticRegression(random_state=RANDOM_SEED, n_jobs=-1),\n","    n_jobs=-1,\n",")\n","model = cb.CatBoostClassifier(random_state=RANDOM_SEED, verbose=False, **catboost_best_params)\n","model = create_pipeline(model)\n","X_train = train_df.drop(columns=target_col)\n","y_train = train_df[target_col]\n","X_test = test_df\n","\n","model.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{},"source":["Use for comparison or blending with other predictions:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-04T20:09:58.484835Z","iopub.status.busy":"2024-01-04T20:09:58.483806Z","iopub.status.idle":"2024-01-04T20:10:01.900339Z","shell.execute_reply":"2024-01-04T20:10:01.898976Z","shell.execute_reply.started":"2024-01-04T20:09:58.484778Z"},"trusted":true},"outputs":[],"source":["# predict on test data\n","y_pred = model.predict(X_test)\n","y_proba = model.predict_proba(X_test)[:, 1]\n","\n","\n","# create submission df\n","\n","submission_df = pd.DataFrame({\n","    \"id\": test_df.index,\n","    target_col: y_proba\n","})\n","submission_df.to_csv(\"./submission.csv\", index=False)\n","submission_df"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":7405009,"sourceId":65711,"sourceType":"competition"},{"datasetId":3191230,"sourceId":5536933,"sourceType":"datasetVersion"}],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
