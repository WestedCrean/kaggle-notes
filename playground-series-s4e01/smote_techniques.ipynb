{"cells":[{"cell_type":"markdown","metadata":{},"source":["# âš½S4E1 - EDA & initial submission - Binary Classification with a Bank Churn Dataset \n","\n","Welcome to 2024! For this Episode of the Series, your task is to predict whether a customer continues with their account or closes it (e.g., churns). Good luck!\n","\n","## Evaluation\n","\n","Submissions are evaluated on area under the ROC curve between the predicted probability and the observed target.\n","\n","## Submission Format\n","\n","For each id in the test set, you must predict the probability for the target variable Exited. The file should contain a header and have the following format:\n","\n","```\n","id,Exited\n","0,0.9\n","1,0.1\n","2,0.5\n","etc.\n","```\n","\n","## Data Description\n","\n","The dataset for this competition (both train and test) was generated from a deep learning model trained on the Bank Customer Churn Prediction dataset. Feature distributions are close to, but not exactly the same, as the original. \n","\n","# Code\n","\n","## ToC\n","\n","- [Imports](#Imports)\n","\n","\n","## Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-01-04T20:03:46.497400Z","iopub.status.busy":"2024-01-04T20:03:46.496914Z","iopub.status.idle":"2024-01-04T20:03:59.746581Z","shell.execute_reply":"2024-01-04T20:03:59.745260Z","shell.execute_reply.started":"2024-01-04T20:03:46.497360Z"},"trusted":true},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAZcAAABhCAYAAAAa2uy9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADKUlEQVR4nO3bz2qcZRjG4eedP2nsQCsh0SIFNz2BZO8p9CQ8Bg9AcO/GnoBuPQE3HkKCCLpxUTcFbQ2kJjWZmczrQnGZTOktn5+9rs1sHoabgY8fwzCt994LAIImQw8A4P9HXACIExcA4sQFgDhxASBOXACIExcA4sQFgLjZNkcnJyfVe6/5fP5v7wHgP2y1WlVrrQ4PD2+82youvffabDb162+v6tof+re2f3lV/WBR7flFtWuf2zb6tFV/b1Gz+ctqbTP0nNHofVLr5b2aXZ1W69dDzxmF3qa1urNXZ3VZm/J8but+7dZsMr31bqu4zOfzWi6X9eU3z+vZi+Ubj3tbfPH9d3X+5HEtPv22Zj+dDj1nFNaP9ur8yeN6+Ojr2r37y9BzRuPy1fv19MeP6+EPn9c7Fz8PPWcU/lh8WE+PPquv+kk9q9+HnjMan9RH9WD+7q13fnMBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIhrvfd+29Hx8XH13uvsfF3rza3n/G1/uay+v6j24qLaajP0nFHo80n1/UXN5i+rteuh54xG79Nar+7V7Oq02mY99JxR6JNZre/s1Vm/rOvyfG7rfu3WbDKto6OjG+9m27xZa62qqg727r75srfK4q+XD3aGnTFK+0MPGJXWqnZ2qmrnwdBTRqNV1U5VHZTn83WsVqt/mnCTrb65AMDr8JsLAHHiAkCcuAAQJy4AxIkLAHHiAkCcuAAQJy4AxP0JEUGH3u8dhhMAAAAASUVORK5CYII=","text/plain":["<Figure size 500x100 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# essentials\n","import os\n","import pathlib\n","from copy import copy\n","import json\n","\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","\n","# visualisation\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# sklearn imports\n","import sklearn\n","from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, cross_val_score\n","from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MaxAbsScaler, PowerTransformer, FunctionTransformer, StandardScaler\n","from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MaxAbsScaler, PowerTransformer, FunctionTransformer, StandardScaler\n","from sklearn.pipeline import Pipeline, make_pipeline, make_union, FeatureUnion\n","from sklearn.compose import ColumnTransformer\n","from sklearn.feature_selection import SelectKBest, chi2, f_classif, SequentialFeatureSelector, RFECV\n","from sklearn.calibration import CalibratedClassifierCV\n","from sklearn.base import clone as clone_model\n","from sklearn.metrics import classification_report, confusion_matrix, log_loss\n","from sklearn.impute import SimpleImputer, MissingIndicator, KNNImputer\n","\n","\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, StackingClassifier, VotingClassifier, AdaBoostClassifier\n","from sklearn.linear_model import LogisticRegression, ElasticNet, SGDClassifier, RidgeClassifier, PassiveAggressiveClassifier, TweedieRegressor\n","from sklearn.svm import SVC, LinearSVC, NuSVC\n","from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB, ComplementNB\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import RocCurveDisplay, roc_auc_score, make_scorer, roc_curve\n","\n","from sklearn.preprocessing import Binarizer, Normalizer, RobustScaler, StandardScaler\n","from sklearn.preprocessing import FunctionTransformer\n","\n","# others\n","import xgboost as xgb \n","import lightgbm as lgb\n","import catboost as cb\n","\n","import optuna\n","import shap\n","\n","RANDOM_SEED = 64\n","\n","palette = [\"#4464ad\", \"#dc136c\", \"#F4FF52\", \"#f58f29\",\"#45cb85\"]\n","\n","sns.set_theme(style=\"whitegrid\")\n","sns.set_palette(palette)\n","sns.palplot(palette)"]},{"cell_type":"markdown","metadata":{},"source":["## Data loading & EDA\n","\n","First we will check\n","\n","1. Number and types of columns\n","2. Number of rows in train and test\n","2. Missing values\n","3. Target variable distribution"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-01-04T20:04:02.461936Z","iopub.status.busy":"2024-01-04T20:04:02.461081Z","iopub.status.idle":"2024-01-04T20:04:03.308882Z","shell.execute_reply":"2024-01-04T20:04:03.307180Z","shell.execute_reply.started":"2024-01-04T20:04:02.461876Z"},"trusted":true},"outputs":[],"source":["IN_KAGGLE = False\n","\n","kaggle_folder = \"/kaggle/input/\"\n","local_folder = \"./data/\"\n","input_folder = kaggle_folder if IN_KAGGLE else local_folder\n","\n","train_df = pd.read_csv(input_folder + \"playground-series-s4e1/train.csv\", index_col=\"id\")\n","test_df = pd.read_csv(input_folder + \"playground-series-s4e1/test.csv\", index_col=\"id\")\n","submission_df = pd.read_csv(input_folder + \"playground-series-s4e1/sample_submission.csv\")\n","original_df = pd.read_csv(input_folder + \"bank-customer-churn-prediction/Churn_Modelling.csv\")\n","target_col = \"Exited\"\n","\n","numeric_features = ['CustomerId', 'CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n","categorical_features = ['Surname', 'Geography', 'Gender', 'HasCrCard', 'IsActiveMember']\n","\n","features_to_drop = ['CustomerId', 'Surname']\n","\n","GENERATED_COLUMN = True\n","ADD_ORIGINAL_DF = True\n","\n","model_postfix = \"_with_original\" if ADD_ORIGINAL_DF else \"\"\n","model_postfix += \"_generated\" if GENERATED_COLUMN else \"\"\n","\n","original_df = original_df.drop(columns=['RowNumber'])\n","\n","# drop na rows from orignal df\n","original_df = original_df.dropna()\n","\n","if GENERATED_COLUMN:\n","    train_df['generated'] = 1\n","    test_df['generated'] = 1\n","    original_df['generated'] = 0\n","    categorical_features.append('generated')\n","    \n","if ADD_ORIGINAL_DF:\n","    train_df = pd.concat([train_df, original_df])\n","\n","\n","for f in features_to_drop:\n","    if f in numeric_features:\n","        numeric_features.remove(f)\n","    if f in categorical_features:\n","        categorical_features.remove(f)\n","    \n","    train_df = train_df.drop(columns=f)\n","\n","def initial_feature_engineering(df):\n","    df['HasCrCard'] = df['HasCrCard'].astype('bool')\n","    df['IsActiveMember'] = df['IsActiveMember'].astype('bool')\n","    df['Gender'] = df['Gender'].map({ \"Male\": 0, \"Female\": 1}).astype(\"bool\")\n","    # encode geography\n","    df = pd.get_dummies(df, columns=['Geography'])\n","\n","    return df\n","\n","def feature_engineering_1(df):\n","    # Balance\n","    df['balance_over_100k'] = df['Balance'] >= 100000\n","    df['balance_over_150k'] = df['Balance'] >= 150000\n","\n","    # EstimatedSalary\n","    df[\"estimated_salary_under_50k\"] = df[\"EstimatedSalary\"] < 50000\n","    df[\"estimated_salary_50k_to_100k\"] = (df[\"EstimatedSalary\"] >= 50000) & (df[\"EstimatedSalary\"] < 100000)\n","    df[\"estamated_salary_over_150k\"] = df[\"EstimatedSalary\"] >= 150000\n","\n","    # NumOfProducts\n","    df[\"num_of_products_3_or_4\"] = df[\"NumOfProducts\"] >= 3\n","\n","    # Age\n","    df[\"age_over_40\"] = df[\"Age\"] >= 40\n","    df[\"age_over_50\"] = df[\"Age\"] >= 50\n","    df[\"age_over_60\"] = df[\"Age\"] >= 60\n","\n","    new_features = [\n","        \"balance_over_100k\",\n","        \"balance_over_150k\",\n","        \"estimated_salary_under_50k\",\n","        \"estimated_salary_50k_to_100k\",\n","        \"estamated_salary_over_150k\",\n","        \"num_of_products_3_or_4\",\n","        \"age_over_40\",\n","        \"age_over_50\",\n","        \"age_over_60\",\n","    ]\n","    for f in new_features:\n","        df[f] = df[f].astype(\"int\")\n","\n","    return df\n","\n","train_df = initial_feature_engineering(train_df)\n","train_df = feature_engineering_1(train_df)\n","X_train, X_val, y_train, y_val = train_test_split(train_df.drop(columns=target_col), train_df[target_col], test_size=0.2, random_state=RANDOM_SEED, stratify=train_df[target_col])"]},{"cell_type":"markdown","metadata":{},"source":["## Ideas for feature engineering"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-01-04T20:04:03.311250Z","iopub.status.busy":"2024-01-04T20:04:03.310809Z","iopub.status.idle":"2024-01-04T20:04:03.330270Z","shell.execute_reply":"2024-01-04T20:04:03.328813Z","shell.execute_reply.started":"2024-01-04T20:04:03.311211Z"},"trusted":true},"outputs":[],"source":["def create_pipeline(model, numeric_scalers=(\"scaler\", StandardScaler())):\n","    numeric_pipeline = Pipeline(\n","        [numeric_scalers]\n","    )\n","\n","    categorical_pipeline = Pipeline([\n","        #(\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n","        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\", drop='if_binary')),\n","    ])\n","\n","    preprocessor = ColumnTransformer([\n","        (\"numeric\", numeric_pipeline, numeric_features),\n","        #(\"categorical\", categorical_pipeline, categorical_features),\n","    ], remainder='passthrough')\n","\n","    return Pipeline([\n","        (\"preprocessor\", preprocessor),\n","        (\"classifier\", model),\n","    ])\n","\n","def train_models(models, X_train, y_train, parameters={}):\n","    trained_models = {}\n","    for model_name, model in tqdm(models.items()):\n","        if model_name in parameters:\n","            model.set_params(**parameters[model_name])\n","        model = create_pipeline(model)\n","        model.fit(X_train, y_train)\n","        trained_models[model_name] = model\n","    return trained_models\n","\n","def evaluate_models(models, X_val, y_val):\n","    # create a dataframe with \"model_name\", \"accuracy\", \"precision\", \"recall\", \"area under the ROC curve\"\n","    results_df = pd.DataFrame(columns=[\"model_name\", \"accuracy\", \"precision\", \"recall\", \"auc\"])\n","\n","    for model_name, model in tqdm(models.items()):\n","        y_pred = model.predict(X_val)\n","        y_proba = model.predict_proba(X_val)[:, 1]\n","        results_df = pd.concat([\n","            results_df,\n","            pd.DataFrame({\n","                \"model_name\": [model_name],\n","                \"accuracy\": [model.score(X_val, y_val)],\n","                \"precision\": [sklearn.metrics.precision_score(y_val, y_pred)],\n","                \"recall\": [sklearn.metrics.recall_score(y_val, y_pred)],\n","                \"auc\": [sklearn.metrics.roc_auc_score(y_val, y_proba)],\n","            })\n","        ])\n","    return results_df\n","\n","def plot_roc_curve(models, X_val, y_val):\n","    fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n","    palette_to_use = sns.color_palette(\"husl\", len(models))\n","    # for each model, plot the roc curve in the same plot, with other color\n","    for i, (model_name, model) in enumerate(models.items()):\n","        y_proba = model.predict_proba(X_val)[:, 1]\n","        fpr, tpr, _ = roc_curve(y_val, y_proba)\n","        roc_auc = roc_auc_score(y_val, y_proba)\n","        ax.plot(fpr, tpr, label=f\"{model_name} (AUC = {roc_auc:.2f})\", color=palette_to_use[i])\n","        ax.plot([0, 1], [0, 1], color='black', linestyle='--')\n","    ax.set_xlabel(\"False Positive Rate\")\n","    ax.set_ylabel(\"True Positive Rate\")\n","    ax.set_title(\"ROC Curve\")\n","    # show legend\n","    ax.legend()\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-01-04T20:09:02.848675Z","iopub.status.busy":"2024-01-04T20:09:02.848177Z","iopub.status.idle":"2024-01-04T20:09:02.915864Z","shell.execute_reply":"2024-01-04T20:09:02.914115Z","shell.execute_reply.started":"2024-01-04T20:09:02.848634Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training models...\n"]},{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00,  4.05s/it]\n"]}],"source":["trained_models = {}\n","\n","# generate random seed\n","models = {\n","    \"xgboost\": xgb.XGBClassifier(random_state=RANDOM_SEED, n_jobs=-1),\n","    \"lightgbm\": lgb.LGBMClassifier(random_state=RANDOM_SEED, n_jobs=-1, verbosity=-1),\n","    \"catboost\": cb.CatBoostClassifier(random_state=RANDOM_SEED, verbose=False, thread_count=16),\n","    #\"knn\": KNeighborsClassifier(n_jobs=-1),\n","    #\"random_forest\": RandomForestClassifier(random_state=RANDOM_SEED, n_jobs=-1),\n","    #\"gradient_boosting\": GradientBoostingClassifier(random_state=RANDOM_SEED),\n","    #\"extra_trees\": ExtraTreesClassifier(random_state=RANDOM_SEED, n_jobs=-1),\n","    #\"bagging\": BaggingClassifier(random_state=RANDOM_SEED, n_jobs=-1),\n","    #\"ada_boost\": AdaBoostClassifier(random_state=RANDOM_SEED),\n","    #\"sgd\": SGDClassifier(random_state=RANDOM_SEED, loss=\"log_loss\", n_jobs=-1),\n","}\n","\n","print(\"Training models...\")\n","\n","trained_models = {}\n","for model_name, model in tqdm(models.items()):\n","    model = clone_model(model)\n","    model = create_pipeline(model)\n","    model.fit(X_train, y_train)\n","    trained_models[model_name] = model\n","\n","#print(\"Evaluating models...\")\n","#results_df = evaluate_models(trained_models, X_val, y_val)\n","#results_df.sort_values(by=\"auc\", ascending=False)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 140025 entries, 140341 to 73494\n","Data columns (total 22 columns):\n"," #   Column                        Non-Null Count   Dtype  \n","---  ------                        --------------   -----  \n"," 0   CreditScore                   140025 non-null  int64  \n"," 1   Gender                        140025 non-null  bool   \n"," 2   Age                           140025 non-null  float64\n"," 3   Tenure                        140025 non-null  int64  \n"," 4   Balance                       140025 non-null  float64\n"," 5   NumOfProducts                 140025 non-null  int64  \n"," 6   HasCrCard                     140025 non-null  bool   \n"," 7   IsActiveMember                140025 non-null  bool   \n"," 8   EstimatedSalary               140025 non-null  float64\n"," 9   generated                     140025 non-null  int64  \n"," 10  Geography_France              140025 non-null  bool   \n"," 11  Geography_Germany             140025 non-null  bool   \n"," 12  Geography_Spain               140025 non-null  bool   \n"," 13  balance_over_100k             140025 non-null  int64  \n"," 14  balance_over_150k             140025 non-null  int64  \n"," 15  estimated_salary_under_50k    140025 non-null  int64  \n"," 16  estimated_salary_50k_to_100k  140025 non-null  int64  \n"," 17  estamated_salary_over_150k    140025 non-null  int64  \n"," 18  num_of_products_3_or_4        140025 non-null  int64  \n"," 19  age_over_40                   140025 non-null  int64  \n"," 20  age_over_50                   140025 non-null  int64  \n"," 21  age_over_60                   140025 non-null  int64  \n","dtypes: bool(6), float64(3), int64(13)\n","memory usage: 19.0 MB\n"]}],"source":["X_train.info()"]},{"cell_type":"markdown","metadata":{},"source":["## Oversampling"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":[" 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:27<00:27, 27.38s/it]"]}],"source":["from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN, SVMSMOTE, KMeansSMOTE, BorderlineSMOTE, SMOTEN, SMOTENC\n","from imblearn.combine import SMOTEENN\n","from imblearn.ensemble import BalancedBaggingClassifier\n","from imblearn.pipeline import Pipeline as imPipeline\n","from joblib import parallel_config\n","\n","sampling_techniques = {\n","    #\"randomoversampler\": RandomOverSampler(random_state=RANDOM_SEED),\n","    #\"smote\": SMOTE(),\n","    #\"adasyn\": ADASYN(),\n","    \"borderlinesmote\": BorderlineSMOTE(),\n","    \"smotenc\": SMOTENC(categorical_features=[1, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]),\n","}\n","\n","def create_oversampling_pipeline(model, numeric_scalers=(\"scaler\", StandardScaler()), sampling_class=RandomOverSampler(random_state=RANDOM_SEED)):\n","    numeric_pipeline = Pipeline(\n","        [numeric_scalers]\n","    )\n","\n","    categorical_pipeline = Pipeline([\n","        #(\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n","        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\", drop='if_binary')),\n","    ])\n","\n","    preprocessor = ColumnTransformer([\n","        (\"numeric\", numeric_pipeline, numeric_features),\n","        #(\"categorical\", categorical_pipeline, categorical_features),\n","    ], remainder='passthrough')\n","\n","    return imPipeline([\n","        (\"resampler\", sampling_class),\n","        (\"preprocessor\", preprocessor),\n","        (\"classifier\", model),\n","    ])\n","\n","with parallel_config(backend='threading', n_jobs=12):\n","    for sampling_name, sampling_class in tqdm(sampling_techniques.items()):\n","        for model_name, model in models.items():\n","            model = clone_model(model)\n","            model = create_oversampling_pipeline(model, sampling_class=sampling_class)\n","            model.fit(X_train, y_train)\n","            trained_models[model_name + f\"_{sampling_name}\"] = model\n","\n","    print(\"Evaluating models...\")\n","results_df = evaluate_models(trained_models, X_val, y_val)\n","results_df.sort_values(by=\"auc\", ascending=False)"]},{"cell_type":"markdown","metadata":{},"source":["## Undersampling"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from imblearn.under_sampling import RandomUnderSampler, AllKNN, InstanceHardnessThreshold\n","from imblearn.combine import SMOTEENN\n","from imblearn.ensemble import BalancedBaggingClassifier\n","from imblearn.pipeline import Pipeline as imPipeline\n","\n","sampling_techniques = {\n","    \"randomundersampler\": RandomUnderSampler(random_state=RANDOM_SEED),\n","    \"AllKNN\": AllKNN(),\n","    \"InstanceHardnessThreshold\": InstanceHardnessThreshold(random_state=RANDOM_SEED),\n","    \"SMOTEENN\": SMOTEENN(random_state=RANDOM_SEED),\n","}\n","\n","def create_oversampling_pipeline(model, numeric_scalers=(\"scaler\", StandardScaler()), sampling_class=RandomOverSampler):\n","    numeric_pipeline = Pipeline(\n","        [numeric_scalers]\n","    )\n","\n","    categorical_pipeline = Pipeline([\n","        #(\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n","        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\", drop='if_binary')),\n","    ])\n","\n","    preprocessor = ColumnTransformer([\n","        (\"numeric\", numeric_pipeline, numeric_features),\n","        #(\"categorical\", categorical_pipeline, categorical_features),\n","    ], remainder='passthrough')\n","\n","    return imPipeline([\n","        (\"resampler\", sampling_class),\n","        (\"preprocessor\", preprocessor),\n","        (\"classifier\", model),\n","    ])\n","\n","for sampling_name, sampling_class in tqdm(sampling_techniques.items()):\n","    for model_name, model in models.items():\n","        model = clone_model(model)\n","        model = create_oversampling_pipeline(model, sampling_class=sampling_class)\n","        model.fit(X_train, y_train)\n","        trained_models[model_name + f\"_{sampling_name}\"] = model\n","\n","print(\"Evaluating models...\")\n","results_df = evaluate_models(trained_models, X_val, y_val)\n","results_df.sort_values(by=\"auc\", ascending=False)"]},{"cell_type":"markdown","metadata":{},"source":["## Other"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["raise Exception(\"Stop here\")"]},{"cell_type":"markdown","metadata":{},"source":["## Best params"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["best_params_lightgbm = lightgbm_best_params\n","best_params_xgboost = xgboost_best_params\n","best_params_catboost = catboost_best_params\n","\n","optuna_best_parameters_found = {\n","    \"xgboost\": xgboost_best_params,\n","    \"lightgbm\": lightgbm_best_params,\n","    \"catboost\": catboost_best_params,\n","}\n","\n","optuna_best_parameters_found"]},{"cell_type":"markdown","metadata":{},"source":["## Submission"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import lightgbm\n","\n","models = {\n","    \"xgboost\": xgb.XGBClassifier(random_state=RANDOM_SEED, n_jobs=-1),\n","    \"lightgbm\": lightgbm.LGBMClassifier(random_state=RANDOM_SEED, n_jobs=-1, verbosity=-1),\n","    \"catboost\": cb.CatBoostClassifier(random_state=RANDOM_SEED, verbose=False),\n","    #\"logistic_regression\": LogisticRegression(random_state=RANDOM_SEED, n_jobs=-1),\n","    \"knn\": KNeighborsClassifier(n_jobs=-1),\n","    \"stacked\": StackingClassifier(\n","        [\n","            (\"xgboost\", xgb.XGBClassifier(random_state=RANDOM_SEED, n_jobs=-1, **xgboost_best_params)),\n","            (\"lightgbm\", lightgbm.LGBMClassifier(random_state=RANDOM_SEED, n_jobs=-1, **lightgbm_best_params)),\n","            (\"catboost\", cb.CatBoostClassifier(random_state=RANDOM_SEED, verbose=False, **catboost_best_params)),\n","        ],\n","        final_estimator=LogisticRegression(random_state=RANDOM_SEED, n_jobs=-1),\n","        n_jobs=-1,\n","    ),\n","}\n","\n","trained_models = train_models(models, X_train, y_train, parameters=optuna_best_parameters_found)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_df = evaluate_models(trained_models, X_val, y_val)\n","results_df.sort_values(by=\"auc\", ascending=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_roc_curve(trained_models, X_val, y_val)"]},{"cell_type":"markdown","metadata":{},"source":["# Submission"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_df = pd.read_csv(input_folder + \"playground-series-s4e1/train.csv\", index_col=\"id\")\n","test_df = pd.read_csv(input_folder + \"playground-series-s4e1/test.csv\", index_col=\"id\")\n","submission_df = pd.read_csv(input_folder + \"playground-series-s4e1/sample_submission.csv\")\n","original_df = pd.read_csv(input_folder + \"bank-customer-churn-prediction/Churn_Modelling.csv\")\n","target_col = \"Exited\"\n","\n","numeric_features = ['CustomerId', 'CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n","categorical_features = ['Surname', 'Geography', 'Gender', 'HasCrCard', 'IsActiveMember']\n","\n","features_to_drop = ['CustomerId', 'Surname']\n","\n","GENERATED_COLUMN = True\n","ADD_ORIGINAL_DF = True\n","\n","model_postfix = \"_with_original\" if ADD_ORIGINAL_DF else \"\"\n","model_postfix += \"_generated\" if GENERATED_COLUMN else \"\"\n","\n","original_df = original_df.drop(columns=['RowNumber'])\n","\n","# drop na rows from orignal df\n","original_df = original_df.dropna()\n","\n","if GENERATED_COLUMN:\n","    train_df['generated'] = 1\n","    test_df['generated'] = 1\n","    original_df['generated'] = 0\n","    categorical_features.append('generated')\n","    \n","if ADD_ORIGINAL_DF:\n","    train_df = pd.concat([train_df, original_df])\n","\n","\n","for f in features_to_drop:\n","    if f in numeric_features:\n","        numeric_features.remove(f)\n","    if f in categorical_features:\n","        categorical_features.remove(f)\n","    \n","    train_df = train_df.drop(columns=f)\n","    test_df = test_df.drop(columns=f)\n","\n","train_df = initial_feature_engineering(train_df)\n","train_df = feature_engineering_1(train_df)\n","\n","test_df = initial_feature_engineering(test_df)\n","test_df = feature_engineering_1(test_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-04T20:09:37.302130Z","iopub.status.busy":"2024-01-04T20:09:37.301584Z","iopub.status.idle":"2024-01-04T20:09:50.619255Z","shell.execute_reply":"2024-01-04T20:09:50.617914Z","shell.execute_reply.started":"2024-01-04T20:09:37.302089Z"},"trusted":true},"outputs":[],"source":["# train model on train data\n","model = StackingClassifier(\n","    [\n","        (\"xgboost\", xgb.XGBClassifier(random_state=RANDOM_SEED, n_jobs=-1, **xgboost_best_params)),\n","        (\"lightgbm\", lightgbm.LGBMClassifier(random_state=RANDOM_SEED, n_jobs=-1, **lightgbm_best_params)),\n","        (\"catboost\", cb.CatBoostClassifier(random_state=RANDOM_SEED, verbose=False, **catboost_best_params)),\n","    ],\n","    final_estimator=LogisticRegression(random_state=RANDOM_SEED, n_jobs=-1),\n","    n_jobs=-1,\n",")\n","model = cb.CatBoostClassifier(random_state=RANDOM_SEED, verbose=False, **catboost_best_params)\n","model = create_pipeline(model)\n","X_train = train_df.drop(columns=target_col)\n","y_train = train_df[target_col]\n","X_test = test_df\n","\n","model.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{},"source":["Use for comparison or blending with other predictions:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-04T20:09:58.484835Z","iopub.status.busy":"2024-01-04T20:09:58.483806Z","iopub.status.idle":"2024-01-04T20:10:01.900339Z","shell.execute_reply":"2024-01-04T20:10:01.898976Z","shell.execute_reply.started":"2024-01-04T20:09:58.484778Z"},"trusted":true},"outputs":[],"source":["# predict on test data\n","y_pred = model.predict(X_test)\n","y_proba = model.predict_proba(X_test)[:, 1]\n","\n","\n","# create submission df\n","\n","submission_df = pd.DataFrame({\n","    \"id\": test_df.index,\n","    target_col: y_proba\n","})\n","submission_df.to_csv(\"./submission.csv\", index=False)\n","submission_df"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":7405009,"sourceId":65711,"sourceType":"competition"},{"datasetId":3191230,"sourceId":5536933,"sourceType":"datasetVersion"}],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
