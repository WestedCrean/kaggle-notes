{"cells":[{"cell_type":"markdown","metadata":{},"source":["# âš½S4E1 - Gluon\n","\n","Welcome to 2024! For this Episode of the Series, your task is to predict whether a customer continues with their account or closes it (e.g., churns). Good luck!"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-01-04T20:03:46.497400Z","iopub.status.busy":"2024-01-04T20:03:46.496914Z","iopub.status.idle":"2024-01-04T20:03:59.746581Z","shell.execute_reply":"2024-01-04T20:03:59.745260Z","shell.execute_reply.started":"2024-01-04T20:03:46.497360Z"},"trusted":true},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAZcAAABhCAYAAAAa2uy9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADKUlEQVR4nO3bz2qcZRjG4eedP2nsQCsh0SIFNz2BZO8p9CQ8Bg9AcO/GnoBuPQE3HkKCCLpxUTcFbQ2kJjWZmczrQnGZTOktn5+9rs1sHoabgY8fwzCt994LAIImQw8A4P9HXACIExcA4sQFgDhxASBOXACIExcA4sQFgLjZNkcnJyfVe6/5fP5v7wHgP2y1WlVrrQ4PD2+82youvffabDb162+v6tof+re2f3lV/WBR7flFtWuf2zb6tFV/b1Gz+ctqbTP0nNHofVLr5b2aXZ1W69dDzxmF3qa1urNXZ3VZm/J8but+7dZsMr31bqu4zOfzWi6X9eU3z+vZi+Ubj3tbfPH9d3X+5HEtPv22Zj+dDj1nFNaP9ur8yeN6+Ojr2r37y9BzRuPy1fv19MeP6+EPn9c7Fz8PPWcU/lh8WE+PPquv+kk9q9+HnjMan9RH9WD+7q13fnMBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIhrvfd+29Hx8XH13uvsfF3rza3n/G1/uay+v6j24qLaajP0nFHo80n1/UXN5i+rteuh54xG79Nar+7V7Oq02mY99JxR6JNZre/s1Vm/rOvyfG7rfu3WbDKto6OjG+9m27xZa62qqg727r75srfK4q+XD3aGnTFK+0MPGJXWqnZ2qmrnwdBTRqNV1U5VHZTn83WsVqt/mnCTrb65AMDr8JsLAHHiAkCcuAAQJy4AxIkLAHHiAkCcuAAQJy4AxP0JEUGH3u8dhhMAAAAASUVORK5CYII=","text/plain":["<Figure size 500x100 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# essentials\n","import os\n","import pathlib\n","from copy import copy\n","import json\n","\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","\n","# visualisation\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# sklearn imports\n","import sklearn\n","from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, cross_val_score\n","from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MaxAbsScaler, PowerTransformer, FunctionTransformer, StandardScaler\n","from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MaxAbsScaler, PowerTransformer, FunctionTransformer, StandardScaler\n","from sklearn.pipeline import Pipeline, make_pipeline, make_union, FeatureUnion\n","from sklearn.compose import ColumnTransformer\n","from sklearn.feature_selection import SelectKBest, chi2, f_classif, SequentialFeatureSelector, RFECV\n","from sklearn.calibration import CalibratedClassifierCV\n","from sklearn.base import clone as clone_model\n","from sklearn.metrics import classification_report, confusion_matrix, log_loss\n","from sklearn.impute import SimpleImputer, MissingIndicator, KNNImputer\n","\n","\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, StackingClassifier, VotingClassifier, AdaBoostClassifier\n","from sklearn.linear_model import LogisticRegression, ElasticNet, SGDClassifier, RidgeClassifier, PassiveAggressiveClassifier, TweedieRegressor\n","from sklearn.svm import SVC, LinearSVC, NuSVC\n","from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB, ComplementNB\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import RocCurveDisplay, roc_auc_score, make_scorer, roc_curve\n","\n","from sklearn.preprocessing import Binarizer, Normalizer, RobustScaler, StandardScaler\n","from sklearn.preprocessing import FunctionTransformer\n","\n","# others\n","import xgboost as xgb \n","import lightgbm as lgb\n","import catboost as cb\n","\n","import optuna\n","import shap\n","\n","RANDOM_SEED = 64\n","\n","palette = [\"#4464ad\", \"#dc136c\", \"#F4FF52\", \"#f58f29\",\"#45cb85\"]\n","\n","sns.set_theme(style=\"whitegrid\")\n","sns.set_palette(palette)\n","sns.palplot(palette)"]},{"cell_type":"markdown","metadata":{},"source":["## Data loading & EDA\n","\n","First we will check\n","\n","1. Number and types of columns\n","2. Number of rows in train and test\n","2. Missing values\n","3. Target variable distribution"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-01-04T20:04:02.461936Z","iopub.status.busy":"2024-01-04T20:04:02.461081Z","iopub.status.idle":"2024-01-04T20:04:03.308882Z","shell.execute_reply":"2024-01-04T20:04:03.307180Z","shell.execute_reply.started":"2024-01-04T20:04:02.461876Z"},"trusted":true},"outputs":[],"source":["IN_KAGGLE = True\n","\n","kaggle_folder = \"/kaggle/input/\"\n","local_folder = \"./data/\"\n","input_folder = kaggle_folder if IN_KAGGLE else local_folder\n","output_folder = \"/kaggle/output/\" if IN_KAGGLE else \"./\"\n","\n","train_df = pd.read_csv(input_folder + \"playground-series-s4e1/train.csv\", index_col=\"id\")\n","test_df = pd.read_csv(input_folder + \"playground-series-s4e1/test.csv\", index_col=\"id\")\n","submission_df = pd.read_csv(input_folder + \"playground-series-s4e1/sample_submission.csv\")\n","original_df = pd.read_csv(input_folder + \"bank-customer-churn-prediction/Churn_Modelling.csv\")\n","target_col = \"Exited\"\n","\n","numeric_features = ['CustomerId', 'CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n","categorical_features = ['Surname', 'Geography', 'Gender', 'HasCrCard', 'IsActiveMember']\n","\n","features_to_drop = ['CustomerId', 'Surname']\n","\n","GENERATED_COLUMN = True\n","ADD_ORIGINAL_DF = True\n","\n","model_postfix = \"_with_original\" if ADD_ORIGINAL_DF else \"\"\n","model_postfix += \"_generated\" if GENERATED_COLUMN else \"\"\n","\n","original_df = original_df.drop(columns=['RowNumber'])\n","\n","# drop na rows from orignal df\n","original_df = original_df.dropna()\n","\n","if GENERATED_COLUMN:\n","    train_df['generated'] = 1\n","    test_df['generated'] = 1\n","    original_df['generated'] = 0\n","    categorical_features.append('generated')\n","    \n","if ADD_ORIGINAL_DF:\n","    train_df = pd.concat([train_df, original_df])\n","\n","\n","for f in features_to_drop:\n","    if f in numeric_features:\n","        numeric_features.remove(f)\n","    if f in categorical_features:\n","        categorical_features.remove(f)\n","    \n","    train_df = train_df.drop(columns=f)\n","\n","def initial_feature_engineering(df):\n","    df['HasCrCard'] = df['HasCrCard'].astype('bool')\n","    df['IsActiveMember'] = df['IsActiveMember'].astype('bool')\n","    #df['Gender'] = df['Gender'].map({ \"Male\": 0, \"Female\": 1}).astype(\"bool\")\n","    # encode geography\n","    #df = pd.get_dummies(df, columns=['Geography'])\n","\n","    return df\n","\n","def feature_engineering_1(df):\n","    # Balance\n","    df['balance_over_100k'] = df['Balance'] >= 100000\n","    df['balance_over_150k'] = df['Balance'] >= 150000\n","\n","    # EstimatedSalary\n","    df[\"estimated_salary_under_50k\"] = df[\"EstimatedSalary\"] < 50000\n","    df[\"estimated_salary_50k_to_100k\"] = (df[\"EstimatedSalary\"] >= 50000) & (df[\"EstimatedSalary\"] < 100000)\n","    df[\"estamated_salary_over_150k\"] = df[\"EstimatedSalary\"] >= 150000\n","\n","    # NumOfProducts\n","    df[\"num_of_products_3_or_4\"] = df[\"NumOfProducts\"] >= 3\n","\n","    # Age\n","    df[\"age_over_40\"] = df[\"Age\"] >= 40\n","    df[\"age_over_50\"] = df[\"Age\"] >= 50\n","    df[\"age_over_60\"] = df[\"Age\"] >= 60\n","\n","    new_features = [\n","        \"balance_over_100k\",\n","        \"balance_over_150k\",\n","        \"estimated_salary_under_50k\",\n","        \"estimated_salary_50k_to_100k\",\n","        \"estamated_salary_over_150k\",\n","        \"num_of_products_3_or_4\",\n","        \"age_over_40\",\n","        \"age_over_50\",\n","        \"age_over_60\",\n","    ]\n","    for f in new_features:\n","        df[f] = df[f].astype(\"int\")\n","\n","    return df\n","\n","train_df = initial_feature_engineering(train_df)\n","#train_df = feature_engineering_1(train_df)\n","\n","X_train, X_val, y_train, y_val = train_test_split(train_df.drop(columns=target_col), train_df[target_col], test_size=0.4, random_state=RANDOM_SEED, stratify=train_df[target_col])"]},{"cell_type":"markdown","metadata":{},"source":["## Ideas for feature engineering"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-01-04T20:04:03.311250Z","iopub.status.busy":"2024-01-04T20:04:03.310809Z","iopub.status.idle":"2024-01-04T20:04:03.330270Z","shell.execute_reply":"2024-01-04T20:04:03.328813Z","shell.execute_reply.started":"2024-01-04T20:04:03.311211Z"},"trusted":true},"outputs":[],"source":["def create_pipeline(model, numeric_scalers=(\"scaler\", StandardScaler())):\n","    numeric_pipeline = Pipeline(\n","        [numeric_scalers]\n","    )\n","\n","    categorical_pipeline = Pipeline([\n","        #(\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n","        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\", drop='if_binary')),\n","    ])\n","\n","    preprocessor = ColumnTransformer([\n","        (\"numeric\", numeric_pipeline, numeric_features),\n","        #(\"categorical\", categorical_pipeline, categorical_features),\n","    ], remainder='passthrough')\n","\n","    return Pipeline([\n","        (\"preprocessor\", preprocessor),\n","        (\"classifier\", model),\n","    ])\n","\n","def train_models(models, X_train, y_train, parameters={}):\n","    trained_models = {}\n","    for model_name, model in tqdm(models.items()):\n","        if model_name in parameters:\n","            model.set_params(**parameters[model_name])\n","        model = create_pipeline(model)\n","        model.fit(X_train, y_train)\n","        trained_models[model_name] = model\n","    return trained_models\n","\n","def evaluate_models(models, X_val, y_val):\n","    # create a dataframe with \"model_name\", \"accuracy\", \"precision\", \"recall\", \"area under the ROC curve\"\n","    results_df = pd.DataFrame(columns=[\"model_name\", \"accuracy\", \"precision\", \"recall\", \"auc\"])\n","\n","    for model_name, model in tqdm(models.items()):\n","        y_pred = model.predict(X_val)\n","        y_proba = model.predict_proba(X_val)[:, 1]\n","        results_df = pd.concat([\n","            results_df,\n","            pd.DataFrame({\n","                \"model_name\": [model_name],\n","                \"accuracy\": [model.score(X_val, y_val)],\n","                \"precision\": [sklearn.metrics.precision_score(y_val, y_pred)],\n","                \"recall\": [sklearn.metrics.recall_score(y_val, y_pred)],\n","                \"auc\": [sklearn.metrics.roc_auc_score(y_val, y_proba)],\n","            })\n","        ])\n","    return results_df\n","\n","def plot_roc_curve(models, X_val, y_val):\n","    fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n","    palette_to_use = sns.color_palette(\"husl\", len(models))\n","    # for each model, plot the roc curve in the same plot, with other color\n","    for i, (model_name, model) in enumerate(models.items()):\n","        y_proba = model.predict_proba(X_val)[:, 1]\n","        fpr, tpr, _ = roc_curve(y_val, y_proba)\n","        roc_auc = roc_auc_score(y_val, y_proba)\n","        ax.plot(fpr, tpr, label=f\"{model_name} (AUC = {roc_auc:.2f})\", color=palette_to_use[i])\n","        ax.plot([0, 1], [0, 1], color='black', linestyle='--')\n","    ax.set_xlabel(\"False Positive Rate\")\n","    ax.set_ylabel(\"True Positive Rate\")\n","    ax.set_title(\"ROC Curve\")\n","    # show legend\n","    ax.legend()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Gluon"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["No path specified. Models will be saved in: \"AutogluonModels/ag-20240108_152104\"\n","No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n","\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n","\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n","\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n","\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n","\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n","Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (105019 samples, 20.89 MB).\n","\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n","Beginning AutoGluon training ...\n","AutoGluon will save models to \"AutogluonModels/ag-20240108_152104\"\n","=================== System Info ===================\n","AutoGluon Version:  1.0.0\n","Python Version:     3.11.3\n","Operating System:   Linux\n","Platform Machine:   x86_64\n","Platform Version:   #1 SMP Thu Oct 5 21:02:42 UTC 2023\n","CPU Count:          16\n","Memory Avail:       17.18 GB / 23.47 GB (73.2%)\n","Disk Space Avail:   874.95 GB / 1006.85 GB (86.9%)\n","===================================================\n","Train Data Rows:    105019\n","Train Data Columns: 11\n","Label Column:       Exited\n","AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n","\t2 unique label values:  [0, 1]\n","\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n","Problem Type:       binary\n","Preprocessing data ...\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n","Using Feature Generators to preprocess the data ...\n","Fitting AutoMLPipelineFeatureGenerator...\n","\tAvailable Memory:                    17607.37 MB\n","\tTrain Data (Original)  Memory Usage: 18.32 MB (0.1% of available memory)\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n","\tStage 1 Generators:\n","\t\tFitting AsTypeFeatureGenerator...\n","\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n","\tStage 2 Generators:\n","\t\tFitting FillNaFeatureGenerator...\n","\tStage 3 Generators:\n","\t\tFitting IdentityFeatureGenerator...\n","\t\tFitting CategoryFeatureGenerator...\n","\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n","\tStage 4 Generators:\n","\t\tFitting DropUniqueFeatureGenerator...\n","\tStage 5 Generators:\n","\t\tFitting DropDuplicatesFeatureGenerator...\n","\tTypes of features in original data (raw dtype, special dtypes):\n","\t\t('bool', [])   : 2 | ['HasCrCard', 'IsActiveMember']\n","\t\t('float', [])  : 3 | ['Age', 'Balance', 'EstimatedSalary']\n","\t\t('int', [])    : 4 | ['CreditScore', 'Tenure', 'NumOfProducts', 'generated']\n","\t\t('object', []) : 2 | ['Geography', 'Gender']\n","\tTypes of features in processed data (raw dtype, special dtypes):\n","\t\t('category', [])  : 1 | ['Geography']\n","\t\t('float', [])     : 3 | ['Age', 'Balance', 'EstimatedSalary']\n","\t\t('int', [])       : 3 | ['CreditScore', 'Tenure', 'NumOfProducts']\n","\t\t('int', ['bool']) : 4 | ['Gender', 'HasCrCard', 'IsActiveMember', 'generated']\n","\t0.2s = Fit runtime\n","\t11 features in original data used to generate 11 features in processed data.\n","\tTrain Data (Processed) Memory Usage: 5.31 MB (0.0% of available memory)\n","Data preprocessing and feature engineering runtime = 0.22s ...\n","AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n","\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n","\tTo change this, specify the eval_metric parameter of Predictor()\n","Automatically generating train/validation split with holdout_frac=0.02380521619897352, Train Rows: 102519, Val Rows: 2500\n","User-specified model hyperparameters to be fit:\n","{\n","\t'NN_TORCH': {},\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n","\t'CAT': {},\n","\t'XGB': {},\n","\t'FASTAI': {},\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n","}\n","Fitting 13 L1 models ...\n","Fitting model: KNeighborsUnif ...\n","\t0.5874\t = Validation score   (roc_auc)\n","\t0.1s\t = Training   runtime\n","\t0.02s\t = Validation runtime\n","Fitting model: KNeighborsDist ...\n","\t0.5933\t = Validation score   (roc_auc)\n","\t0.1s\t = Training   runtime\n","\t0.02s\t = Validation runtime\n","Fitting model: LightGBMXT ...\n","\t0.8903\t = Validation score   (roc_auc)\n","\t2.11s\t = Training   runtime\n","\t0.01s\t = Validation runtime\n","Fitting model: LightGBM ...\n","\t0.8902\t = Validation score   (roc_auc)\n","\t1.0s\t = Training   runtime\n","\t0.01s\t = Validation runtime\n","Fitting model: RandomForestGini ...\n","\t0.8772\t = Validation score   (roc_auc)\n","\t4.25s\t = Training   runtime\n","\t0.18s\t = Validation runtime\n","Fitting model: RandomForestEntr ...\n","\t0.8792\t = Validation score   (roc_auc)\n","\t4.96s\t = Training   runtime\n","\t0.18s\t = Validation runtime\n","Fitting model: CatBoost ...\n","\t0.8901\t = Validation score   (roc_auc)\n","\t6.58s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","Fitting model: ExtraTreesGini ...\n","\t0.8844\t = Validation score   (roc_auc)\n","\t2.22s\t = Training   runtime\n","\t0.18s\t = Validation runtime\n","Fitting model: ExtraTreesEntr ...\n","\t0.8823\t = Validation score   (roc_auc)\n","\t2.0s\t = Training   runtime\n","\t0.17s\t = Validation runtime\n","Fitting model: NeuralNetFastAI ...\n","\t0.888\t = Validation score   (roc_auc)\n","\t71.85s\t = Training   runtime\n","\t0.02s\t = Validation runtime\n","Fitting model: XGBoost ...\n","\t0.8895\t = Validation score   (roc_auc)\n","\t0.65s\t = Training   runtime\n","\t0.01s\t = Validation runtime\n","Fitting model: NeuralNetTorch ...\n","\t0.8888\t = Validation score   (roc_auc)\n","\t40.19s\t = Training   runtime\n","\t0.01s\t = Validation runtime\n","Fitting model: LightGBMLarge ...\n","\t0.8912\t = Validation score   (roc_auc)\n","\t2.37s\t = Training   runtime\n","\t0.04s\t = Validation runtime\n","Fitting model: WeightedEnsemble_L2 ...\n","\tEnsemble Weights: {'LightGBMLarge': 0.513, 'LightGBMXT': 0.167, 'CatBoost': 0.167, 'LightGBM': 0.077, 'RandomForestEntr': 0.051, 'XGBoost': 0.026}\n","\t0.8917\t = Validation score   (roc_auc)\n","\t0.48s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","AutoGluon training complete, total runtime = 142.55s ... Best model: \"WeightedEnsemble_L2\"\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240108_152104\")\n"]},{"data":{"text/plain":["{'roc_auc': 0.8884477293978813,\n"," 'accuracy': 0.8641966491937212,\n"," 'balanced_accuracy': 0.7472144714276622,\n"," 'mcc': 0.5580469464842133,\n"," 'f1': 0.6287967517763723,\n"," 'precision': 0.7435826408125578,\n"," 'recall': 0.5447104978354979}"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["from autogluon.tabular import TabularDataset, TabularPredictor\n","\n","\n","gluon_train_df = X_train.copy()\n","gluon_train_df[target_col] = y_train\n","\n","gluon_val_df = X_val.copy()\n","gluon_val_df[target_col] = y_val\n","\n","train_data = TabularDataset(gluon_train_df)\n","val_data = TabularDataset(gluon_val_df)\n","\n","label = target_col\n","\n","predictor = TabularPredictor(label=label, eval_metric='roc_auc').fit(train_data)\n","predictor.evaluate(val_data, silent=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>score_test</th>\n","      <th>score_val</th>\n","      <th>eval_metric</th>\n","      <th>pred_time_test</th>\n","      <th>pred_time_val</th>\n","      <th>fit_time</th>\n","      <th>pred_time_test_marginal</th>\n","      <th>pred_time_val_marginal</th>\n","      <th>fit_time_marginal</th>\n","      <th>stack_level</th>\n","      <th>can_infer</th>\n","      <th>fit_order</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>WeightedEnsemble_L2</td>\n","      <td>0.888448</td>\n","      <td>0.891729</td>\n","      <td>roc_auc</td>\n","      <td>1.304070</td>\n","      <td>0.242181</td>\n","      <td>18.144470</td>\n","      <td>0.004278</td>\n","      <td>0.000538</td>\n","      <td>0.477773</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CatBoost</td>\n","      <td>0.888237</td>\n","      <td>0.890079</td>\n","      <td>roc_auc</td>\n","      <td>0.055577</td>\n","      <td>0.002537</td>\n","      <td>6.581679</td>\n","      <td>0.055577</td>\n","      <td>0.002537</td>\n","      <td>6.581679</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>LightGBM</td>\n","      <td>0.888181</td>\n","      <td>0.890206</td>\n","      <td>roc_auc</td>\n","      <td>0.059850</td>\n","      <td>0.005121</td>\n","      <td>1.001610</td>\n","      <td>0.059850</td>\n","      <td>0.005121</td>\n","      <td>1.001610</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>XGBoost</td>\n","      <td>0.887780</td>\n","      <td>0.889509</td>\n","      <td>roc_auc</td>\n","      <td>0.075617</td>\n","      <td>0.007329</td>\n","      <td>0.647997</td>\n","      <td>0.075617</td>\n","      <td>0.007329</td>\n","      <td>0.647997</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>LightGBMLarge</td>\n","      <td>0.887562</td>\n","      <td>0.891222</td>\n","      <td>roc_auc</td>\n","      <td>0.162201</td>\n","      <td>0.042486</td>\n","      <td>2.374122</td>\n","      <td>0.162201</td>\n","      <td>0.042486</td>\n","      <td>2.374122</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>LightGBMXT</td>\n","      <td>0.887396</td>\n","      <td>0.890296</td>\n","      <td>roc_auc</td>\n","      <td>0.172759</td>\n","      <td>0.008590</td>\n","      <td>2.106066</td>\n","      <td>0.172759</td>\n","      <td>0.008590</td>\n","      <td>2.106066</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>NeuralNetFastAI</td>\n","      <td>0.886950</td>\n","      <td>0.888019</td>\n","      <td>roc_auc</td>\n","      <td>0.630671</td>\n","      <td>0.024803</td>\n","      <td>71.849522</td>\n","      <td>0.630671</td>\n","      <td>0.024803</td>\n","      <td>71.849522</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>NeuralNetTorch</td>\n","      <td>0.885896</td>\n","      <td>0.888776</td>\n","      <td>roc_auc</td>\n","      <td>0.309055</td>\n","      <td>0.010098</td>\n","      <td>40.186801</td>\n","      <td>0.309055</td>\n","      <td>0.010098</td>\n","      <td>40.186801</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>ExtraTreesGini</td>\n","      <td>0.881253</td>\n","      <td>0.884434</td>\n","      <td>roc_auc</td>\n","      <td>0.638494</td>\n","      <td>0.176742</td>\n","      <td>2.218977</td>\n","      <td>0.638494</td>\n","      <td>0.176742</td>\n","      <td>2.218977</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>ExtraTreesEntr</td>\n","      <td>0.880519</td>\n","      <td>0.882325</td>\n","      <td>roc_auc</td>\n","      <td>0.680704</td>\n","      <td>0.174704</td>\n","      <td>2.003752</td>\n","      <td>0.680704</td>\n","      <td>0.174704</td>\n","      <td>2.003752</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>RandomForestEntr</td>\n","      <td>0.875067</td>\n","      <td>0.879222</td>\n","      <td>roc_auc</td>\n","      <td>0.773786</td>\n","      <td>0.175579</td>\n","      <td>4.955223</td>\n","      <td>0.773786</td>\n","      <td>0.175579</td>\n","      <td>4.955223</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>RandomForestGini</td>\n","      <td>0.874514</td>\n","      <td>0.877187</td>\n","      <td>roc_auc</td>\n","      <td>0.590264</td>\n","      <td>0.175297</td>\n","      <td>4.254274</td>\n","      <td>0.590264</td>\n","      <td>0.175297</td>\n","      <td>4.254274</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>KNeighborsDist</td>\n","      <td>0.566730</td>\n","      <td>0.593267</td>\n","      <td>roc_auc</td>\n","      <td>0.268801</td>\n","      <td>0.019101</td>\n","      <td>0.096417</td>\n","      <td>0.268801</td>\n","      <td>0.019101</td>\n","      <td>0.096417</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>KNeighborsUnif</td>\n","      <td>0.566023</td>\n","      <td>0.587361</td>\n","      <td>roc_auc</td>\n","      <td>0.239705</td>\n","      <td>0.017448</td>\n","      <td>0.097765</td>\n","      <td>0.239705</td>\n","      <td>0.017448</td>\n","      <td>0.097765</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  model  score_test  score_val eval_metric  pred_time_test  \\\n","0   WeightedEnsemble_L2    0.888448   0.891729     roc_auc        1.304070   \n","1              CatBoost    0.888237   0.890079     roc_auc        0.055577   \n","2              LightGBM    0.888181   0.890206     roc_auc        0.059850   \n","3               XGBoost    0.887780   0.889509     roc_auc        0.075617   \n","4         LightGBMLarge    0.887562   0.891222     roc_auc        0.162201   \n","5            LightGBMXT    0.887396   0.890296     roc_auc        0.172759   \n","6       NeuralNetFastAI    0.886950   0.888019     roc_auc        0.630671   \n","7        NeuralNetTorch    0.885896   0.888776     roc_auc        0.309055   \n","8        ExtraTreesGini    0.881253   0.884434     roc_auc        0.638494   \n","9        ExtraTreesEntr    0.880519   0.882325     roc_auc        0.680704   \n","10     RandomForestEntr    0.875067   0.879222     roc_auc        0.773786   \n","11     RandomForestGini    0.874514   0.877187     roc_auc        0.590264   \n","12       KNeighborsDist    0.566730   0.593267     roc_auc        0.268801   \n","13       KNeighborsUnif    0.566023   0.587361     roc_auc        0.239705   \n","\n","    pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n","0        0.242181  18.144470                 0.004278                0.000538   \n","1        0.002537   6.581679                 0.055577                0.002537   \n","2        0.005121   1.001610                 0.059850                0.005121   \n","3        0.007329   0.647997                 0.075617                0.007329   \n","4        0.042486   2.374122                 0.162201                0.042486   \n","5        0.008590   2.106066                 0.172759                0.008590   \n","6        0.024803  71.849522                 0.630671                0.024803   \n","7        0.010098  40.186801                 0.309055                0.010098   \n","8        0.176742   2.218977                 0.638494                0.176742   \n","9        0.174704   2.003752                 0.680704                0.174704   \n","10       0.175579   4.955223                 0.773786                0.175579   \n","11       0.175297   4.254274                 0.590264                0.175297   \n","12       0.019101   0.096417                 0.268801                0.019101   \n","13       0.017448   0.097765                 0.239705                0.017448   \n","\n","    fit_time_marginal  stack_level  can_infer  fit_order  \n","0            0.477773            2       True         14  \n","1            6.581679            1       True          7  \n","2            1.001610            1       True          4  \n","3            0.647997            1       True         11  \n","4            2.374122            1       True         13  \n","5            2.106066            1       True          3  \n","6           71.849522            1       True         10  \n","7           40.186801            1       True         12  \n","8            2.218977            1       True          8  \n","9            2.003752            1       True          9  \n","10           4.955223            1       True          6  \n","11           4.254274            1       True          5  \n","12           0.096417            1       True          2  \n","13           0.097765            1       True          1  "]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["predictor.leaderboard(val_data)"]},{"cell_type":"markdown","metadata":{},"source":["# Submission"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["train_df = pd.read_csv(input_folder + \"playground-series-s4e1/train.csv\", index_col=\"id\")\n","test_df = pd.read_csv(input_folder + \"playground-series-s4e1/test.csv\", index_col=\"id\")\n","submission_df = pd.read_csv(input_folder + \"playground-series-s4e1/sample_submission.csv\")\n","original_df = pd.read_csv(input_folder + \"bank-customer-churn-prediction/Churn_Modelling.csv\")\n","target_col = \"Exited\"\n","\n","numeric_features = ['CustomerId', 'CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n","categorical_features = ['Surname', 'Geography', 'Gender', 'HasCrCard', 'IsActiveMember']\n","\n","features_to_drop = ['CustomerId', 'Surname']\n","\n","GENERATED_COLUMN = True\n","ADD_ORIGINAL_DF = True\n","\n","model_postfix = \"_with_original\" if ADD_ORIGINAL_DF else \"\"\n","model_postfix += \"_generated\" if GENERATED_COLUMN else \"\"\n","\n","original_df = original_df.drop(columns=['RowNumber'])\n","\n","# drop na rows from orignal df\n","original_df = original_df.dropna()\n","\n","if GENERATED_COLUMN:\n","    train_df['generated'] = 1\n","    test_df['generated'] = 1\n","    original_df['generated'] = 0\n","    categorical_features.append('generated')\n","    \n","if ADD_ORIGINAL_DF:\n","    train_df = pd.concat([train_df, original_df])\n","\n","\n","for f in features_to_drop:\n","    if f in numeric_features:\n","        numeric_features.remove(f)\n","    if f in categorical_features:\n","        categorical_features.remove(f)\n","    \n","    train_df = train_df.drop(columns=f)\n","    test_df = test_df.drop(columns=f)\n","\n","train_df = initial_feature_engineering(train_df)\n","train_df = feature_engineering_1(train_df)\n","\n","test_df = initial_feature_engineering(test_df)\n","test_df = feature_engineering_1(test_df)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Fitting AutoMLPipelineFeatureGenerator...\n","\tAvailable Memory:                    20003.99 MB\n","\tTrain Data (Original)  Memory Usage: 45.21 MB (0.2% of available memory)\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n","\tStage 1 Generators:\n","\t\tFitting AsTypeFeatureGenerator...\n","\t\t\tNote: Converting 14 features to boolean dtype as they only contain 2 unique values.\n","\tStage 2 Generators:\n","\t\tFitting FillNaFeatureGenerator...\n","\tStage 3 Generators:\n","\t\tFitting IdentityFeatureGenerator...\n","\t\tFitting CategoryFeatureGenerator...\n","\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n","\tStage 4 Generators:\n","\t\tFitting DropUniqueFeatureGenerator...\n","\tStage 5 Generators:\n","\t\tFitting DropDuplicatesFeatureGenerator...\n","\tTypes of features in original data (raw dtype, special dtypes):\n","\t\t('bool', [])   :  2 | ['HasCrCard', 'IsActiveMember']\n","\t\t('float', [])  :  3 | ['Age', 'Balance', 'EstimatedSalary']\n","\t\t('int', [])    : 14 | ['CreditScore', 'Tenure', 'NumOfProducts', 'Exited', 'generated', ...]\n","\t\t('object', []) :  2 | ['Geography', 'Gender']\n","\tTypes of features in processed data (raw dtype, special dtypes):\n","\t\t('category', [])  :  1 | ['Geography']\n","\t\t('float', [])     :  3 | ['Age', 'Balance', 'EstimatedSalary']\n","\t\t('int', [])       :  3 | ['CreditScore', 'Tenure', 'NumOfProducts']\n","\t\t('int', ['bool']) : 14 | ['Gender', 'HasCrCard', 'IsActiveMember', 'Exited', 'generated', ...]\n","\t0.3s = Fit runtime\n","\t21 features in original data used to generate 21 features in processed data.\n","\tTrain Data (Processed) Memory Usage: 11.85 MB (0.1% of available memory)\n","No path specified. Models will be saved in: \"AutogluonModels/ag-20240108_171740\"\n","Presets specified: ['best_quality']\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n","Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n","Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n","Sub-fit(s) time limit is: 2 seconds.\n","Starting holdout-based sub-fit for dynamic stacking. Context path is: AutogluonModels/ag-20240108_171740/ds_sub_fit/sub_fit_ho.\n","Running the sub-fit in a ray process to avoid memory leakage.\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m TabularPredictor(label\u001b[38;5;241m=\u001b[39mlabel, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# time limit should be 15 minutes\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_quality\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_ml_pipeline_feature_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/kaggling/lib/python3.11/site-packages/autogluon/core/utils/decorators.py:31\u001b[0m, in \u001b[0;36munpack.<locals>._unpack_inner.<locals>._call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     30\u001b[0m     gargs, gkwargs \u001b[38;5;241m=\u001b[39m g(\u001b[38;5;241m*\u001b[39mother_args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/kaggling/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:1099\u001b[0m, in \u001b[0;36mTabularPredictor.fit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, fit_full_last_level_weighted_ensemble, full_weighted_ensemble_additionally, dynamic_stacking, calibrate_decision_threshold, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dynamic_stacking:\n\u001b[1;32m   1094\u001b[0m     logger\u001b[38;5;241m.\u001b[39mlog(\n\u001b[1;32m   1095\u001b[0m         \u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m   1096\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDynamic stacking is enabled (dynamic_stacking=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdynamic_stacking\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1097\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1098\u001b[0m     )\n\u001b[0;32m-> 1099\u001b[0m     num_stack_levels, time_limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamic_stacking\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mds_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (time_limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (time_limit \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m   1102\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1103\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot enough time left to train models for the full fit. Consider specifying a larger time_limit. Time remaining: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_limit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m         )\n","File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/kaggling/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:1186\u001b[0m, in \u001b[0;36mTabularPredictor._dynamic_stacking\u001b[0;34m(self, ag_fit_kwargs, ag_post_fit_kwargs, validation_procedure, detection_time_frac, holdout_frac, n_folds, n_repeats, memory_safe_fits, clean_up_fits, holdout_data)\u001b[0m\n\u001b[1;32m   1181\u001b[0m         ds_fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mds_fit_context\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ds_fit_context \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/sub_fit_custom_ho\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1182\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   1183\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting holdout-based sub-fit for dynamic stacking with custom validation data. Context path is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mds_fit_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds_fit_context\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1184\u001b[0m         )\n\u001b[0;32m-> 1186\u001b[0m     stacked_overfitting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sub_fit_memory_save_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mds_fit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_ag_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_ag_post_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mholdout_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mholdout_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1195\u001b[0m     \u001b[38;5;66;03m# Holdout is false, use (repeated) cross-validation\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m     is_stratified \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;129;01min\u001b[39;00m [REGRESSION, QUANTILE, SOFTCLASS]\n","File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/kaggling/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:1328\u001b[0m, in \u001b[0;36mTabularPredictor._sub_fit_memory_save_wrapper\u001b[0;34m(self, train_data, time_limit, ds_fit_kwargs, ag_fit_kwargs, ag_post_fit_kwargs, holdout_data)\u001b[0m\n\u001b[1;32m   1318\u001b[0m     sub_fit_caller \u001b[38;5;241m=\u001b[39m _ds_ray\u001b[38;5;241m.\u001b[39mremote(max_calls\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)(_sub_fit)\n\u001b[1;32m   1319\u001b[0m     ref \u001b[38;5;241m=\u001b[39m sub_fit_caller\u001b[38;5;241m.\u001b[39moptions(num_cpus\u001b[38;5;241m=\u001b[39mnum_cpus, num_gpus\u001b[38;5;241m=\u001b[39mnum_gpus)\u001b[38;5;241m.\u001b[39mremote(\n\u001b[1;32m   1320\u001b[0m         predictor\u001b[38;5;241m=\u001b[39mpredictor_ref,\n\u001b[1;32m   1321\u001b[0m         train_data\u001b[38;5;241m=\u001b[39mtrain_data_ref,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1326\u001b[0m         holdout_data\u001b[38;5;241m=\u001b[39mholdout_data_ref,\n\u001b[1;32m   1327\u001b[0m     )\n\u001b[0;32m-> 1328\u001b[0m     finished, unfinished \u001b[38;5;241m=\u001b[39m \u001b[43m_ds_ray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mref\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m     stacked_overfitting \u001b[38;5;241m=\u001b[39m _ds_ray\u001b[38;5;241m.\u001b[39mget(finished[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/kaggling/lib/python3.11/site-packages/ray/_private/auto_init_hook.py:24\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mauto_init_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     23\u001b[0m     auto_init_ray()\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/kaggling/lib/python3.11/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/kaggling/lib/python3.11/site-packages/ray/_private/worker.py:2732\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_refs, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[1;32m   2730\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeout \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m6\u001b[39m\n\u001b[1;32m   2731\u001b[0m timeout_milliseconds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m-> 2732\u001b[0m ready_ids, remaining_ids \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobject_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_milliseconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_task_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2738\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2739\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ready_ids, remaining_ids\n","File \u001b[0;32mpython/ray/_raylet.pyx:3012\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpython/ray/_raylet.pyx:400\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from autogluon.features.generators import AutoMLPipelineFeatureGenerator\n","from autogluon.tabular import TabularDataset, TabularPredictor\n","\n","train_data = TabularDataset(train_df)\n","test_data = TabularDataset(test_df)\n","\n","label = target_col\n","\n","auto_ml_pipeline_feature_generator = AutoMLPipelineFeatureGenerator()\n","auto_ml_pipeline_feature_generator.fit_transform(X=train_data)\n","\n","model = TabularPredictor(label=label, eval_metric='roc_auc')\n","# time limit should be 15 minutes\n","\n","model.fit(train_data, presets='best_quality', feature_generator=auto_ml_pipeline_feature_generator, time_limit=60*15)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"AssertionError","evalue":"Predictor is not fit. Call `.fit` before calling `.fit_summary`.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/kaggling/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:2539\u001b[0m, in \u001b[0;36mTabularPredictor.fit_summary\u001b[0;34m(self, verbosity, show_plot)\u001b[0m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_summary\u001b[39m(\u001b[38;5;28mself\u001b[39m, verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, show_plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2523\u001b[0m \u001b[38;5;124;03m    Output summary of information about models produced during `fit()`.\u001b[39;00m\n\u001b[1;32m   2524\u001b[0m \u001b[38;5;124;03m    May create various generated summary plots and store them in folder: `predictor.path`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2537\u001b[0m \u001b[38;5;124;03m    Dict containing various detailed information. We do not recommend directly printing this dict as it may be very large.\u001b[39;00m\n\u001b[1;32m   2538\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2539\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assert_is_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_summary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2540\u001b[0m     \u001b[38;5;66;03m# hpo_used = len(self._trainer.hpo_results) > 0\u001b[39;00m\n\u001b[1;32m   2541\u001b[0m     hpo_used \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# Disabled until a more memory efficient hpo_results object is implemented.\u001b[39;00m\n","File \u001b[0;32m~/.pyenv/versions/3.11.3/envs/kaggling/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:4742\u001b[0m, in \u001b[0;36mTabularPredictor._assert_is_fit\u001b[0;34m(self, message_suffix)\u001b[0m\n\u001b[1;32m   4740\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4741\u001b[0m     error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m `.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage_suffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 4742\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(error_message)\n","\u001b[0;31mAssertionError\u001b[0m: Predictor is not fit. Call `.fit` before calling `.fit_summary`."]}],"source":["model.fit_summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-04T20:09:37.302130Z","iopub.status.busy":"2024-01-04T20:09:37.301584Z","iopub.status.idle":"2024-01-04T20:09:50.619255Z","shell.execute_reply":"2024-01-04T20:09:50.617914Z","shell.execute_reply.started":"2024-01-04T20:09:37.302089Z"},"trusted":true},"outputs":[],"source":["model.leaderboard(train_data)"]},{"cell_type":"markdown","metadata":{},"source":["Use for comparison or blending with other predictions:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-04T20:09:58.484835Z","iopub.status.busy":"2024-01-04T20:09:58.483806Z","iopub.status.idle":"2024-01-04T20:10:01.900339Z","shell.execute_reply":"2024-01-04T20:10:01.898976Z","shell.execute_reply.started":"2024-01-04T20:09:58.484778Z"},"trusted":true},"outputs":[],"source":["# predict on test data\n","y_predproba = model.predict_proba(test_data)\n","\n","# create submission df\n","\n","submission_df = pd.DataFrame({\n","    \"id\": test_df.index,\n","    target_col: y_predproba\n","})\n","submission_df.to_csv(f\"{output_folder}/submission.csv\", index=False)\n","submission_df"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":7405009,"sourceId":65711,"sourceType":"competition"},{"datasetId":3191230,"sourceId":5536933,"sourceType":"datasetVersion"}],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
