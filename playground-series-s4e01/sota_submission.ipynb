{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wiktor/.pyenv/versions/3.11.3/envs/kaggling/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAABhCAYAAAAa2uy9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADKUlEQVR4nO3bz2qcZRjG4eedP2nsQCsh0SIFNz2BZO8p9CQ8Bg9AcO/GnoBuPQE3HkKCCLpxUTcFbQ2kJjWZmczrQnGZTOktn5+9rs1sHoabgY8fwzCt994LAIImQw8A4P9HXACIExcA4sQFgDhxASBOXACIExcA4sQFgLjZNkcnJyfVe6/5fP5v7wHgP2y1WlVrrQ4PD2+82youvffabDb162+v6tof+re2f3lV/WBR7flFtWuf2zb6tFV/b1Gz+ctqbTP0nNHofVLr5b2aXZ1W69dDzxmF3qa1urNXZ3VZm/J8but+7dZsMr31bqu4zOfzWi6X9eU3z+vZi+Ubj3tbfPH9d3X+5HEtPv22Zj+dDj1nFNaP9ur8yeN6+Ojr2r37y9BzRuPy1fv19MeP6+EPn9c7Fz8PPWcU/lh8WE+PPquv+kk9q9+HnjMan9RH9WD+7q13fnMBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIhrvfd+29Hx8XH13uvsfF3rza3n/G1/uay+v6j24qLaajP0nFHo80n1/UXN5i+rteuh54xG79Nar+7V7Oq02mY99JxR6JNZre/s1Vm/rOvyfG7rfu3WbDKto6OjG+9m27xZa62qqg727r75srfK4q+XD3aGnTFK+0MPGJXWqnZ2qmrnwdBTRqNV1U5VHZTn83WsVqt/mnCTrb65AMDr8JsLAHHiAkCcuAAQJy4AxIkLAHHiAkCcuAAQJy4AxP0JEUGH3u8dhhMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# essentials\n",
    "import os\n",
    "import pathlib\n",
    "from copy import copy\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# visualisation\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn imports\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MaxAbsScaler, PowerTransformer, FunctionTransformer, StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MaxAbsScaler, PowerTransformer, FunctionTransformer, StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, make_union, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, SequentialFeatureSelector, RFECV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.base import clone as clone_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix, log_loss\n",
    "from sklearn.impute import SimpleImputer, MissingIndicator, KNNImputer\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, ElasticNet, SGDClassifier, RidgeClassifier, PassiveAggressiveClassifier, TweedieRegressor\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB, ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import RocCurveDisplay, roc_auc_score, make_scorer, roc_curve\n",
    "\n",
    "from sklearn.preprocessing import Binarizer, Normalizer, RobustScaler, StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "# others\n",
    "import xgboost as xgb \n",
    "import lightgbm as lgb\n",
    "\n",
    "import optuna\n",
    "import shap\n",
    "\n",
    "RANDOM_SEED = 64\n",
    "\n",
    "palette = [\"#4464ad\", \"#dc136c\", \"#F4FF52\", \"#f58f29\",\"#45cb85\"]\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_palette(palette)\n",
    "sns.palplot(palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering_1(df):\n",
    "    # Balance\n",
    "    df['balance_over_100k'] = df['Balance'] >= 100000\n",
    "    df['balance_over_150k'] = df['Balance'] >= 150000\n",
    "\n",
    "    # EstimatedSalary\n",
    "    df[\"estimated_salary_under_50k\"] = df[\"EstimatedSalary\"] < 50000\n",
    "    df[\"estimated_salary_50k_to_100k\"] = (df[\"EstimatedSalary\"] >= 50000) & (df[\"EstimatedSalary\"] < 100000)\n",
    "    df[\"estamated_salary_over_150k\"] = df[\"EstimatedSalary\"] >= 150000\n",
    "\n",
    "    # NumOfProducts\n",
    "    df[\"num_of_products_3_or_4\"] = df[\"NumOfProducts\"] >= 3\n",
    "\n",
    "    # Age\n",
    "    df[\"age_over_40\"] = df[\"Age\"] >= 40\n",
    "    df[\"age_over_50\"] = df[\"Age\"] >= 50\n",
    "    df[\"age_over_60\"] = df[\"Age\"] >= 60\n",
    "\n",
    "    new_features = [\n",
    "        \"balance_over_100k\",\n",
    "        \"balance_over_150k\",\n",
    "        \"estimated_salary_under_50k\",\n",
    "        \"estimated_salary_50k_to_100k\",\n",
    "        \"estamated_salary_over_150k\",\n",
    "        \"num_of_products_3_or_4\",\n",
    "        \"age_over_40\",\n",
    "        \"age_over_50\",\n",
    "        \"age_over_60\",\n",
    "    ]\n",
    "    for f in new_features:\n",
    "        df[f] = df[f].astype(\"int\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_KAGGLE = False\n",
    "\n",
    "kaggle_folder = \"/kaggle/input/\"\n",
    "local_folder = \"./data/\"\n",
    "input_folder = kaggle_folder if IN_KAGGLE else local_folder\n",
    "\n",
    "train_df = pd.read_csv(input_folder + \"playground-series-s4e1/train.csv\", index_col=\"id\")\n",
    "test_df = pd.read_csv(input_folder + \"playground-series-s4e1/test.csv\", index_col=\"id\")\n",
    "submission_df = pd.read_csv(input_folder + \"playground-series-s4e1/sample_submission.csv\")\n",
    "original_df = pd.read_csv(input_folder + \"bank-customer-churn-prediction/Churn_Modelling.csv\")\n",
    "target_col = \"Exited\"\n",
    "\n",
    "numeric_features = ['CustomerId', 'CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "categorical_features = ['Surname', 'Geography', 'Gender', 'HasCrCard', 'IsActiveMember']\n",
    "\n",
    "features_to_drop = ['CustomerId', 'Surname']\n",
    "\n",
    "for f in features_to_drop:\n",
    "    if f in numeric_features:\n",
    "        numeric_features.remove(f)\n",
    "    if f in categorical_features:\n",
    "        categorical_features.remove(f)\n",
    "    \n",
    "    test_df = test_df.drop(columns=f)\n",
    "    train_df = train_df.drop(columns=f)\n",
    "\n",
    "def initial_feature_engineering(df):\n",
    "    df['HasCrCard'] = df['HasCrCard'].astype('bool')\n",
    "    df['IsActiveMember'] = df['IsActiveMember'].astype('bool')\n",
    "    df['Gender'] = df['Gender'].map({ \"Male\": 0, \"Female\": 1}).astype(\"bool\")\n",
    "    # encode geography\n",
    "    df = pd.get_dummies(df, columns=['Geography'])\n",
    "\n",
    "    return df\n",
    "\n",
    "train_df = initial_feature_engineering(train_df)\n",
    "test_df = initial_feature_engineering(test_df)\n",
    "\n",
    "train_df = feature_engineering_1(train_df)\n",
    "test_df = feature_engineering_1(test_df)\n",
    "\n",
    "X_train = train_df.drop(columns=target_col)\n",
    "y_train = train_df[target_col]\n",
    "X_test = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {'n_estimators': 631, 'learning_rate': 0.07492424154497802, 'max_depth': 3, 'reg_alpha': 5.323900045022921, 'reg_lambda': 5.220597472139037, 'min_child_weight': 1.6884481522503845, 'min_child_samples': 62, 'subsample': 0.6762768751029923, 'subsample_freq': 3, 'colsample_bytree': 0.9210890470992197, 'num_leaves': 60, 'max_bin': 592}\n",
    "xgb_params = {'learning_rate': 0.014348229871720625, 'max_depth': 4, 'n_estimators': 400, 'gamma': 5.680012611123468e-05, 'subsample': 0.831669794155444, 'colsample_bytree': 0.8672951333636212, 'reg_alpha': 1.93331396215278e-05, 'reg_lambda': 4.9053061670211516e-06, 'min_child_weight': 7.059289455794295e-07}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 =  StackingClassifier(\n",
    "    estimators=[\n",
    "        (\"xgboost\", xgb.XGBClassifier(random_state=RANDOM_SEED, n_jobs=-1, **xgb_params)),\n",
    "        (\"lightgbm\", lgb.LGBMClassifier(random_state=RANDOM_SEED, n_jobs=-1, verbosity=-1, **lgbm_params)),\n",
    "        (\"knn\", KNeighborsClassifier(n_jobs=-1)),\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(random_state=RANDOM_SEED, n_jobs=-1),\n",
    "    n_jobs=-1,\n",
    "    verbose=1,   \n",
    ")\n",
    "\n",
    "model_2 = StackingClassifier(\n",
    "    estimators=[\n",
    "        (\"xgboost\", xgb.XGBClassifier(random_state=RANDOM_SEED, n_jobs=-1, **xgb_params)),\n",
    "        (\"lightgbm\", lgb.LGBMClassifier(random_state=RANDOM_SEED, n_jobs=-1, verbosity=-1, **lgbm_params)),\n",
    "        (\"logistic_regression\", LogisticRegression(random_state=RANDOM_SEED, n_jobs=-1)),\n",
    "        (\"sgd\", SGDClassifier(random_state=RANDOM_SEED, loss=\"log_loss\", n_jobs=-1)),\n",
    "    ],\n",
    "    final_estimator=lgb.LGBMClassifier(random_state=RANDOM_SEED, n_jobs=-1, verbosity=-1),\n",
    "    n_jobs=-1,\n",
    "    verbose=1,   \n",
    ")\n",
    "\n",
    "model_3 = lgb.LGBMClassifier(random_state=RANDOM_SEED, n_jobs=-1, verbosity=-1)\n",
    "\n",
    "models = {\n",
    "    \"stacking_classifier\": model_1,\n",
    "    \"stacking_classifier_lgbm\": model_2,\n",
    "    \"lightgbm\": model_3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_pipeline(model, features=None):\n",
    "    numeric_pipeline = Pipeline(\n",
    "        [(\"scaler\", StandardScaler())]\n",
    "    )\n",
    "\n",
    "    categorical_pipeline = Pipeline([\n",
    "        #(\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\", drop='if_binary')),\n",
    "    ])\n",
    "\n",
    "    pipeline_numeric_features = numeric_features\n",
    "    pipeline_categorical_features = categorical_features\n",
    "    if features:\n",
    "        # select only the features that are in features\n",
    "        pipeline_numeric_features = [f for f in numeric_features if f in features]\n",
    "        pipeline_categorical_features = [f for f in categorical_features if f in features]\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"numeric\", numeric_pipeline, pipeline_numeric_features),\n",
    "        #(\"categorical\", categorical_pipeline, pipeline_categorical_features),\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "    return Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", model),\n",
    "    ])\n",
    "\n",
    "def train_models(models, X_train, y_train, parameters={}):\n",
    "    trained_models = {}\n",
    "    for model_name, model in tqdm(models.items()):\n",
    "        model = create_pipeline(model)\n",
    "        if model_name in parameters:\n",
    "            model.set_params(**parameters[model_name])\n",
    "        model.fit(X_train, y_train)\n",
    "        trained_models[model_name] = model\n",
    "    return trained_models\n",
    "\n",
    "def evaluate_models(models, X_val, y_val):\n",
    "    # create a dataframe with \"model_name\", \"accuracy\", \"precision\", \"recall\", \"area under the ROC curve\"\n",
    "    results_df = pd.DataFrame(columns=[\"model_name\", \"accuracy\", \"precision\", \"recall\", \"auc\"])\n",
    "\n",
    "    for model_name, model in tqdm(models.items()):\n",
    "        print(model_name)\n",
    "        y_pred = model.predict(X_val)\n",
    "        y_proba = model.predict_proba(X_val)[:, 1]\n",
    "        \n",
    "        results_df = pd.concat([\n",
    "            results_df,\n",
    "            pd.DataFrame({\n",
    "                \"model_name\": [model_name],\n",
    "                \"accuracy\": [model.score(X_val, y_val)],\n",
    "                \"precision\": [sklearn.metrics.precision_score(y_val, y_pred)],\n",
    "                \"recall\": [sklearn.metrics.recall_score(y_val, y_pred)],\n",
    "                \"auc\": [sklearn.metrics.roc_auc_score(y_val, y_proba)],\n",
    "            })\n",
    "        ])\n",
    "    return results_df\n",
    "\n",
    "def plot_roc_curve(models, X_val, y_val):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "    palette_to_use = sns.color_palette(\"husl\", len(models))\n",
    "    # for each model, plot the roc curve in the same plot, with other color\n",
    "    for i, (model_name, model) in enumerate(models.items()):\n",
    "        y_proba = model.predict_proba(X_val)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_val, y_proba)\n",
    "        roc_auc = roc_auc_score(y_val, y_proba)\n",
    "        ax.plot(fpr, tpr, label=f\"{model_name} (AUC = {roc_auc:.2f})\", color=palette_to_use[i])\n",
    "        ax.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.set_title(\"ROC Curve\")\n",
    "    # show legend\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s][Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   10.2s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   12.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   24.6s finished\n"
     ]
    }
   ],
   "source": [
    "trained_models = {}\n",
    "\n",
    "for model_name, model in tqdm(models.items()):\n",
    "    model = clone_model(model)\n",
    "    model = create_pipeline(model)\n",
    "    model.fit(X_train, y_train)\n",
    "    trained_models[model_name] = model\n",
    "\n",
    "    # predict on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "    # create submission df\n",
    "\n",
    "    submission_df = pd.DataFrame({\n",
    "        \"id\": test_df.index,\n",
    "        target_col: y_proba\n",
    "    })\n",
    "    submission_df.to_csv(f\"./submission_{model_name}.csv\", index=False)\n",
    "submission_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
